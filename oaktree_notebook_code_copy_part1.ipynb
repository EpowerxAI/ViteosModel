{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ViteosMongoDB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d37e24aab8dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mViteosMongoDB\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mViteosMongoDB_Class\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmngdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ViteosMongoDB'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Sep  5 20:36:16 2020\n",
    "\n",
    "@author: consultant138\n",
    "\"\"\"\n",
    "import os\n",
    "#os.chdir('D:\\\\ViteosModel')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import sys\n",
    "from ViteosMongoDB import  ViteosMongoDB_Class as mngdb\n",
    "from datetime import datetime,date,timedelta\n",
    "from pandas.io.json import json_normalize\n",
    "import dateutil.parser\n",
    "from difflib import SequenceMatcher\n",
    "import pprint\n",
    "import json\n",
    "from pandas import merge\n",
    "import re\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dateutil.parser import parse\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import random\n",
    "import decimal\n",
    "\n",
    "cols = ['Currency','Account Type','Accounting Net Amount',\n",
    "#'Accounting Net Amount Difference','Accounting Net Amount Difference Absolute ',\n",
    "'Task ID', 'Source Combination Code',\n",
    "'Activity Code','Age','Age WK',\n",
    "'Asset Type Category','Base Currency','Base Net Amount','Bloomberg_Yellow_Key',\n",
    "'B-P Net Amount',\n",
    "#'B-P Net Amount Difference','B-P Net Amount Difference Absolute',\n",
    "'BreakID',\n",
    "'Business Date','Cancel Amount','Cancel Flag','CUSIP','Custodian',\n",
    "'Custodian Account',\n",
    "'Derived Source','Description','Department','ExpiryDate','ExternalComment1','ExternalComment2',\n",
    "'ExternalComment3','Fund','FX Rate','Interest Amount','InternalComment1','InternalComment2',\n",
    "'InternalComment3','Investment Type','Is Combined Data','ISIN','Keys',\n",
    "'Mapped Custodian Account','Net Amount Difference','Net Amount Difference Absolute','Non Trade Description',\n",
    "'OTE Custodian Account',\n",
    "#'Predicted Action','Predicted Status','Prediction Details',\n",
    "'Price','Prime Broker',\n",
    "'Quantity','SEDOL','Settle Date','SPM ID','Status','Strike Price',\n",
    "'System Comments','Ticker','Trade Date','Trade Expenses','Transaction Category','Transaction ID','Transaction Type',\n",
    "'Underlying Cusip','Underlying Investment ID','Underlying ISIN','Underlying Sedol','Underlying Ticker','Source Combination','_ID']\n",
    "#'UnMapped']\n",
    "\n",
    "add = ['ViewData.Side0_UniqueIds', 'ViewData.Side1_UniqueIds',\n",
    "      # 'MetaData.0._RecordID','MetaData.1._RecordID',\n",
    "       'ViewData.Task Business Date']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_cols = ['ViewData.' + x for x in cols] + add\n",
    "\n",
    "common_cols = ['ViewData.Accounting Net Amount', 'ViewData.Age',\n",
    "'ViewData.Age WK', 'ViewData.Asset Type Category',\n",
    "'ViewData.B-P Net Amount', 'ViewData.Base Net Amount','ViewData.CUSIP', \n",
    " 'ViewData.Cancel Amount',\n",
    "       'ViewData.Cancel Flag',\n",
    "#'ViewData.Commission',\n",
    "        'ViewData.Currency', 'ViewData.Custodian',\n",
    "       'ViewData.Custodian Account',\n",
    "       'ViewData.Description','ViewData.Department', 'ViewData.ExpiryDate', 'ViewData.Fund',\n",
    "       'ViewData.ISIN',\n",
    "       'ViewData.Investment Type',\n",
    "      # 'ViewData.Keys',\n",
    "       'ViewData.Mapped Custodian Account',\n",
    "       'ViewData.Net Amount Difference',\n",
    "       'ViewData.Net Amount Difference Absolute',\n",
    "        #'ViewData.OTE Ticker',\n",
    "        'ViewData.Price',\n",
    "       'ViewData.Prime Broker', 'ViewData.Quantity',\n",
    "       'ViewData.SEDOL', 'ViewData.SPM ID', 'ViewData.Settle Date',\n",
    "       \n",
    "  #  'ViewData.Strike Price',\n",
    "               'Date',\n",
    "       'ViewData.Ticker', 'ViewData.Trade Date',\n",
    "       'ViewData.Transaction Category',\n",
    "       'ViewData.Transaction Type', 'ViewData.Underlying Cusip',\n",
    "       'ViewData.Underlying ISIN',\n",
    "       'ViewData.Underlying Sedol','filter_key','ViewData.Status','ViewData.BreakID',\n",
    "              'ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData._ID']\n",
    "\n",
    "model_cols = [\n",
    "            'SideA.ViewData.B-P Net Amount', \n",
    "              #'SideA.ViewData.Cancel Flag', \n",
    "              #'SideA.new_desc_cat',\n",
    "             # 'SideA.ViewData.Description',\n",
    "             # 'SideA.ViewData.Department',\n",
    "   \n",
    "    \n",
    "              \n",
    "             # 'SideA.ViewData.Price',\n",
    "             # 'SideA.ViewData.Quantity',\n",
    "             #'SideA.ViewData.Investment Type', \n",
    "              #'SideA.ViewData.Asset Type Category', \n",
    "              'SideB.ViewData.Accounting Net Amount', \n",
    "              #'SideB.ViewData.Cancel Flag', \n",
    "             # 'SideB.ViewData.Description',\n",
    "              # 'SideB.ViewData.Department',\n",
    "              \n",
    "             # 'SideB.ViewData.Price',\n",
    "             # 'SideB.ViewData.Quantity',\n",
    "             # 'SideB.new_desc_cat',\n",
    "             # 'SideB.ViewData.Investment Type', \n",
    "              #'SideB.ViewData.Asset Type Category', \n",
    "              'Trade_Date_match', 'Settle_Date_match', \n",
    "                'Amount_diff_2', \n",
    "              'Trade_date_diff', 'Settle_date_diff', 'SideA.ISIN_NA', 'SideB.ISIN_NA', \n",
    "             # 'ViewData.Combined Fund',\n",
    "              'ViewData.Combined Transaction Type', 'Combined_Desc','Combined_TType',\n",
    "             # 'SideA.TType', 'SideB.TType', \n",
    "              'abs_amount_flag',\n",
    "    'tt_map_flag', \n",
    "              'All_key_nan','new_key_match', 'new_pb1',\n",
    "              'SideB.Date','SideA.ViewData.Settle Date','SideB.ViewData.Settle Date',\n",
    "            'SideA.ViewData._ID', 'SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds', 'SideA.ViewData.Side1_UniqueIds',\n",
    "              'SideB.ViewData.Status', 'SideB.ViewData.BreakID_B_side',\n",
    "              'SideA.ViewData.Status', 'SideA.ViewData.BreakID_A_side'] \n",
    "              #'label']\n",
    "\n",
    "model_cols_2 =[#'SideA.ViewData.B-P Net Amount', \n",
    "              #'SideA.ViewData.Cancel Flag', \n",
    "              #'SideA.new_desc_cat',\n",
    "             # 'SideA.ViewData.Description',\n",
    "             # 'SideA.ViewData.Department',\n",
    "   \n",
    "    \n",
    "              \n",
    "             # 'SideA.ViewData.Price',\n",
    "             # 'SideA.ViewData.Quantity',\n",
    "             #'SideA.ViewData.Investment Type', \n",
    "              #'SideA.ViewData.Asset Type Category', \n",
    "              #'SideB.ViewData.Accounting Net Amount', \n",
    "              #'SideB.ViewData.Cancel Flag', \n",
    "             # 'SideB.ViewData.Description',\n",
    "              # 'SideB.ViewData.Department',\n",
    "              \n",
    "             # 'SideB.ViewData.Price',\n",
    "             # 'SideB.ViewData.Quantity',\n",
    "             # 'SideB.new_desc_cat',\n",
    "             # 'SideB.ViewData.Investment Type', \n",
    "              #'SideB.ViewData.Asset Type Category', \n",
    "              'Trade_Date_match', 'Settle_Date_match', \n",
    "              #  'Amount_diff_2', \n",
    "              'Trade_date_diff', 'Settle_date_diff', 'SideA.ISIN_NA', 'SideB.ISIN_NA', \n",
    "             # 'ViewData.Combined Fund',\n",
    "              'ViewData.Combined Transaction Type', 'Combined_Desc','Combined_TType',\n",
    "             # 'SideA.TType', 'SideB.TType', \n",
    "              'abs_amount_flag',\n",
    "    'tt_map_flag', \n",
    "              'All_key_nan','new_key_match', 'new_pb1',\n",
    "              'SideB.Date','SideA.ViewData.Settle Date','SideB.ViewData.Settle Date',\n",
    "            'SideA.ViewData._ID', 'SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds', 'SideA.ViewData.Side1_UniqueIds',\n",
    "              'SideB.ViewData.Status', 'SideB.ViewData.BreakID_B_side',\n",
    "              'SideA.ViewData.Status', 'SideA.ViewData.BreakID_A_side'] \n",
    "              #'label']\n",
    "\n",
    "#### Closed break functions - Begin #### \n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def dictionary_exclude_keys(fun_dict, fun_keys_to_exclude):\n",
    "    return {x: fun_dict[x] for x in fun_dict if x not in fun_keys_to_exclude}\n",
    "\n",
    "def write_dict_at_top(fun_filename, fun_dict_to_add):\n",
    "    with open(fun_filename, 'r+') as f:\n",
    "        fun_existing_content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        f.write(json.dumps(fun_dict_to_add, indent = 4))\n",
    "        f.write('\\n')\n",
    "        f.write(fun_existing_content)\n",
    "\n",
    "def normalize_bp_acct_col_names(fun_df):\n",
    "    bp_acct_col_names_mapping_dict = {\n",
    "                                      'ViewData.Cust Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.Cust Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.Cust Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.CP Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.CP Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.CP Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.PMSVendor Net Amount' : 'ViewData.Accounting Net Amount'\n",
    "                                        }\n",
    "    fun_df.rename(columns = bp_acct_col_names_mapping_dict, inplace = True)\n",
    "    return(fun_df)\n",
    "\n",
    "\n",
    "\n",
    "# M X M and N X N architecture for closed break prediction\n",
    "def closed_cols():\n",
    "    cols_for_closed_list = ['Status','Source Combination','Mapped Custodian Account',\n",
    "                   'Accounting Currency','B-P Currency', \n",
    "                   'Transaction ID','Transaction Type','Description','Investment ID',\n",
    "                   'Accounting Net Amount','B-P Net Amount', \n",
    "                   'InternalComment2','Custodian','Fund']\n",
    "    cols_for_closed_list = ['ViewData.' + x for x in cols_for_closed_list]\n",
    "    cols_for_closed_x_list = [x + '_x' for x in cols_for_closed_list] + ['ViewData.Side0_UniqueIds_x','ViewData.Side1_UniqueIds_x']\n",
    "    cols_for_closed_y_list = [x + '_y' for x in cols_for_closed_list] + ['ViewData.Side0_UniqueIds_y','ViewData.Side1_UniqueIds_y']\n",
    "    cols_for_closed_x_y_list = cols_for_closed_x_list + cols_for_closed_y_list\n",
    "    return({\n",
    "            'cols_for_closed' : cols_for_closed_list,\n",
    "            'cols_for_closed_x' : cols_for_closed_x_list,\n",
    "            'cols_for_closed_y' : cols_for_closed_y_list,\n",
    "            'cols_for_closed_x_y' : cols_for_closed_x_y_list\n",
    "            })\n",
    "\n",
    "def cleaned_meo(#fun_filepath_meo, \n",
    "                fun_meo_df):\n",
    "#    meo = pd.read_csv(fun_filepath_meo)           .drop_duplicates()           .reset_index()           .drop('index',1)\n",
    "    meo = fun_meo_df\n",
    "    meo = normalize_bp_acct_col_names(fun_df = meo)\n",
    "    \n",
    "#    Commened out below line on 26-11-2020 to exclude SPM from closed coverage, and added the line below the commened line\n",
    "#    meo = meo[~meo['ViewData.Status'].isin(['SMT','HST', 'OC', 'CT', 'Archive','SMR'])]\n",
    "    meo = meo[~meo['ViewData.Status'].isin(['SPM','SMT','HST', 'OC', 'CT', 'Archive','SMR'])] \n",
    "    meo = meo[~meo['ViewData.Status'].isnull()]           .reset_index()           .drop('index',1)\n",
    "    \n",
    "    meo['Date'] = pd.to_datetime(meo['ViewData.Task Business Date'])\n",
    "    meo = meo[~meo['Date'].isnull()]           .reset_index()           .drop('index',1)\n",
    "    meo['Date'] = pd.to_datetime(meo['Date']).dt.date\n",
    "    meo['Date'] = meo['Date'].astype(str)\n",
    "\n",
    "    meo['ViewData.Side0_UniqueIds'] = meo['ViewData.Side0_UniqueIds'].astype(str)\n",
    "    meo['ViewData.Side1_UniqueIds'] = meo['ViewData.Side1_UniqueIds'].astype(str)\n",
    "\n",
    "    meo['flag_side0'] = meo.apply(lambda x: len(x['ViewData.Side0_UniqueIds'].split(',')), axis=1)\n",
    "    meo['flag_side1'] = meo.apply(lambda x: len(x['ViewData.Side1_UniqueIds'].split(',')), axis=1)\n",
    "\n",
    "    meo.loc[meo['ViewData.Side0_UniqueIds']=='nan','flag_side0'] = 0\n",
    "    meo.loc[meo['ViewData.Side1_UniqueIds']=='nan','flag_side1'] = 0\n",
    "\n",
    "    meo.loc[meo['ViewData.Side0_UniqueIds']=='None','flag_side0'] = 0\n",
    "    meo.loc[meo['ViewData.Side1_UniqueIds']=='None','flag_side1'] = 0\n",
    "   \n",
    "    meo['ViewData.BreakID'] = meo['ViewData.BreakID'].astype(int)\n",
    "    meo = meo[meo['ViewData.BreakID']!=-1]           .reset_index()           .drop('index',1)\n",
    "          \n",
    "    meo['Side_0_1_UniqueIds'] = meo['ViewData.Side0_UniqueIds'].astype(str) +                                 meo['ViewData.Side1_UniqueIds'].astype(str)\n",
    "                                \n",
    "    meo = meo.sort_values(by=['ViewData.Transaction ID','ViewData.Transaction Type'],ascending = False)\n",
    "    return(meo)\n",
    "    \n",
    "def cleaned_aua(fun_filepath_aua):\n",
    "    aua = pd.read_csv(fun_filepath_aua)       .drop_duplicates()       .reset_index()       .drop('index',1)       .sort_values(by=['ViewData.Transaction ID','ViewData.Transaction Type'],ascending = False)\n",
    "\n",
    "    aua = normalize_bp_acct_col_names(fun_df = aua)\n",
    "\n",
    "    \n",
    "    aua['Side_0_1_UniqueIds'] = aua['ViewData.Side0_UniqueIds'].astype(str) +                                 aua['ViewData.Side1_UniqueIds'].astype(str)\n",
    "    \n",
    "    return(aua)\n",
    "\n",
    "def Acct_MEO_combination_file(fun_side, fun_cleaned_meo_df):\n",
    "    if(fun_side == 'PB' or fun_side == 'BP' or fun_side == 'B-P' or fun_side == 'Prime Broker'):\n",
    "        side_meo = fun_cleaned_meo_df[(fun_cleaned_meo_df['flag_side1'] >= 1) & (fun_cleaned_meo_df['flag_side0'] == 0)]\n",
    "#        Currency_col_name = 'ViewData.B-P Currency'\n",
    "    elif(fun_side == 'Acct' or fun_side == 'Accounting'):\n",
    "        side_meo = fun_cleaned_meo_df[(fun_cleaned_meo_df['flag_side1'] == 0) & (fun_cleaned_meo_df['flag_side0'] >= 1)]\n",
    "#        Currency_col_name = 'ViewData.Accounting Currency'\n",
    "    else:\n",
    "        print('The only options for side are on of the following : ')\n",
    "        print('For Prime Broker side, the options are PB or BP or B-P or Prime Broker')\n",
    "        print('For Accounting side, the options are Acct or Accounting')\n",
    "        raise ValueError('Exiting function because fun_side argument was not from the accepted set of parameter values')\n",
    "    \n",
    "    side_meo['filter_key'] = side_meo['ViewData.Source Combination'].astype(str) +                          side_meo['ViewData.Mapped Custodian Account'].astype(str) +                          side_meo['ViewData.Currency'].astype(str)\n",
    "        \n",
    "    side_meo_training_df =[]\n",
    "    for key in (list(np.unique(np.array(list(side_meo['filter_key'].values))))):\n",
    "        side_meo_filter_slice = side_meo[side_meo['filter_key']==key]\n",
    "        if side_meo_filter_slice.empty == False:\n",
    "    \n",
    "            side_meo_filter_slice = side_meo_filter_slice.reset_index()\n",
    "            side_meo_filter_slice = side_meo_filter_slice.drop('index', 1)\n",
    "    \n",
    "            side_meo_filter_joined = pd.merge(side_meo_filter_slice, side_meo_filter_slice, on='filter_key')\n",
    "            side_meo_training_df.append(side_meo_filter_joined)\n",
    "    return(pd.concat(side_meo_training_df))\n",
    "    \n",
    "def identifying_closed_breaks_from_Trans_type(fun_side, fun_transaction_type_list, fun_side_meo_combination_df, fun_setup_code_crucial):\n",
    "    if(fun_side == 'PB' or fun_side == 'BP' or fun_side == 'B-P' or fun_side == 'Prime Broker'):\n",
    "        Net_amount_col_name_list = ['ViewData.B-P Net Amount_' + x for x in ['x','y']]\n",
    "        Side_0_1_UniqueIds_col_name_list = ['ViewData.Side1_UniqueIds_' + x for x in ['x','y']]\n",
    "    elif(fun_side == 'Acct' or fun_side == 'Accounting'):\n",
    "        Net_amount_col_name_list = ['ViewData.Accounting Net Amount_' + x for x in ['x','y']]\n",
    "        Side_0_1_UniqueIds_col_name_list = ['ViewData.Side0_UniqueIds_' + x for x in ['x','y']]\n",
    "    else:\n",
    "        print('The only options for side are on of the following : ')\n",
    "        print('For Prime Broker side, the options are PB or BP or B-P or Prime Broker')\n",
    "        print('For Accounting side, the options are Acct or Accounting')\n",
    "        raise ValueError('Exiting function because fun_side argument was not from the accepted set of parameter values')        \n",
    "    \n",
    "    if(fun_setup_code_crucial == '379'):\n",
    "        Transaction_type_closed_break_df =             fun_side_meo_combination_df[                     (fun_side_meo_combination_df['ViewData.Transaction Type_x'].astype(str).isin(fun_transaction_type_list)) &                     (fun_side_meo_combination_df['ViewData.Transaction Type_y'].astype(str).isin(fun_transaction_type_list)) &                     (abs(fun_side_meo_combination_df[Net_amount_col_name_list[0]]).astype(str) == abs(fun_side_meo_combination_df[Net_amount_col_name_list[1]]).astype(str)) &                     (fun_side_meo_combination_df[Side_0_1_UniqueIds_col_name_list[0]].astype(str) != fun_side_meo_combination_df[Side_0_1_UniqueIds_col_name_list[1]].astype(str))                     ]\n",
    "    return(set(\n",
    "                Transaction_type_closed_break_df['ViewData.Side0_UniqueIds_x'].astype(str) + \\\n",
    "                Transaction_type_closed_break_df['ViewData.Side1_UniqueIds_x'].astype(str)\n",
    "               ))\n",
    "\n",
    "def closed_breaks_captured_mode(fun_aua_df, fun_transaction_type, fun_captured_closed_breaks_set, fun_mode):\n",
    "    if(fun_transaction_type != 'All_Closed_Breaks'):\n",
    "        aua_df = fun_aua_df[(fun_aua_df['ViewData.Status'] == 'UCB') &                             (fun_aua_df['ViewData.Transaction Type'] == fun_transaction_type)]\n",
    "    else:\n",
    "        aua_df = fun_aua_df[(fun_aua_df['ViewData.Status'] == 'UCB')]\n",
    "        \n",
    "    aua_side_0_1_UniqueIds_set = set(aua_df['ViewData.Side0_UniqueIds'].astype(str) +                                  aua_df['ViewData.Side1_UniqueIds'].astype(str))\n",
    "    if(fun_mode == 'Correctly_Captured_In_AUA'):\n",
    "        list_to_return = list(aua_side_0_1_UniqueIds_set & fun_captured_closed_breaks_set)\n",
    "    elif(fun_mode == 'Not_Captured_In_AUA'):\n",
    "        list_to_return = list(aua_side_0_1_UniqueIds_set - fun_captured_closed_breaks_set)\n",
    "    elif(fun_mode == 'Over_Captured_In_AUA'):\n",
    "        list_to_return = list(fun_captured_closed_breaks_set - aua_side_0_1_UniqueIds_set)\n",
    "    return(list_to_return)\n",
    "\n",
    "def update_dict_to_output_breakids_number_pct(fun_dict, fun_aua_df, fun_loop_transaction_type, fun_count, fun_Side_0_1_UniqueIds_list):\n",
    "    mode_type_list = ['Correctly_Captured_In_AUA','Not_Captured_In_AUA','Over_Captured_In_AUA']\n",
    "    for mode_type in mode_type_list:\n",
    "#    if(fun_loop_transaction_type != 'All_Closed_Breaks'):\n",
    "        fun_dict[fun_loop_transaction_type][mode_type + '_BreakIDs_in_AUA'] = list(set(            fun_aua_df[fun_aua_df['Side_0_1_UniqueIds'].isin(                     closed_breaks_captured_mode(fun_aua_df = fun_aua_df,                                         fun_transaction_type = fun_loop_transaction_type,                                         fun_captured_closed_breaks_set = set(fun_Side_0_1_UniqueIds_list),                                         fun_mode = mode_type))]                    ['ViewData.BreakID']))\n",
    "    \n",
    "        fun_total_number = len(                             fun_dict[fun_loop_transaction_type][mode_type + '_BreakIDs_in_AUA'])\n",
    "        \n",
    "        fun_dict[fun_loop_transaction_type][mode_type + '_Total_Number'] = len(                             fun_dict[fun_loop_transaction_type][mode_type + '_BreakIDs_in_AUA'])\n",
    "        \n",
    "        if(fun_count != 0):\n",
    "            \n",
    "            fun_dict[fun_loop_transaction_type][mode_type + '_Percentage'] = fun_total_number/fun_count#\\\n",
    "#                                 fun_dict[fun_loop_transaction_type][mode_type + '_Total_Number']/fun_count\n",
    "        \n",
    "        else:\n",
    "            fun_dict[fun_loop_transaction_type][mode_type + '_Percentage'] = fun_loop_transaction_type + ' not found in Closed breaks of AUA'\n",
    "    return(fun_dict)\n",
    "\n",
    "def closed_daily_run(fun_setup_code, \n",
    "                     fun_date, \n",
    "                     fun_meo_df_daily_run#,\n",
    "#                     fun_main_filepath_meo, \n",
    "#                     fun_main_filepath_aua\n",
    "                     ):\n",
    "    setup_val = fun_setup_code\n",
    "    main_meo = cleaned_meo(fun_meo_df = fun_meo_df_daily_run)#, fun_filepath_meo = fun_main_filepath_meo\n",
    "    \n",
    "    BP_meo_training_df = Acct_MEO_combination_file(fun_side = 'PB', \\\n",
    "                                                   fun_cleaned_meo_df = main_meo)\n",
    "    \n",
    "    Acct_meo_training_df = Acct_MEO_combination_file(fun_side = 'Acct', \\\n",
    "                                                     fun_cleaned_meo_df = main_meo)\n",
    "\n",
    "#    main_aua = cleaned_aua(fun_filepath_aua = fun_main_filepath_aua)\n",
    "    \n",
    "    if(fun_setup_code == '379'):\n",
    "        Transaction_Type_dict = {\n",
    "                                'Interest BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Interest'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Interest Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Interest'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'STIF Interest BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['STIF Interest'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'STIF Interest Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['STIF Interest'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Buy BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Buy'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Buy Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Buy'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Sell BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Sell'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Sell Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Sell'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'ForwardFX BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['ForwardFX'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'ForwardFX Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['ForwardFX'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Internal Trans' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Internal Trans'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Withdraw' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Withdraw'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Deposit' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Deposit'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Redemption' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Redemption'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Subscription' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Redemption'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Incoming Wire' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Incoming Wire'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Transfer' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Transfer'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Withdrawal BP_side' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Withdrawal'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df},\n",
    "                                'Withdrawal Acct_side' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Withdrawal'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Revenue' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Revenue'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Pay Down' : {'side' : 'Acct',\n",
    "                                           'Transaction_Type' : ['Pay Down'],\n",
    "                                           'Side_meo_training_df' : Acct_meo_training_df},\n",
    "                                'Over & Short' : {'side' : 'PB',\n",
    "                                           'Transaction_Type' : ['Over & Short'],\n",
    "                                           'Side_meo_training_df' : BP_meo_training_df}\n",
    "                                }\n",
    "\n",
    "    print(os.getcwd())\n",
    "    os.chdir('D:\\\\ViteosModel\\\\Closed')\n",
    "    print(os.getcwd())\n",
    "    \n",
    "    filepath_stdout = fun_setup_code + '_closed_run_date_' + str(fun_date) + '_timestamp_' + str(datetime.now().strftime(\"%d_%m_%Y_%H_%M\")) + '.txt'\n",
    "    orig_stdout = sys.stdout\n",
    "    f = open(filepath_stdout, 'w')\n",
    "    sys.stdout = f\n",
    "    \n",
    "    Side_0_1_UniqueIds_closed_all_list = []\n",
    "    for Transaction_type in Transaction_Type_dict:\n",
    "\n",
    "        Side_0_1_UniqueIds_for_Transaction_type = identifying_closed_breaks_from_Trans_type(fun_side = Transaction_Type_dict.get(Transaction_type).get('side'), \\\n",
    "                                                                                            fun_transaction_type_list = Transaction_Type_dict.get(Transaction_type).get('Transaction_Type'), \\\n",
    "                                                                                            fun_side_meo_combination_df = Transaction_Type_dict.get(Transaction_type).get('Side_meo_training_df'), \\\n",
    "                                                                                            fun_setup_code_crucial = setup_val)\n",
    "\n",
    "#        count_closed_breaks_for_transaction_type = len(set(main_aua[(main_aua['ViewData.Status'] == 'UCB') & \\\n",
    "#                                                                    (main_aua['ViewData.Transaction Type'] == Transaction_type)]['Side_0_1_UniqueIds']))\n",
    "#        \n",
    "#        Transaction_Type_dict = update_dict_to_output_breakids_number_pct(fun_dict = Transaction_Type_dict, \\\n",
    "#                                                                          fun_aua_df = main_aua, \\\n",
    "#                                                                          fun_loop_transaction_type = Transaction_type, \\\n",
    "#                                                                          fun_count = count_closed_breaks_for_transaction_type, \\\n",
    "#                                                                          fun_Side_0_1_UniqueIds_list = Side_0_1_UniqueIds_for_Transaction_type)\n",
    "            \n",
    "        \n",
    "        Side_0_1_UniqueIds_closed_all_list.extend(Side_0_1_UniqueIds_for_Transaction_type)\n",
    "        print('\\n' + Transaction_type + '\\n')\n",
    "#        pprint.pprint(dictionary_exclude_keys(fun_dict = Transaction_Type_dict.get(Transaction_type),                                      fun_keys_to_exclude = {'side','Transaction_Type','Side_meo_training_df'}),                      width = 4)\n",
    "    \n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "    \n",
    "#    count_all_closed_breaks = len(set(main_aua[(main_aua['ViewData.Status'] == 'UCB')]                                               ['Side_0_1_UniqueIds']))\n",
    "    \n",
    "#    aua_closed_dict = {'All_Closed_Breaks' : {}}\n",
    "#    aua_closed_dict = update_dict_to_output_breakids_number_pct(fun_dict = aua_closed_dict,\\\n",
    "#                                                                fun_aua_df = main_aua, \\\n",
    "#                                                                fun_loop_transaction_type = 'All_Closed_Breaks', \\\n",
    "#                                                                fun_count = count_all_closed_breaks, \\\n",
    "#                                                                fun_Side_0_1_UniqueIds_list = Side_0_1_UniqueIds_closed_all_list)\n",
    "    \n",
    "#    write_dict_at_top(fun_filename = filepath_stdout, \\\n",
    "#                      fun_dict_to_add = aua_closed_dict)\n",
    "    \n",
    "    return(Side_0_1_UniqueIds_closed_all_list)\n",
    "\n",
    "#### Closed break functions - End #### \n",
    "\n",
    "#### Break Prediction functions - Begin #### \n",
    "\n",
    "def equals_fun(a,b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vec_equals_fun = np.vectorize(equals_fun)\n",
    "\n",
    "\n",
    "def descclean(com,cat_list):\n",
    "    cat_all1 = []\n",
    "    list1 = cat_list\n",
    "    m = 0\n",
    "    if (type(com) == str):\n",
    "        com = com.lower()\n",
    "        com1 =  re.split(\"[,/. \\-!?:]+\", com)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for item in list1:\n",
    "            if (type(item) == str):\n",
    "                item = item.lower()\n",
    "                item1 = item.split(' ')\n",
    "                lst3 = [value for value in item1 if value in com1] \n",
    "                if len(lst3) == len(item1):\n",
    "                    cat_all1.append(item)\n",
    "                    m = m+1\n",
    "            \n",
    "                else:\n",
    "                    m = m\n",
    "            else:\n",
    "                    m = 0\n",
    "    else:\n",
    "        m = 0\n",
    "    \n",
    "\n",
    "            \n",
    "    if m >0 :\n",
    "        return list(set(cat_all1))\n",
    "    else:\n",
    "        if ((type(com)==str)):\n",
    "            if (len(com1)<4):\n",
    "                if ((len(com1)==1) & com1[0].startswith('20')== True):\n",
    "                    return 'swap id'\n",
    "                else:\n",
    "                    return com\n",
    "            else:\n",
    "                return 'NA'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "def currcln(x):\n",
    "    if (type(x)==list):\n",
    "        return x\n",
    "      \n",
    "    else:\n",
    "       \n",
    "        \n",
    "        if x == 'NA':\n",
    "            return \"NA\"\n",
    "        elif (('dollar' in x) | ('dollars' in x )):\n",
    "            return 'dollar'\n",
    "        elif (('pound' in x) | ('pounds' in x)):\n",
    "            return 'pound'\n",
    "        elif ('yen' in x):\n",
    "            return 'yen'\n",
    "        elif ('euro' in x) :\n",
    "            return 'euro'\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "def catcln1(cat,df):\n",
    "    ret = []\n",
    "    if (type(cat)==list):\n",
    "        \n",
    "        if 'equity swap settlement' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'equity swap' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'swap settlement' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'swap unwind' in cat:\n",
    "            ret.append('swap unwind')\n",
    "        #return 'swap unwind'\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "        else:\n",
    "        \n",
    "       \n",
    "            for item in cat:\n",
    "            \n",
    "                a = df[df['Pairing']==item]['replace'].values[0]\n",
    "                if a not in ret:\n",
    "                    ret.append(a)\n",
    "        return list(set(ret))\n",
    "      \n",
    "    else:\n",
    "        return cat\n",
    "\n",
    "def desccat(x):\n",
    "    if isinstance(x, list):\n",
    "        \n",
    "        if 'equity swap settlement' in x:\n",
    "            return 'swap settlement'\n",
    "        elif 'collateral transfer' in x:\n",
    "            return 'collateral transfer'\n",
    "        elif 'dividend' in x:\n",
    "            return 'dividend'\n",
    "        elif (('loan' in x) & ('option' in x)):\n",
    "            return 'option loan'\n",
    "        \n",
    "        elif (('interest' in x) & ('corp' in x) ):\n",
    "            return 'corp loan'\n",
    "        elif (('interest' in x) & ('loan' in x) ):\n",
    "            return 'interest'\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def new_pf_mapping(x):\n",
    "    if x=='GSIL':\n",
    "        return 'GS'\n",
    "    elif x == 'CITIGM':\n",
    "        return 'CITI'\n",
    "    elif x == 'JPMNA':\n",
    "        return 'JPM'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def mhreplaced(item):\n",
    "    word1 = []\n",
    "    word2 = []\n",
    "    if (type(item) == str):\n",
    "    \n",
    "        for items in item.split(' '):\n",
    "            if (type(items) == str):\n",
    "                items = items.lower()\n",
    "                if items.isdigit() == False:\n",
    "                    word1.append(items)\n",
    "        \n",
    "            \n",
    "                for c in word1:\n",
    "                    if c.endswith('MH')==False:\n",
    "                        word2.append(c)\n",
    "    \n",
    "                words = ' '.join(word2)\n",
    "                return words\n",
    "    else:\n",
    "        return item\n",
    "    \n",
    "\n",
    "def fundmatch(item):\n",
    "    items = item.lower()\n",
    "    items = item.replace(' ','') \n",
    "    return items\n",
    "\n",
    "def is_num(item):\n",
    "    try:\n",
    "        float(item)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_date_format(item):\n",
    "    try:\n",
    "        parse(item, fuzzy=False)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def date_edge_cases(item):\n",
    "    if len(item) == 5 and item[2] =='/' and is_num(item[:2]) and is_num(item[3:]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def nan_fun(x):\n",
    "    if x=='nan':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def a_keymatch(a_cusip, a_isin):\n",
    "    \n",
    "    pb_nan = 0\n",
    "    a_common_key = 'NA' \n",
    "    if a_cusip=='nan' and a_isin =='nan':\n",
    "        pb_nan =1\n",
    "    elif(a_cusip!='nan' and a_isin == 'nan'):\n",
    "        a_common_key = a_cusip\n",
    "    elif(a_cusip =='nan' and a_isin !='nan'):\n",
    "        a_common_key = a_isin\n",
    "    else:\n",
    "        a_common_key = a_isin\n",
    "        \n",
    "    return (pb_nan, a_common_key)\n",
    "\n",
    "def b_keymatch(b_cusip, b_isin):\n",
    "    accounting_nan = 0\n",
    "    b_common_key = 'NA'\n",
    "    if b_cusip =='nan' and b_isin =='nan':\n",
    "        accounting_nan =1\n",
    "    elif (b_cusip!='nan' and b_isin == 'nan'):\n",
    "        b_common_key = b_cusip\n",
    "    elif(b_cusip =='nan' and b_isin !='nan'):\n",
    "        b_common_key = b_isin\n",
    "    else:\n",
    "        b_common_key = b_isin\n",
    "    return (accounting_nan, b_common_key)\n",
    "\n",
    "\n",
    "def nan_equals_fun(a,b):\n",
    "    if a==1 and b==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def new_key_match_fun(a,b,c):\n",
    "    if a==b and c==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[text_field] = df[text_field].astype(str)\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x))  \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: re.sub(r\"\\d+\", \"\", x))\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('usd','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('eur0','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' usd','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' euro','')\n",
    "\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' eur','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('eur','')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def umr_seg(X_test):\n",
    "    b_count = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].value_counts().reset_index(name='count')\n",
    "    b_unique = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    \n",
    "    b_unique['len'] = b_unique['Predicted_action'].str.len()\n",
    "    b_count2 = pd.merge(b_count, b_unique.drop('Predicted_action',1), on='SideB.ViewData.Side0_UniqueIds', how='left')\n",
    "    umr_table = b_count2[(b_count2['Predicted_action']=='UMR_One_to_One') & (b_count2['count']==1) & (b_count2['len']<=2)]\n",
    "    return umr_table['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "def normalize_final_no_pair_table_col_names(fun_final_no_pair_table):\n",
    "    final_no_pair_table_col_names_mapping_dict = {\n",
    "                                      'SideA.ViewData.Side1_UniqueIds' : 'ViewData.Side1_UniqueIds',\n",
    "                                      'SideB.ViewData.Side0_UniqueIds' : 'ViewData.Side0_UniqueIds',\n",
    "                                      'SideA.ViewData.BreakID_A_side' : 'ViewData.BreakID_Side1', \n",
    "                                      'SideB.ViewData.BreakID_B_side' : 'ViewData.BreakID_Side0'\n",
    "                                      }\n",
    "    fun_final_no_pair_table.rename(columns = final_no_pair_table_col_names_mapping_dict, inplace = True)\n",
    "    return(fun_final_no_pair_table)\n",
    "\n",
    "def no_pair_seg(X_test):\n",
    "    \n",
    "    b_side_agg = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "    a_side_agg = X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "    \n",
    "    b_side_agg['len'] = b_side_agg['Predicted_action_2'].str.len()\n",
    "    b_side_agg['No_Pair_flag'] = b_side_agg['Predicted_action_2'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "\n",
    "    a_side_agg['len'] = a_side_agg['Predicted_action_2'].str.len()\n",
    "    a_side_agg['No_Pair_flag'] = a_side_agg['Predicted_action_2'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "    \n",
    "    no_pair_ids_b_side = b_side_agg[(b_side_agg['len']==1) & (b_side_agg['No_Pair_flag']==1)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "    no_pair_ids_a_side = a_side_agg[(a_side_agg['len']==1) & (a_side_agg['No_Pair_flag']==1)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "    \n",
    "    return no_pair_ids_b_side, no_pair_ids_a_side\n",
    " \n",
    "def subSum(numbers,total):\n",
    "    for length in range(1, 3):\n",
    "        if len(numbers) < length or length < 1:\n",
    "            return []\n",
    "        for index,number in enumerate(numbers):\n",
    "            if length == 1 and np.isclose(number, total,atol=0.25).any():\n",
    "                return [number]\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset: \n",
    "                return [number] + subset\n",
    "        return []\n",
    "\n",
    "def one_to_one_umb(data):\n",
    "    \n",
    "    count = data['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count0')\n",
    "    id0s = count[count['count0']==1]['index'].unique()\n",
    "    id1s = data[data['SideB.ViewData.Side0_UniqueIds'].isin(id0s)]['SideA.ViewData.Side1_UniqueIds']\n",
    "    \n",
    "    count1 = data['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count1')\n",
    "    final_ids = count1[(count1['count1']==1) & (count1['index'].isin(id1s))]['index'].unique()\n",
    "    return final_ids\n",
    "\n",
    "def no_pair_seg2(X_test):\n",
    "    \n",
    "    b_side_agg = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    a_side_agg = X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    \n",
    "    b_side_agg['len'] = b_side_agg['Predicted_action'].str.len()\n",
    "    b_side_agg['No_Pair_flag'] = b_side_agg['Predicted_action'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "\n",
    "    a_side_agg['len'] = a_side_agg['Predicted_action'].str.len()\n",
    "    a_side_agg['No_Pair_flag'] = a_side_agg['Predicted_action'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "    \n",
    "    no_pair_ids_b_side = b_side_agg[(b_side_agg['len']==1) & (b_side_agg['No_Pair_flag']==1)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "    no_pair_ids_a_side = a_side_agg[(a_side_agg['len']==1) & (a_side_agg['No_Pair_flag']==1)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "    \n",
    "    return no_pair_ids_b_side, no_pair_ids_a_side\n",
    "\n",
    "def return_int_list(list_x):\n",
    "    return [int(i) for i in list_x]\n",
    "    \n",
    "def normalize_bp_acct_col_names(fun_df):\n",
    "    bp_acct_col_names_mapping_dict = {\n",
    "                                      'ViewData.Cust Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.Cust Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.Cust Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.CP Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.CP Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.CP Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.PMSVendor Net Amount' : 'ViewData.Accounting Net Amount'\n",
    "                                        }\n",
    "    fun_df.rename(columns = bp_acct_col_names_mapping_dict, inplace = True)\n",
    "    return(fun_df)\n",
    "\n",
    "def find_BreakID_and_other_cols_in_meo_for_Side_0_1_UniqueIds_value(fun_string_value_of_Side_0_1_UniqueIds, fun_meo_df, fun_side, fun_other_cols_list = None):\n",
    "    if fun_other_cols_list is None:\n",
    "        all_cols_to_find = ['ViewData.BreakID']\n",
    "    else:\n",
    "        all_cols_to_find = fun_other_cols_list + ['ViewData.BreakID']\n",
    "    if(fun_side == 0):\n",
    "        return(fun_meo_df[fun_meo_df['ViewData.Side0_UniqueIds'] == fun_string_value_of_Side_0_1_UniqueIds][all_cols_to_find])\n",
    "    elif(fun_side == 1):\n",
    "        return(fun_meo_df[fun_meo_df['ViewData.Side1_UniqueIds'] == fun_string_value_of_Side_0_1_UniqueIds][all_cols_to_find])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def contains_multiple_values_in_either_Side_0_or_1_UniqueIds_for_expected_single_sided_status(fun_row):\n",
    "    \n",
    "    if(',' in str(fun_row['ViewData.Side0_UniqueIds'])):\n",
    "        Side_0_contains_comma = 1\n",
    "    else:\n",
    "        Side_0_contains_comma = 0\n",
    "\n",
    "    if(',' in str(fun_row['ViewData.Side1_UniqueIds'])):\n",
    "        Side_1_contains_comma = 1\n",
    "    else:\n",
    "        Side_1_contains_comma = 0\n",
    "    \n",
    "    if((str(fun_row['ViewData.Status']) in ['OB','SDB','UOB','CNF','CMF']) and ((Side_0_contains_comma == 1) or (Side_1_contains_comma == 1))):\n",
    "        return('remove')\n",
    "    else:\n",
    "        return('keep')\n",
    "\n",
    "def find_Side_0_1_UniqueIds_and_other_cols_in_meo_for_BreakID_value(fun_string_value_of_BreakID,fun_meo_df,fun_other_cols_list = None):\n",
    "    if fun_other_cols_list is None:\n",
    "        all_cols_to_find = ['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData.Status']\n",
    "    else:\n",
    "        all_cols_to_find = fun_other_cols_list + ['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData.Status']\n",
    "    fun_meo_df['ViewData.BreakID'] = fun_meo_df['ViewData.BreakID'].astype(str)\n",
    "    return(fun_meo_df[fun_meo_df['ViewData.BreakID'] == fun_string_value_of_BreakID][all_cols_to_find])\n",
    "\n",
    "def make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side):\n",
    "#    print(row)\n",
    "\n",
    "    if(fun_side == 0):\n",
    "        if(row['Side0_UniqueIds_OB'] == ''):\n",
    "            return(row['Side0_UniqueIds_SMB'])\n",
    "        else:\n",
    "            return(row['Side0_UniqueIds_OB'] + ',' + row['Side0_UniqueIds_SMB'])\n",
    "    elif(fun_side == 1):\n",
    "        if(row['Side1_UniqueIds_OB'] == ''):\n",
    "            return(row['Side1_UniqueIds_SMB'])\n",
    "        else:\n",
    "            return(row['Side1_UniqueIds_OB'] + ',' + row['Side1_UniqueIds_SMB'])\n",
    "    \n",
    "def make_Side0_Side1_columns_for_final_smb_ob_table(fun_final_smb_ob_table, fun_meo_df):\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side0_UniqueIds']], left_on = 'BreakID_OB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side0_UniqueIds' : 'Side0_UniqueIds_OB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side1_UniqueIds']], left_on = 'BreakID_OB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side1_UniqueIds' : 'Side1_UniqueIds_OB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side0_UniqueIds']], left_on = 'BreakID_SMB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side0_UniqueIds' : 'Side0_UniqueIds_SMB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side1_UniqueIds']], left_on = 'BreakID_SMB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side1_UniqueIds' : 'Side1_UniqueIds_SMB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].astype(str)            \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].replace('None','')            \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].replace('nan','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].replace('nan','')\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].replace('nan','') \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].replace('nan','')\n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds'] = fun_final_smb_ob_table.apply(lambda row : make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side = 0),axis = 1,result_type=\"expand\")\n",
    "    fun_final_smb_ob_table['Side1_UniqueIds'] = fun_final_smb_ob_table.apply(lambda row : make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side = 1),axis = 1,result_type=\"expand\")\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side0_UniqueIds_OB'] == '', 'Side0_UniqueIds'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side0_UniqueIds_OB'] != '', 'Side0_UniqueIds'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'] + fun_final_smb_ob_table['Side0_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side1_UniqueIds_OB'] == '', 'Side1_UniqueIds'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side1_UniqueIds_OB'] != '', 'Side1_UniqueIds'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'] + fun_final_smb_ob_table['Side1_UniqueIds_SMB']\n",
    "\n",
    "    fun_final_smb_ob_table.drop(['Side0_UniqueIds_OB','Side1_UniqueIds_OB','Side0_UniqueIds_SMB','Side1_UniqueIds_SMB'], axis = 1, inplace = True)\n",
    "\n",
    "    return(fun_final_smb_ob_table)\n",
    "\n",
    "\n",
    "date_numbers_list = [16]\n",
    "                     #2,3,4,\n",
    "                    # 7,8,9,10,11,\n",
    "                    # 14,15,16,17,18,\n",
    "                    # 21,22,23,24,25,\n",
    "                    # 28,29,30]\n",
    "\n",
    "client = 'OakTree'\n",
    "\n",
    "setup_code = '379'\n",
    "\n",
    "today = date.today()\n",
    "d1 = datetime.strptime(today.strftime(\"%Y-%m-%d\"),\"%Y-%m-%d\")\n",
    "desired_date = d1 - timedelta(days=4)\n",
    "desired_date_str = desired_date.strftime(\"%Y-%m-%d\")\n",
    "date_input = desired_date_str\n",
    "\n",
    "#filepaths_AUA = '//vitblrdevcons01/Raman  Strategy ML 2.0/All_Data/' + client + '/JuneData/AUA/AUACollections.AUA_HST_RecData_' + setup_code + '_' + str(date_input) + '.csv'\n",
    "#filepaths_MEO = '//vitblrdevcons01/Raman  Strategy ML 2.0/All_Data/' + client + '/JuneData/MEO/MeoCollections.MEO_HST_RecData_' + setup_code + '_' + str(date_input) + '.csv'\n",
    "filepaths_no_pair_id_data = '//vitblrdevcons01/Raman  Strategy ML 2.0/All_Data/' + client + '/UAT_Run/X_Test_' + setup_code + '/no_pair_ids_' + setup_code + '_' + str(date_input) + '.csv'\n",
    "filepaths_no_pair_id_no_data_warning = '//vitblrdevcons01/Raman  Strategy ML 2.0/All_Data/' + client + '/UAT_Run/X_Test_' + setup_code + '/WARNING_no_pair_ids_' + setup_code + str(date_input) + '.csv'\n",
    "\n",
    "\n",
    "mngdb_obj_1_for_reading_and_writing_in_uat_server = mngdb(param_without_ssh  = True, param_without_RabbitMQ_pipeline = True,\n",
    "                 param_SSH_HOST = None, param_SSH_PORT = None,\n",
    "                 param_SSH_USERNAME = None, param_SSH_PASSWORD = None,\n",
    "                 param_MONGO_HOST = '10.1.15.137', param_MONGO_PORT = 27017,\n",
    "                 param_MONGO_USERNAME = 'mongouseradmin', param_MONGO_PASSWORD = '@L0ck&Key')\n",
    "mngdb_obj_1_for_reading_and_writing_in_uat_server.connect_with_or_without_ssh()\n",
    "db_1_for_MEO_data = mngdb_obj_1_for_reading_and_writing_in_uat_server.client['ReconDB_ML']\n",
    "\n",
    "\n",
    "query_1_for_MEO_data = db_1_for_MEO_data['RecData_' + setup_code].find({ \n",
    "                                                                     \"LastPerformedAction\": 31\n",
    "                                                             },\n",
    "                                                             {\n",
    "                                                                     \"DataSides\" : 1,\n",
    "                                                                     \"BreakID\" : 1,\n",
    "                                                                     \"LastPerformedAction\" : 1,\n",
    "                                                                     \"TaskInstanceID\" : 1,\n",
    "                                                                     \"SourceCombinationCode\" : 1,\n",
    "                                                                     \"MetaData\" : 1, \n",
    "                                                                     \"ViewData\" : 1\n",
    "                                                             })\n",
    "list_of_dicts_query_result_1 = list(query_1_for_MEO_data)\n",
    "\n",
    "meo_df = json_normalize(list_of_dicts_query_result_1)\n",
    "meo_df = meo_df.loc[:,meo_df.columns.str.startswith('ViewData')]\n",
    "meo_df['ViewData.Task Business Date'] = meo_df['ViewData.Task Business Date'].apply(dt.datetime.isoformat) \n",
    "print(meo_df.shape[0])\n",
    "meo_df.drop_duplicates(keep=False, inplace = True)\n",
    "meo_df = normalize_bp_acct_col_names(fun_df = meo_df)\n",
    "\n",
    "#Change added on 17-12-2020 to remove records with multiple values of Side0 and Side1 UniqueIds for statuses like OB,UOB,SDB,CNF and CMF. Typically, these statuses should have single values in Side0 and Side1 UniqueIds. So records not following expected behviour are removed\n",
    "\n",
    "meo_df['remove_or_keep_for_multiple_uniqueids_in_ob_issue'] = meo_df.apply(lambda row : contains_multiple_values_in_either_Side_0_or_1_UniqueIds_for_expected_single_sided_status(fun_row = row), axis = 1,result_type=\"expand\")\n",
    "meo_df = meo_df[~(meo_df['remove_or_keep_for_multiple_uniqueids_in_ob_issue'] == 'remove')]\n",
    "\n",
    "meo = meo_df[new_cols]\n",
    "print('meo size')\n",
    "print(meo.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "umb_carry_forward_df = meo_df[meo_df['ViewData.Status'] == 'UMB']\n",
    "\n",
    "meo_df_taskids = list(meo_df['ViewData.Task ID'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant136\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\consultant136\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import sys\n",
    "#from ViteosMongoDB import  ViteosMongoDB_Class as mngdb\n",
    "from datetime import datetime,date,timedelta\n",
    "from pandas.io.json import json_normalize\n",
    "import dateutil.parser\n",
    "from difflib import SequenceMatcher\n",
    "import pprint\n",
    "import json\n",
    "from pandas import merge\n",
    "import re\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dateutil.parser import parse\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import random\n",
    "import decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\consultant136\\\\ML1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "meo = pd.read_csv('meo_df_setup_379_date_2020-12-08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = ['ViewData.Accounting Net Amount', 'ViewData.Age',\n",
    "'ViewData.Age WK', 'ViewData.Asset Type Category',\n",
    "'ViewData.B-P Net Amount', 'ViewData.Base Net Amount','ViewData.CUSIP', \n",
    " 'ViewData.Cancel Amount',\n",
    "       'ViewData.Cancel Flag',\n",
    "#'ViewData.Commission',\n",
    "        'ViewData.Currency', 'ViewData.Custodian',\n",
    "       'ViewData.Custodian Account',\n",
    "       'ViewData.Description','ViewData.Department', 'ViewData.ExpiryDate', 'ViewData.Fund',\n",
    "       'ViewData.ISIN',\n",
    "       'ViewData.Investment Type',\n",
    "      # 'ViewData.Keys',\n",
    "       'ViewData.Mapped Custodian Account',\n",
    "       'ViewData.Net Amount Difference',\n",
    "       'ViewData.Net Amount Difference Absolute',\n",
    "        #'ViewData.OTE Ticker',\n",
    "        'ViewData.Price',\n",
    "       'ViewData.Prime Broker', 'ViewData.Quantity',\n",
    "       'ViewData.SEDOL', 'ViewData.SPM ID', 'ViewData.Settle Date',\n",
    "       \n",
    "  #  'ViewData.Strike Price',\n",
    "               'Date',\n",
    "       'ViewData.Ticker', 'ViewData.Trade Date',\n",
    "       'ViewData.Transaction Category',\n",
    "       'ViewData.Transaction Type', 'ViewData.Underlying Cusip',\n",
    "       'ViewData.Underlying ISIN',\n",
    "       'ViewData.Underlying Sedol','filter_key','ViewData.Status','ViewData.BreakID',\n",
    "              'ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData._ID']\n",
    "\n",
    "model_cols = [\n",
    "            'SideA.ViewData.B-P Net Amount', \n",
    "              #'SideA.ViewData.Cancel Flag', \n",
    "              #'SideA.new_desc_cat',\n",
    "             # 'SideA.ViewData.Description',\n",
    "             # 'SideA.ViewData.Department',\n",
    "   \n",
    "    \n",
    "              \n",
    "             # 'SideA.ViewData.Price',\n",
    "             # 'SideA.ViewData.Quantity',\n",
    "             #'SideA.ViewData.Investment Type', \n",
    "              #'SideA.ViewData.Asset Type Category', \n",
    "              'SideB.ViewData.Accounting Net Amount', \n",
    "              #'SideB.ViewData.Cancel Flag', \n",
    "             # 'SideB.ViewData.Description',\n",
    "              # 'SideB.ViewData.Department',\n",
    "              \n",
    "             # 'SideB.ViewData.Price',\n",
    "             # 'SideB.ViewData.Quantity',\n",
    "             # 'SideB.new_desc_cat',\n",
    "             # 'SideB.ViewData.Investment Type', \n",
    "              #'SideB.ViewData.Asset Type Category', \n",
    "              'Trade_Date_match', 'Settle_Date_match', \n",
    "                'Amount_diff_2', \n",
    "              'Trade_date_diff', 'Settle_date_diff', 'SideA.ISIN_NA', 'SideB.ISIN_NA', \n",
    "             # 'ViewData.Combined Fund',\n",
    "              'ViewData.Combined Transaction Type', 'Combined_Desc','Combined_TType',\n",
    "             # 'SideA.TType', 'SideB.TType', \n",
    "              'abs_amount_flag',\n",
    "    'tt_map_flag', \n",
    "              'All_key_nan','new_key_match', 'new_pb1',\n",
    "              'SideB.Date','SideA.ViewData.Settle Date','SideB.ViewData.Settle Date',\n",
    "            'SideA.ViewData._ID', 'SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds', 'SideA.ViewData.Side1_UniqueIds',\n",
    "              'SideB.ViewData.Status', 'SideB.ViewData.BreakID_B_side',\n",
    "              'SideA.ViewData.Status', 'SideA.ViewData.BreakID_A_side'] \n",
    "              #'label']\n",
    "\n",
    "model_cols_2 =[#'SideA.ViewData.B-P Net Amount', \n",
    "              #'SideA.ViewData.Cancel Flag', \n",
    "              #'SideA.new_desc_cat',\n",
    "             # 'SideA.ViewData.Description',\n",
    "             # 'SideA.ViewData.Department',\n",
    "   \n",
    "    \n",
    "              \n",
    "             # 'SideA.ViewData.Price',\n",
    "             # 'SideA.ViewData.Quantity',\n",
    "             #'SideA.ViewData.Investment Type', \n",
    "              #'SideA.ViewData.Asset Type Category', \n",
    "              #'SideB.ViewData.Accounting Net Amount', \n",
    "              #'SideB.ViewData.Cancel Flag', \n",
    "             # 'SideB.ViewData.Description',\n",
    "              # 'SideB.ViewData.Department',\n",
    "              \n",
    "             # 'SideB.ViewData.Price',\n",
    "             # 'SideB.ViewData.Quantity',\n",
    "             # 'SideB.new_desc_cat',\n",
    "             # 'SideB.ViewData.Investment Type', \n",
    "              #'SideB.ViewData.Asset Type Category', \n",
    "              'Trade_Date_match', 'Settle_Date_match', \n",
    "              #  'Amount_diff_2', \n",
    "              'Trade_date_diff', 'Settle_date_diff', 'SideA.ISIN_NA', 'SideB.ISIN_NA', \n",
    "             # 'ViewData.Combined Fund',\n",
    "              'ViewData.Combined Transaction Type', 'Combined_Desc','Combined_TType',\n",
    "             # 'SideA.TType', 'SideB.TType', \n",
    "              'abs_amount_flag',\n",
    "    'tt_map_flag', \n",
    "              'All_key_nan','new_key_match', 'new_pb1',\n",
    "              'SideB.Date','SideA.ViewData.Settle Date','SideB.ViewData.Settle Date',\n",
    "            'SideA.ViewData._ID', 'SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds', 'SideA.ViewData.Side1_UniqueIds',\n",
    "              'SideB.ViewData.Status', 'SideB.ViewData.BreakID_B_side',\n",
    "              'SideA.ViewData.Status', 'SideA.ViewData.BreakID_A_side'] \n",
    "              #'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Break Prediction functions - Begin #### \n",
    "\n",
    "def equals_fun(a,b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vec_equals_fun = np.vectorize(equals_fun)\n",
    "\n",
    "\n",
    "def descclean(com,cat_list):\n",
    "    cat_all1 = []\n",
    "    list1 = cat_list\n",
    "    m = 0\n",
    "    if (type(com) == str):\n",
    "        com = com.lower()\n",
    "        com1 =  re.split(\"[,/. \\-!?:]+\", com)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for item in list1:\n",
    "            if (type(item) == str):\n",
    "                item = item.lower()\n",
    "                item1 = item.split(' ')\n",
    "                lst3 = [value for value in item1 if value in com1] \n",
    "                if len(lst3) == len(item1):\n",
    "                    cat_all1.append(item)\n",
    "                    m = m+1\n",
    "            \n",
    "                else:\n",
    "                    m = m\n",
    "            else:\n",
    "                    m = 0\n",
    "    else:\n",
    "        m = 0\n",
    "    \n",
    "\n",
    "            \n",
    "    if m >0 :\n",
    "        return list(set(cat_all1))\n",
    "    else:\n",
    "        if ((type(com)==str)):\n",
    "            if (len(com1)<4):\n",
    "                if ((len(com1)==1) & com1[0].startswith('20')== True):\n",
    "                    return 'swap id'\n",
    "                else:\n",
    "                    return com\n",
    "            else:\n",
    "                return 'NA'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "def currcln(x):\n",
    "    if (type(x)==list):\n",
    "        return x\n",
    "      \n",
    "    else:\n",
    "       \n",
    "        \n",
    "        if x == 'NA':\n",
    "            return \"NA\"\n",
    "        elif (('dollar' in x) | ('dollars' in x )):\n",
    "            return 'dollar'\n",
    "        elif (('pound' in x) | ('pounds' in x)):\n",
    "            return 'pound'\n",
    "        elif ('yen' in x):\n",
    "            return 'yen'\n",
    "        elif ('euro' in x) :\n",
    "            return 'euro'\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "def catcln1(cat,df):\n",
    "    ret = []\n",
    "    if (type(cat)==list):\n",
    "        \n",
    "        if 'equity swap settlement' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'equity swap' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'swap settlement' in cat:\n",
    "            ret.append('equity swap settlement')\n",
    "        #return 'equity swap settlement'\n",
    "        elif 'swap unwind' in cat:\n",
    "            ret.append('swap unwind')\n",
    "        #return 'swap unwind'\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "        else:\n",
    "        \n",
    "       \n",
    "            for item in cat:\n",
    "            \n",
    "                a = df[df['Pairing']==item]['replace'].values[0]\n",
    "                if a not in ret:\n",
    "                    ret.append(a)\n",
    "        return list(set(ret))\n",
    "      \n",
    "    else:\n",
    "        return cat\n",
    "\n",
    "def desccat(x):\n",
    "    if isinstance(x, list):\n",
    "        \n",
    "        if 'equity swap settlement' in x:\n",
    "            return 'swap settlement'\n",
    "        elif 'collateral transfer' in x:\n",
    "            return 'collateral transfer'\n",
    "        elif 'dividend' in x:\n",
    "            return 'dividend'\n",
    "        elif (('loan' in x) & ('option' in x)):\n",
    "            return 'option loan'\n",
    "        \n",
    "        elif (('interest' in x) & ('corp' in x) ):\n",
    "            return 'corp loan'\n",
    "        elif (('interest' in x) & ('loan' in x) ):\n",
    "            return 'interest'\n",
    "        else:\n",
    "            return x[0]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def new_pf_mapping(x):\n",
    "    if x=='GSIL':\n",
    "        return 'GS'\n",
    "    elif x == 'CITIGM':\n",
    "        return 'CITI'\n",
    "    elif x == 'JPMNA':\n",
    "        return 'JPM'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def mhreplaced(item):\n",
    "    word1 = []\n",
    "    word2 = []\n",
    "    if (type(item) == str):\n",
    "    \n",
    "        for items in item.split(' '):\n",
    "            if (type(items) == str):\n",
    "                items = items.lower()\n",
    "                if items.isdigit() == False:\n",
    "                    word1.append(items)\n",
    "        \n",
    "            \n",
    "                for c in word1:\n",
    "                    if c.endswith('MH')==False:\n",
    "                        word2.append(c)\n",
    "    \n",
    "                words = ' '.join(word2)\n",
    "                return words\n",
    "    else:\n",
    "        return item\n",
    "    \n",
    "\n",
    "def fundmatch(item):\n",
    "    items = item.lower()\n",
    "    items = item.replace(' ','') \n",
    "    return items\n",
    "\n",
    "def is_num(item):\n",
    "    try:\n",
    "        float(item)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_date_format(item):\n",
    "    try:\n",
    "        parse(item, fuzzy=False)\n",
    "        return True\n",
    "    \n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def date_edge_cases(item):\n",
    "    if len(item) == 5 and item[2] =='/' and is_num(item[:2]) and is_num(item[3:]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def nan_fun(x):\n",
    "    if x=='nan':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def a_keymatch(a_cusip, a_isin):\n",
    "    \n",
    "    pb_nan = 0\n",
    "    a_common_key = 'NA' \n",
    "    if a_cusip=='nan' and a_isin =='nan':\n",
    "        pb_nan =1\n",
    "    elif(a_cusip!='nan' and a_isin == 'nan'):\n",
    "        a_common_key = a_cusip\n",
    "    elif(a_cusip =='nan' and a_isin !='nan'):\n",
    "        a_common_key = a_isin\n",
    "    else:\n",
    "        a_common_key = a_isin\n",
    "        \n",
    "    return (pb_nan, a_common_key)\n",
    "\n",
    "def b_keymatch(b_cusip, b_isin):\n",
    "    accounting_nan = 0\n",
    "    b_common_key = 'NA'\n",
    "    if b_cusip =='nan' and b_isin =='nan':\n",
    "        accounting_nan =1\n",
    "    elif (b_cusip!='nan' and b_isin == 'nan'):\n",
    "        b_common_key = b_cusip\n",
    "    elif(b_cusip =='nan' and b_isin !='nan'):\n",
    "        b_common_key = b_isin\n",
    "    else:\n",
    "        b_common_key = b_isin\n",
    "    return (accounting_nan, b_common_key)\n",
    "\n",
    "\n",
    "def nan_equals_fun(a,b):\n",
    "    if a==1 and b==1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def new_key_match_fun(a,b,c):\n",
    "    if a==b and c==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[text_field] = df[text_field].astype(str)\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x))  \n",
    "    # remove numbers\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: re.sub(r\"\\d+\", \"\", x))\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('usd','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('eur0','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' usd','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' euro','')\n",
    "\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace(' eur','')\n",
    "    df[new_text_field_name] = df[new_text_field_name].str.replace('eur','')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def umr_seg(X_test):\n",
    "    b_count = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].value_counts().reset_index(name='count')\n",
    "    b_unique = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    \n",
    "    b_unique['len'] = b_unique['Predicted_action'].str.len()\n",
    "    b_count2 = pd.merge(b_count, b_unique.drop('Predicted_action',1), on='SideB.ViewData.Side0_UniqueIds', how='left')\n",
    "    umr_table = b_count2[(b_count2['Predicted_action']=='UMR_One_to_One') & (b_count2['count']==1) & (b_count2['len']<=2)]\n",
    "    return umr_table['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "def normalize_final_no_pair_table_col_names(fun_final_no_pair_table):\n",
    "    final_no_pair_table_col_names_mapping_dict = {\n",
    "                                      'SideA.ViewData.Side1_UniqueIds' : 'ViewData.Side1_UniqueIds',\n",
    "                                      'SideB.ViewData.Side0_UniqueIds' : 'ViewData.Side0_UniqueIds',\n",
    "                                      'SideA.ViewData.BreakID_A_side' : 'ViewData.BreakID_Side1', \n",
    "                                      'SideB.ViewData.BreakID_B_side' : 'ViewData.BreakID_Side0'\n",
    "                                      }\n",
    "    fun_final_no_pair_table.rename(columns = final_no_pair_table_col_names_mapping_dict, inplace = True)\n",
    "    return(fun_final_no_pair_table)\n",
    "\n",
    "def no_pair_seg(X_test):\n",
    "    \n",
    "    b_side_agg = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "    a_side_agg = X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "    \n",
    "    b_side_agg['len'] = b_side_agg['Predicted_action_2'].str.len()\n",
    "    b_side_agg['No_Pair_flag'] = b_side_agg['Predicted_action_2'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "\n",
    "    a_side_agg['len'] = a_side_agg['Predicted_action_2'].str.len()\n",
    "    a_side_agg['No_Pair_flag'] = a_side_agg['Predicted_action_2'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "    \n",
    "    no_pair_ids_b_side = b_side_agg[(b_side_agg['len']==1) & (b_side_agg['No_Pair_flag']==1)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "    no_pair_ids_a_side = a_side_agg[(a_side_agg['len']==1) & (a_side_agg['No_Pair_flag']==1)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "    \n",
    "    return no_pair_ids_b_side, no_pair_ids_a_side\n",
    " \n",
    "def subSum(numbers,total):\n",
    "    for length in range(1, 3):\n",
    "        if len(numbers) < length or length < 1:\n",
    "            return []\n",
    "        for index,number in enumerate(numbers):\n",
    "            if length == 1 and np.isclose(number, total,atol=0.25).any():\n",
    "                return [number]\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset: \n",
    "                return [number] + subset\n",
    "        return []\n",
    "\n",
    "def one_to_one_umb(data):\n",
    "    \n",
    "    count = data['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count0')\n",
    "    id0s = count[count['count0']==1]['index'].unique()\n",
    "    id1s = data[data['SideB.ViewData.Side0_UniqueIds'].isin(id0s)]['SideA.ViewData.Side1_UniqueIds']\n",
    "    \n",
    "    count1 = data['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count1')\n",
    "    final_ids = count1[(count1['count1']==1) & (count1['index'].isin(id1s))]['index'].unique()\n",
    "    return final_ids\n",
    "\n",
    "def no_pair_seg2(X_test):\n",
    "    \n",
    "    b_side_agg = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    a_side_agg = X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action'].unique().reset_index()\n",
    "    \n",
    "    b_side_agg['len'] = b_side_agg['Predicted_action'].str.len()\n",
    "    b_side_agg['No_Pair_flag'] = b_side_agg['Predicted_action'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "\n",
    "    a_side_agg['len'] = a_side_agg['Predicted_action'].str.len()\n",
    "    a_side_agg['No_Pair_flag'] = a_side_agg['Predicted_action'].apply(lambda x: 1 if 'No-Pair' in x else 0)\n",
    "    \n",
    "    no_pair_ids_b_side = b_side_agg[(b_side_agg['len']==1) & (b_side_agg['No_Pair_flag']==1)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "\n",
    "    no_pair_ids_a_side = a_side_agg[(a_side_agg['len']==1) & (a_side_agg['No_Pair_flag']==1)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "    \n",
    "    return no_pair_ids_b_side, no_pair_ids_a_side\n",
    "\n",
    "def return_int_list(list_x):\n",
    "    return [int(i) for i in list_x]\n",
    "    \n",
    "def normalize_bp_acct_col_names(fun_df):\n",
    "    bp_acct_col_names_mapping_dict = {\n",
    "                                      'ViewData.Cust Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.Cust Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.Cust Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.CP Net Amount' : 'ViewData.B-P Net Amount',\n",
    "                                      'ViewData.CP Net Amount Difference' : 'ViewData.B-P Net Amount Difference',\n",
    "                                      'ViewData.CP Net Amount Difference Absolute' : 'ViewData.B-P Net Amount Difference Absolute',\n",
    "                                      'ViewData.PMSVendor Net Amount' : 'ViewData.Accounting Net Amount'\n",
    "                                        }\n",
    "    fun_df.rename(columns = bp_acct_col_names_mapping_dict, inplace = True)\n",
    "    return(fun_df)\n",
    "\n",
    "def find_BreakID_and_other_cols_in_meo_for_Side_0_1_UniqueIds_value(fun_string_value_of_Side_0_1_UniqueIds, fun_meo_df, fun_side, fun_other_cols_list = None):\n",
    "    if fun_other_cols_list is None:\n",
    "        all_cols_to_find = ['ViewData.BreakID']\n",
    "    else:\n",
    "        all_cols_to_find = fun_other_cols_list + ['ViewData.BreakID']\n",
    "    if(fun_side == 0):\n",
    "        return(fun_meo_df[fun_meo_df['ViewData.Side0_UniqueIds'] == fun_string_value_of_Side_0_1_UniqueIds][all_cols_to_find])\n",
    "    elif(fun_side == 1):\n",
    "        return(fun_meo_df[fun_meo_df['ViewData.Side1_UniqueIds'] == fun_string_value_of_Side_0_1_UniqueIds][all_cols_to_find])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def contains_multiple_values_in_either_Side_0_or_1_UniqueIds_for_expected_single_sided_status(fun_row):\n",
    "    \n",
    "    if(',' in str(fun_row['ViewData.Side0_UniqueIds'])):\n",
    "        Side_0_contains_comma = 1\n",
    "    else:\n",
    "        Side_0_contains_comma = 0\n",
    "\n",
    "    if(',' in str(fun_row['ViewData.Side1_UniqueIds'])):\n",
    "        Side_1_contains_comma = 1\n",
    "    else:\n",
    "        Side_1_contains_comma = 0\n",
    "    \n",
    "    if((str(fun_row['ViewData.Status']) in ['OB','SDB','UOB','CNF','CMF']) and ((Side_0_contains_comma == 1) or (Side_1_contains_comma == 1))):\n",
    "        return('remove')\n",
    "    else:\n",
    "        return('keep')\n",
    "\n",
    "def find_Side_0_1_UniqueIds_and_other_cols_in_meo_for_BreakID_value(fun_string_value_of_BreakID,fun_meo_df,fun_other_cols_list = None):\n",
    "    if fun_other_cols_list is None:\n",
    "        all_cols_to_find = ['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData.Status']\n",
    "    else:\n",
    "        all_cols_to_find = fun_other_cols_list + ['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','ViewData.Status']\n",
    "    fun_meo_df['ViewData.BreakID'] = fun_meo_df['ViewData.BreakID'].astype(str)\n",
    "    return(fun_meo_df[fun_meo_df['ViewData.BreakID'] == fun_string_value_of_BreakID][all_cols_to_find])\n",
    "\n",
    "def make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side):\n",
    "#    print(row)\n",
    "\n",
    "    if(fun_side == 0):\n",
    "        if(row['Side0_UniqueIds_OB'] == ''):\n",
    "            return(row['Side0_UniqueIds_SMB'])\n",
    "        else:\n",
    "            return(row['Side0_UniqueIds_OB'] + ',' + row['Side0_UniqueIds_SMB'])\n",
    "    elif(fun_side == 1):\n",
    "        if(row['Side1_UniqueIds_OB'] == ''):\n",
    "            return(row['Side1_UniqueIds_SMB'])\n",
    "        else:\n",
    "            return(row['Side1_UniqueIds_OB'] + ',' + row['Side1_UniqueIds_SMB'])\n",
    "    \n",
    "def make_Side0_Side1_columns_for_final_smb_ob_table(fun_final_smb_ob_table, fun_meo_df):\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side0_UniqueIds']], left_on = 'BreakID_OB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side0_UniqueIds' : 'Side0_UniqueIds_OB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side1_UniqueIds']], left_on = 'BreakID_OB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side1_UniqueIds' : 'Side1_UniqueIds_OB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side0_UniqueIds']], left_on = 'BreakID_SMB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side0_UniqueIds' : 'Side0_UniqueIds_SMB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table = pd.merge(fun_final_smb_ob_table,fun_meo_df[['ViewData.BreakID','ViewData.Side1_UniqueIds']], left_on = 'BreakID_SMB', right_on = 'ViewData.BreakID')\n",
    "    fun_final_smb_ob_table.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    fun_final_smb_ob_table.rename(columns = {'ViewData.Side1_UniqueIds' : 'Side1_UniqueIds_SMB'}, inplace = True) \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].astype(str)            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].astype(str)            \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].replace('None','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].replace('None','')            \n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_OB'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'].replace('nan','')            \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_OB'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'].replace('nan','')\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds_SMB'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB'].replace('nan','') \n",
    "    fun_final_smb_ob_table['Side1_UniqueIds_SMB'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB'].replace('nan','')\n",
    "\n",
    "    fun_final_smb_ob_table['Side0_UniqueIds'] = fun_final_smb_ob_table.apply(lambda row : make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side = 0),axis = 1,result_type=\"expand\")\n",
    "    fun_final_smb_ob_table['Side1_UniqueIds'] = fun_final_smb_ob_table.apply(lambda row : make_Side0_Side1_columns_for_final_smb_ob_table_row_apply(row, fun_side = 1),axis = 1,result_type=\"expand\")\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side0_UniqueIds_OB'] == '', 'Side0_UniqueIds'] = fun_final_smb_ob_table['Side0_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side0_UniqueIds_OB'] != '', 'Side0_UniqueIds'] = fun_final_smb_ob_table['Side0_UniqueIds_OB'] + fun_final_smb_ob_table['Side0_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side1_UniqueIds_OB'] == '', 'Side1_UniqueIds'] = fun_final_smb_ob_table['Side1_UniqueIds_SMB']\n",
    "#    fun_final_smb_ob_table.iloc[fun_final_smb_ob_table['Side1_UniqueIds_OB'] != '', 'Side1_UniqueIds'] = fun_final_smb_ob_table['Side1_UniqueIds_OB'] + fun_final_smb_ob_table['Side1_UniqueIds_SMB']\n",
    "\n",
    "    fun_final_smb_ob_table.drop(['Side0_UniqueIds_OB','Side1_UniqueIds_OB','Side0_UniqueIds_SMB','Side1_UniqueIds_SMB'], axis = 1, inplace = True)\n",
    "\n",
    "    return(fun_final_smb_ob_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change made on 12-12-2020 as per Pratik to catch instances where a single SMB pairs off with a single OB. BreakIDs caught in this code piece will be removed from propogating down further. Also, these BreakIDs will be given the status of UMR with Predicted_action of UMR_One-Many_to_Many-One\n",
    "#Begin change code made on 12-12-2020\n",
    "meo2 = meo[meo['ViewData.Status'].isin(['OB','SMB','SPM','UMB'])]\n",
    "meo2 = meo2.reset_index().drop('index',1)\n",
    "\n",
    "meo2['ViewData.Net Amount Difference Absolute'] = np.round(meo2['ViewData.Net Amount Difference Absolute'],2)\n",
    "\n",
    "abs_amount_count = meo2['ViewData.Net Amount Difference Absolute'].value_counts().reset_index()\n",
    "\n",
    "duplicate_amount = abs_amount_count[abs_amount_count['ViewData.Net Amount Difference Absolute']==2]\n",
    "duplicate_amount.columns = ['ViewData.Net Amount Difference Absolute','count']\n",
    "duplicate_amount = duplicate_amount.reset_index().drop('index',1)\n",
    "\n",
    "if duplicate_amount.shape[0]>0:\n",
    "    meo3 = meo2[meo2['ViewData.Net Amount Difference Absolute'].isin(duplicate_amount['ViewData.Net Amount Difference Absolute'].unique())]\n",
    "    meo3 = meo3.reset_index().drop('index',1)\n",
    "    meo3 = meo3.sort_values(by='ViewData.Net Amount Difference Absolute')\n",
    "    meo3 = meo3.reset_index().drop('index',1)\n",
    "    \n",
    "    smb_amount = meo3[meo3['ViewData.Status'].isin(['SMB'])]['ViewData.Net Amount Difference Absolute'].unique()\n",
    "    umb_amount = meo3[meo3['ViewData.Status'].isin(['UMB'])]['ViewData.Net Amount Difference Absolute'].unique()\n",
    "    \n",
    "    smb_ob_table = meo3[meo3['ViewData.Net Amount Difference Absolute'].isin(smb_amount)]\n",
    "    umb_ob_table = meo3[meo3['ViewData.Net Amount Difference Absolute'].isin(umb_amount)]\n",
    "    \n",
    "    ob_breakid = []\n",
    "    smb_breakid = []\n",
    "    for amount in smb_amount:\n",
    "        ob = smb_ob_table[(smb_ob_table['ViewData.Net Amount Difference Absolute']==amount) & (smb_ob_table['ViewData.Status']=='OB')]\n",
    "        smb = smb_ob_table[(smb_ob_table['ViewData.Net Amount Difference Absolute']==amount) & (smb_ob_table['ViewData.Status']=='SMB')]\n",
    "#         if((ob.shape[0]==1) and (smb.shape[0]==1) and (ob['ViewData.Mapped Custodian Account'] == smb['ViewData.Mapped Custodian Account']) and (ob['ViewData.Currency'] == smb['ViewData.Currency']) and (ob['ViewData.Source Combination Code'] == smb['ViewData.Source Combination Code'])):\n",
    "\n",
    "        if ob.shape[0]==1 and smb.shape[0]==1 :\n",
    "#Change added on 17-12-2020 by Rohit to include filter on ob and smb. Below if statement is commented out and new if statement is included\n",
    "            if((ob['ViewData.Mapped Custodian Account'].iloc[0] == smb['ViewData.Mapped Custodian Account'].iloc[0]) and (ob['ViewData.Currency'].iloc[0] == smb['ViewData.Currency'].iloc[0]) and (ob['ViewData.Source Combination Code'].iloc[0] == smb['ViewData.Source Combination Code'].iloc[0])):\n",
    "\n",
    "                ob_breakid.append(ob['ViewData.BreakID'].values)\n",
    "                smb_breakid.append(smb['ViewData.BreakID'].values)\n",
    "            \n",
    "    if len(ob_breakid)>0:\n",
    "        final_smb_ob_table = pd.DataFrame(ob_breakid)\n",
    "        final_smb_ob_table.columns = ['BreakID_OB']\n",
    "        final_smb_ob_table['BreakID_SMB'] = smb_breakid\n",
    "        final_smb_ob_table['BreakID_SMB'] = final_smb_ob_table['BreakID_SMB'].apply(lambda x: str(x).replace(\"[\",''))\n",
    "        final_smb_ob_table['BreakID_SMB'] = final_smb_ob_table['BreakID_SMB'].apply(lambda x: str(x).replace(\"]\",''))\n",
    "        final_smb_ob_table['BreakID_SMB'] = final_smb_ob_table['BreakID_SMB'].astype(int)\n",
    "    else:\n",
    "        final_smb_ob_table = pd.DataFrame()\n",
    "else:\n",
    "    final_smb_ob_table = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BreakID_OB</th>\n",
       "      <th>BreakID_SMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1653645115</td>\n",
       "      <td>1648967636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1653981730</td>\n",
       "      <td>1648950872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654050883</td>\n",
       "      <td>1654050853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BreakID_OB  BreakID_SMB\n",
       "0  1653645115   1648967636\n",
       "1  1653981730   1648950872\n",
       "2  1654050883   1654050853"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_smb_ob_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_breakid = []\n",
    "umb_breakid = []\n",
    "for amount in umb_amount:\n",
    "    ob = umb_ob_table[(umb_ob_table['ViewData.Net Amount Difference Absolute']==amount) & (umb_ob_table['ViewData.Status']=='OB')]\n",
    "    umb = umb_ob_table[(umb_ob_table['ViewData.Net Amount Difference Absolute']==amount) & (umb_ob_table['ViewData.Status']=='UMB')]\n",
    "#         if((ob.shape[0]==1) and (smb.shape[0]==1) and (ob['ViewData.Mapped Custodian Account'] == smb['ViewData.Mapped Custodian Account']) and (ob['ViewData.Currency'] == smb['ViewData.Currency']) and (ob['ViewData.Source Combination Code'] == smb['ViewData.Source Combination Code'])):\n",
    "\n",
    "    if ob.shape[0]==1 and umb.shape[0]==1 :\n",
    "#Change added on 17-12-2020 by Rohit to include filter on ob and smb. Below if statement is commented out and new if statement is included\n",
    "        if((ob['ViewData.Mapped Custodian Account'].iloc[0] == umb['ViewData.Mapped Custodian Account'].iloc[0]) and (ob['ViewData.Currency'].iloc[0] == umb['ViewData.Currency'].iloc[0]) and (ob['ViewData.Source Combination Code'].iloc[0] == umb['ViewData.Source Combination Code'].iloc[0])):\n",
    "\n",
    "            ob_breakid.append(ob['ViewData.BreakID'].values)\n",
    "            umb_breakid.append(umb['ViewData.BreakID'].values)\n",
    "            \n",
    "if len(ob_breakid)>0:\n",
    "    final_umb_ob_table = pd.DataFrame(ob_breakid)\n",
    "    final_umb_ob_table.columns = ['BreakID_OB']\n",
    "    final_umb_ob_table['BreakID_UMB'] = umb_breakid\n",
    "    final_umb_ob_table['BreakID_UMB'] = final_umb_ob_table['BreakID_UMB'].apply(lambda x: str(x).replace(\"[\",''))\n",
    "    final_umb_ob_table['BreakID_UMB'] = final_umb_ob_table['BreakID_UMB'].apply(lambda x: str(x).replace(\"]\",''))\n",
    "    final_umb_ob_table['BreakID_UMB'] = final_umb_ob_table['BreakID_UMB'].astype(int)\n",
    "else:\n",
    "    final_umb_ob_table = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "umb2 = meo[meo['ViewData.Status'].isin(['OB','UMB'])]\n",
    "umb2 = umb2.reset_index().drop('index',1)\n",
    "\n",
    "umb2['ViewData.Net Amount Difference Absolute'] = np.round(umb2['ViewData.Net Amount Difference Absolute'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "umb2['filter_key'] = umb2['ViewData.Mapped Custodian Account'] + umb2['ViewData.Currency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umb2['filter_key'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subSum(numbers,total):\n",
    "    for length in range(1, 3):\n",
    "        if len(numbers) < length or length < 1:\n",
    "            return []\n",
    "        for index,number in enumerate(numbers):\n",
    "            if length == 1 and np.isclose(number, total, atol=0.05).any():\n",
    "                return [number]\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset: \n",
    "                return [number] + subset\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_id_aggregation = []\n",
    "umb2_ids=[]\n",
    "ob2_ids=[]\n",
    "\n",
    "\n",
    "for key in umb2['filter_key'].unique():\n",
    "    partial_data = umb2[umb2['filter_key']==key]\n",
    "\n",
    "    if partial_data.shape[0]<=15 and any(x=='UMB' for x in partial_data['ViewData.Status'].values):\n",
    "        values = partial_data['ViewData.Net Amount Difference']\n",
    "        net_sum= 0\n",
    "        \n",
    "        if subSum(values,net_sum) == []: \n",
    "            #print(\"There are no valid subsets.\")\n",
    "            amount_array = ['NULL']\n",
    "        else:\n",
    "            amount_array = subSum(values,net_sum)\n",
    "\n",
    "            break_id = partial_data[(partial_data['ViewData.Net Amount Difference'].isin(amount_array))]['ViewData.BreakID'].values\n",
    "            #id0_unique = key\n",
    "            \n",
    "            for i in break_id:\n",
    "                if partial_data[(partial_data['ViewData.BreakID']==i) & (partial_data['ViewData.Status']=='UMB')].shape[0]>0:\n",
    "                    umb2_ids.append(i)\n",
    "                else:\n",
    "                    ob2_ids.append(i)\n",
    "            break_id_aggregation.append(break_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654004372</td>\n",
       "      <td>1654004362</td>\n",
       "      <td>1.649154e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1653645112</td>\n",
       "      <td>1653645132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1             2\n",
       "0  1654004372  1654004362  1.649154e+09\n",
       "1  1653645112  1653645132           NaN"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(break_id_aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1649153998]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umb2_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1654004372, 1654004362, 1653645112, 1653645132]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob2_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550    77_3791122313_Advent Geneva,39_3791123345_Adve...\n",
       "Name: ViewData.Side0_UniqueIds, dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "umb2[umb2['ViewData.BreakID']==1649153998]['ViewData.Side0_UniqueIds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_umb_ob_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViewData.Net Amount Difference Absolute</th>\n",
       "      <th>ViewData.Side0_UniqueIds</th>\n",
       "      <th>ViewData.Side1_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ViewData.Net Amount Difference Absolute, ViewData.Side0_UniqueIds, ViewData.Side1_UniqueIds]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meo[meo['ViewData.BreakID']==1669576178][['ViewData.Net Amount Difference Absolute','ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViewData.Net Amount Difference Absolute</th>\n",
       "      <th>ViewData.Side0_UniqueIds</th>\n",
       "      <th>ViewData.Side1_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>333.33</td>\n",
       "      <td>4_3791102560_Advent Geneva</td>\n",
       "      <td>5_3791104392_JP Morgan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ViewData.Net Amount Difference Absolute    ViewData.Side0_UniqueIds  \\\n",
       "282                                   333.33  4_3791102560_Advent Geneva   \n",
       "\n",
       "    ViewData.Side1_UniqueIds  \n",
       "282   5_3791104392_JP Morgan  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meo[meo['ViewData.BreakID']==1607245427][['ViewData.Net Amount Difference Absolute','ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_umb_ob_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove BreakIDs caught in final_smb_ob_table if final_smb_ob_table is not null\n",
    "if(final_smb_ob_table.shape[0] != 0):\n",
    "    final_smb_ob_table['BreakID_SMB'] = final_smb_ob_table['BreakID_SMB'].astype(np.int64)\n",
    "    final_smb_ob_table['BreakID_OB'] = final_smb_ob_table['BreakID_OB'].astype(np.int64)\n",
    "    \n",
    "    final_smb_ob_table_BreakID_list =  list(final_smb_ob_table['BreakID_OB']) + list(final_smb_ob_table['BreakID_SMB'])\n",
    "    meo = meo[~meo['ViewData.BreakID'].isin(final_smb_ob_table_BreakID_list)]\n",
    "else:\n",
    "    final_smb_ob_table_BreakID_list = []\n",
    "#End change code made on 12-12-2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meo_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-4604d88cffd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_smb_ob_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mfinal_smb_ob_table_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_smb_ob_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmeo_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ViewData.BreakID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ViewData.Task ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ViewData.Task Business Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ViewData.Source Combination Code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'BreakID_OB'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mright_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ViewData.BreakID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfinal_smb_ob_table_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ViewData.BreakID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'meo_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Change made on 12-12-2020 to incorporate final_smb_ob_table. The BreakIDs in this table will be given the Predicted_Status of UMR and Predicted_action of UMR_One-Many_to_Many-One\n",
    "#Begin code change made on 12-12-2020 to incorporate final_smb_ob_table\n",
    "#final_smb_ob_table\n",
    "if(final_smb_ob_table.shape[0] != 0):\n",
    "\n",
    "    final_smb_ob_table_copy = pd.merge(final_smb_ob_table,meo_df[['ViewData.BreakID','ViewData.Task ID','ViewData.Task Business Date','ViewData.Source Combination Code']].drop_duplicates(), left_on = 'BreakID_OB',right_on = 'ViewData.BreakID', how='left')\n",
    "    final_smb_ob_table_copy.drop('ViewData.BreakID', axis = 1, inplace = True)\n",
    "    \n",
    "    final_smb_ob_table_copy['Predicted_Status'] = 'UMR'\n",
    "    final_smb_ob_table_copy['Predicted_action'] = 'UMR_One-Many_to_Many-One'\n",
    "    final_smb_ob_table_copy['ML_flag'] = 'ML'\n",
    "    final_smb_ob_table_copy['SetupID'] = setup_code \n",
    "    final_smb_ob_table_copy['ViewData.Task Business Date'] = pd.to_datetime(final_smb_ob_table_copy['ViewData.Task Business Date'])\n",
    "    final_smb_ob_table_copy['ViewData.Task Business Date'] = final_smb_ob_table_copy['ViewData.Task Business Date'].map(lambda x: dt.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    final_smb_ob_table_copy['ViewData.Task Business Date'] = pd.to_datetime(final_smb_ob_table_copy['ViewData.Task Business Date'])\n",
    "    final_smb_ob_table_copy = make_Side0_Side1_columns_for_final_smb_ob_table(final_smb_ob_table_copy,meo_df)\n",
    "    final_smb_ob_table_copy['probability_No_pair'] = ''\n",
    "    final_smb_ob_table_copy['probability_UMB'] = ''\n",
    "    final_smb_ob_table_copy['probability_UMR'] = ''\n",
    "    final_smb_ob_table_copy['probability_UMT'] = ''\n",
    "    final_smb_ob_table_copy['PredictedComment'] = ''\n",
    "    final_smb_ob_table_copy['PredictedCategory'] = ''\n",
    "    columns_rename_for_smb_ob_table_dict = {'BreakID_OB' : 'BreakID',\n",
    "                                       'BreakID_SMB' : 'Final_predicted_break',\n",
    "                                       'ViewData.Task ID' : 'TaskID',\n",
    "                                       'ViewData.Task Business Date' : 'BusinessDate',\n",
    "                                       'ViewData.Source Combination Code' : 'SourceCombinationCode'\n",
    "                                       }\n",
    "    final_smb_ob_table_copy.rename(columns = columns_rename_for_smb_ob_table_dict, inplace = True)\n",
    "    filepaths_final_smb_ob_table_copy = '\\\\\\\\vitblrdevcons01\\\\Raman  Strategy ML 2.0\\\\All_Data\\\\' + client + '\\\\final_smb_ob_table_copy_setup_' + setup_code + '_date_' + str(date_i) + '.csv'\n",
    "\n",
    "    final_smb_ob_table_copy.to_csv(filepaths_final_smb_ob_table_copy)\n",
    "\n",
    "\n",
    "else:\n",
    "    final_smb_ob_table_copy = pd.DataFrame()\n",
    "#End code change made on 12-12-2020 to incorporate final_smb_ob_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_smb_ob_table_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Side_0_1_UniqueIds_closed_all_dates_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "#for i in range(0,len(date_numbers_list)):\n",
    "\n",
    "#    Side_0_1_UniqueIds_closed_all_dates_list.append(\n",
    "#            closed_daily_run(fun_setup_code=setup_code,\\\n",
    "#                             fun_date = i,\\\n",
    "#                             fun_meo_df_daily_run = meo)\n",
    "#                             fun_main_filepath_meo= filepaths_MEO[i],\\\n",
    "#                             fun_main_filepath_aua = filepaths_AUA[i])\n",
    " #           )\n",
    "\n",
    "#new_closed_keys = [i.replace('nan','') for i in Side_0_1_UniqueIds_closed_all_dates_list[0]]\n",
    "#new_closed_keys = [i.replace('None','') for i in new_closed_keys]\n",
    "\n",
    "\n",
    "df1 = meo[~meo['ViewData.Status'].isin(['SMT','HST', 'OC', 'CT', 'Archive','SMR'])]\n",
    "#df = df[df['MatchStatus'] != 21]\n",
    "df1 = df1[~df1['ViewData.Status'].isnull()]\n",
    "df1 = df1.reset_index()\n",
    "df1 = df1.drop('index',1)\n",
    "\n",
    "## Output for Closed breaks\n",
    "\n",
    "#closed_df_side1 = df1[df1['ViewData.Side1_UniqueIds'].isin(new_closed_keys)]\n",
    "#closed_df_side0 = df1[df1['ViewData.Side0_UniqueIds'].isin(new_closed_keys)]\n",
    "#closed_df = closed_df_side1.append(closed_df_side0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Date value count is:\n",
      "2020-12-08    690\n",
      "2019-04-22      2\n",
      "2020-03-04      2\n",
      "2020-09-25      1\n",
      "2020-04-15      1\n",
      "2020-08-31      1\n",
      "2020-07-07      1\n",
      "2020-12-02      1\n",
      "2020-12-04      1\n",
      "2020-02-10      1\n",
      "2020-11-19      1\n",
      "2020-11-27      1\n",
      "2020-09-02      1\n",
      "2020-09-16      1\n",
      "2020-11-30      1\n",
      "Name: Date, dtype: int64\n",
      "Choosing the date : 2020-12-08\n"
     ]
    }
   ],
   "source": [
    "#df2 = df1[~((df1['ViewData.Side1_UniqueIds'].isin(new_closed_keys)) | (df1['ViewData.Side0_UniqueIds'].isin(new_closed_keys)))]\n",
    "\n",
    "df2 = df1.copy()\n",
    "df = df2.copy()\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',1)\n",
    "df['Date'] = pd.to_datetime(df['ViewData.Task Business Date'])\n",
    "df = df[~df['Date'].isnull()]\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',1)\n",
    "\n",
    "pd.to_datetime(df['Date'])\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.date\n",
    "\n",
    "df['Date'] = df['Date'].astype(str)\n",
    "\n",
    "df = df[df['ViewData.Status'].isin(['OB','SDB','UOB','UDB','CMF','CNF','SMB','SPM'])]\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',1)\n",
    "df['ViewData.Side0_UniqueIds'] = df['ViewData.Side0_UniqueIds'].astype(str)\n",
    "df['ViewData.Side1_UniqueIds'] = df['ViewData.Side1_UniqueIds'].astype(str)\n",
    "df['flag_side0'] = df.apply(lambda x: len(x['ViewData.Side0_UniqueIds'].split(',')), axis=1)\n",
    "df['flag_side1'] = df.apply(lambda x: len(x['ViewData.Side1_UniqueIds'].split(',')), axis=1)\n",
    "df = df.rename(columns= {'ViewData.Cust Net Amount':'ViewData.B-P Net Amount'})\n",
    "\n",
    "print('The Date value count is:')\n",
    "print(df['Date'].value_counts())\n",
    "\n",
    "date_i = df['Date'].mode()[0]\n",
    "\n",
    "print('Choosing the date : ' + date_i)\n",
    "\n",
    "sample = df[df['Date'] == date_i]\n",
    "sample = sample.reset_index()\n",
    "sample = sample.drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "smb = sample[sample['ViewData.Status']=='SMB'].reset_index()\n",
    "smb = smb.drop('index',1)\n",
    "smb_pb = smb.copy()\n",
    "smb_acc = smb.copy()\n",
    "smb_pb['ViewData.Accounting Net Amount'] = np.nan\n",
    "smb_pb['ViewData.Side0_UniqueIds'] = np.nan\n",
    "smb_pb['ViewData.Status'] ='SMB-OB'\n",
    "\n",
    "smb_acc['ViewData.B-P Net Amount'] = np.nan\n",
    "smb_acc['ViewData.Side1_UniqueIds'] = np.nan\n",
    "smb_acc['ViewData.Status'] ='SMB-OB'\n",
    "\n",
    "sample = sample[sample['ViewData.Status']!='SMB']\n",
    "sample = sample.reset_index()\n",
    "sample = sample.drop('index',1)\n",
    "\n",
    "sample = pd.concat([sample,smb_pb,smb_acc],axis=0)\n",
    "sample = sample.reset_index()\n",
    "sample = sample.drop('index',1)\n",
    "\n",
    "sample['ViewData.Side0_UniqueIds'] = sample['ViewData.Side0_UniqueIds'].astype(str)\n",
    "sample['ViewData.Side1_UniqueIds'] = sample['ViewData.Side1_UniqueIds'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 375)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['ViewData.Side1_UniqueIds']=='nan'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 375)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['ViewData.Side0_UniqueIds']=='None'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 375)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['ViewData.Side0_UniqueIds']=='NaN'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 375)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['ViewData.Side0_UniqueIds']==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='nan','flag_side0'] = 0\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='nan','flag_side1'] = 0\n",
    "\n",
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='None','flag_side0'] = 0\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='None','flag_side1'] = 0\n",
    "\n",
    "\n",
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='','flag_side0'] = 0\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='','flag_side1'] = 0\n",
    "\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='nan','Trans_side'] = 'B_side'\n",
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='nan','Trans_side'] = 'A_side'\n",
    "\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='None','Trans_side'] = 'B_side'\n",
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='None','Trans_side'] = 'A_side'\n",
    "\n",
    "sample.loc[sample['ViewData.Side1_UniqueIds']=='','Trans_side'] = 'B_side'\n",
    "sample.loc[sample['ViewData.Side0_UniqueIds']=='','Trans_side'] = 'A_side'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant136\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant136\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "sample.loc[sample['Trans_side']=='A_side','ViewData.B-P Currency'] = sample.loc[sample['Trans_side']=='A_side','ViewData.Currency']\n",
    "sample.loc[sample['Trans_side']=='B_side','ViewData.Accounting Currency'] = sample.loc[sample['Trans_side']=='B_side','ViewData.Currency'] \n",
    "\n",
    "sample['ViewData.B-P Currency'] = sample['ViewData.B-P Currency'].astype(str)\n",
    "sample['ViewData.Accounting Currency'] = sample['ViewData.Accounting Currency'].astype(str)\n",
    "sample['ViewData.Mapped Custodian Account'] = sample['ViewData.Mapped Custodian Account'].astype(str)\n",
    "sample['filter_key'] = sample.apply(lambda x: x['ViewData.Mapped Custodian Account'] + x['ViewData.B-P Currency'] if x['Trans_side']=='A_side' else x['ViewData.Mapped Custodian Account'] + x['ViewData.Accounting Currency'], axis=1)\n",
    "\n",
    "sample1 = sample[(sample['flag_side0']<=1) & (sample['flag_side1']<=1) & (sample['ViewData.Status'].isin(['OB','SPM','SDB','UDB','UOB','SMB-OB','CNF','CMF']))]\n",
    "\n",
    "sample1 = sample1.reset_index()\n",
    "sample1 = sample1.drop('index', 1)\n",
    "\n",
    "sample1['ViewData.BreakID'] = sample1['ViewData.BreakID'].astype(int)\n",
    "\n",
    "sample1 = sample1[sample1['ViewData.BreakID']!=-1]\n",
    "sample1 = sample1.reset_index()\n",
    "sample1 = sample1.drop('index',1)\n",
    "\n",
    "sample1 = sample1.sort_values(['ViewData.BreakID','Date'], ascending =[True, False])\n",
    "sample1 = sample1.reset_index()\n",
    "sample1 = sample1.drop('index',1)\n",
    "\n",
    "aa = sample1[sample1['Trans_side']=='A_side']\n",
    "bb = sample1[sample1['Trans_side']=='B_side']\n",
    "\n",
    "aa['filter_key'] = aa['ViewData.Source Combination'].astype(str) + aa['ViewData.Mapped Custodian Account'].astype(str) + aa['ViewData.B-P Currency'].astype(str)\n",
    "\n",
    "bb['filter_key'] = bb['ViewData.Source Combination'].astype(str) + bb['ViewData.Mapped Custodian Account'].astype(str) + bb['ViewData.Accounting Currency'].astype(str)\n",
    "\n",
    "aa = aa.reset_index()\n",
    "aa = aa.drop('index', 1)\n",
    "bb = bb.reset_index()\n",
    "bb = bb.drop('index', 1)\n",
    "\n",
    "bb = bb[~bb['ViewData.Accounting Net Amount'].isnull()]\n",
    "bb = bb.reset_index()\n",
    "bb = bb.drop('index',1)\n",
    "###################### loop m*n ###############################\n",
    "\n",
    "\n",
    "\n",
    "pool =[]\n",
    "key_index =[]\n",
    "training_df =[]\n",
    "\n",
    "no_pair_ids = []\n",
    "#max_rows = 5\n",
    "\n",
    "for d in (aa['Date'].unique()):\n",
    "    aa1 = aa.loc[aa['Date']==d,:][common_cols]\n",
    "    bb1 = bb.loc[bb['Date']==d,:][common_cols]\n",
    "    \n",
    "    aa1 = aa1.reset_index()\n",
    "    aa1 = aa1.drop('index',1)\n",
    "    bb1 = bb1.reset_index()\n",
    "    bb1 = bb1.drop('index', 1)\n",
    "    \n",
    "    bb1 = bb1.sort_values(by='filter_key',ascending =True)\n",
    "    \n",
    "    for key in (list(np.unique(np.array(list(aa1['filter_key'].values) + list(bb1['filter_key'].values))))):\n",
    "        \n",
    "        df1 = aa1[aa1['filter_key']==key]\n",
    "        df2 = bb1[bb1['filter_key']==key]\n",
    "\n",
    "        if df1.empty == False and df2.empty == False:\n",
    "            #aa_df = pd.concat([aa1[aa1.index==i]]*repeat_num, ignore_index=True)\n",
    "            #bb_df = bb1.loc[pool[len(pool)-1],:][common_cols].reset_index()\n",
    "            #bb_df = bb_df.drop('index', 1)\n",
    "\n",
    "            df1 = df1.rename(columns={'ViewData.BreakID':'ViewData.BreakID_A_side'})\n",
    "            df2 = df2.rename(columns={'ViewData.BreakID':'ViewData.BreakID_B_side'})\n",
    "\n",
    "            #dff  = pd.concat([aa[aa.index==i],bb.loc[pool[i],:][accounting_vars]],axis=1)\n",
    "\n",
    "            df1 = df1.reset_index()\n",
    "            df2 = df2.reset_index()\n",
    "            df1 = df1.drop('index', 1)\n",
    "            df2 = df2.drop('index', 1)\n",
    "\n",
    "            df1.columns = ['SideA.' + x  for x in df1.columns] \n",
    "            df2.columns = ['SideB.' + x  for x in df2.columns]\n",
    "\n",
    "            df1 = df1.rename(columns={'SideA.filter_key':'filter_key'})\n",
    "            df2 = df2.rename(columns={'SideB.filter_key':'filter_key'})\n",
    "\n",
    "            #dff = pd.concat([aa_df,bb_df],axis=1)\n",
    "            dff = merge(df1, df2, on='filter_key')\n",
    "            training_df.append(dff)\n",
    "                #key_index.append(i)\n",
    "            #else:\n",
    "            #no_pair_ids.append([aa1[(aa1['filter_key']=='key') & (aa1['ViewData.Status'].isin(['OB','SDB']))]['ViewData.Side1_UniqueIds'].values[0]])\n",
    "               # no_pair_ids.append(aa1[(aa1['filter_key']== key) & (aa1['ViewData.Status'].isin(['OB','SDB']))]['ViewData.Side1_UniqueIds'].values[0])\n",
    "    \n",
    "        else:\n",
    "#Change made on 26-11-2020 to include CMF and CNF as well, as long as they are single sided. For now, we are assuming they are single sided and no other precaution has been made to explicitely include single sided CNF and CMF\n",
    "#Change made as per above and commenting below on 26-11-2020\n",
    "#            no_pair_ids.append([aa1[(aa1['filter_key']==key) & (aa1['ViewData.Status'].isin(['OB','SDB']))]['ViewData.Side1_UniqueIds'].values])\n",
    "#            no_pair_ids.append([bb1[(bb1['filter_key']==key) & (bb1['ViewData.Status'].isin(['OB','SDB']))]['ViewData.Side0_UniqueIds'].values])\n",
    "#Change made on 26-11-2020 to include CNF and CMF\n",
    "            no_pair_ids.append([aa1[(aa1['filter_key']==key) & (aa1['ViewData.Status'].isin(['OB','SDB','CNF','CMF']))]['ViewData.Side1_UniqueIds'].values])\n",
    "            no_pair_ids.append([bb1[(bb1['filter_key']==key) & (bb1['ViewData.Status'].isin(['OB','SDB','CNF','CMF']))]['ViewData.Side0_UniqueIds'].values])\n",
    "            \n",
    "\n",
    "\n",
    "if len(no_pair_ids) != 0:\n",
    "    no_pair_ids = np.unique(np.concatenate(no_pair_ids,axis=1)[0])\n",
    "    no_pair_ids_df = pd.DataFrame(no_pair_ids, columns = ['Side0_1_UniqueIds'])\n",
    "#    no_pair_ids_df = pd.merge(no_pair_ids_df, meo_df[['ViewData.Side1_UniqueIds','ViewData.BreakID','ViewData.Task ID','ViewData.Task Business Date']].drop_duplicates(), left_on = 'Side0_1_UniqueIds',right_on = 'ViewData.Side1_UniqueIds', how='left')\n",
    "#    no_pair_ids_df = pd.merge(no_pair_ids_df, meo_df[['ViewData.Side0_UniqueIds','ViewData.BreakID','ViewData.Task ID','ViewData.Task Business Date']].drop_duplicates(), left_on = 'Side0_1_UniqueIds',right_on = 'ViewData.Side0_UniqueIds', how='left')\n",
    "#    #no_pair_ids_df = no_pair_ids_df.rename(columns={'0':'filter_key'})\n",
    "#    no_pair_ids_df['Predicted_Status'] = 'OB'\n",
    "#    no_pair_ids_df['Predicted_action'] = 'No-Pair'\n",
    "#    no_pair_ids_df['probability_No_pair'] = 0.9933\n",
    "#    no_pair_ids_df['probability_UMB'] = 0.0033\n",
    "#    no_pair_ids_df['probability_UMR'] = 0.0033    \n",
    "#    no_pair_ids_df['ML_flag'] = 'ML'\n",
    "#    no_pair_ids_df['TaskID'] = setup_code \n",
    " #   no_pair_ids_df.to_csv(filepaths_no_pair_id_data)\n",
    "#else:\n",
    "#     with open(filepaths_no_pair_id_no_data_warning, 'w') as f:\n",
    "#         f.write('No no pair ids found for this setup and date combination')\n",
    "\n",
    "\n",
    "test_file = pd.concat(training_df)\n",
    "\n",
    "test_file = test_file.reset_index()\n",
    "test_file = test_file.drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file['SideB.ViewData.BreakID_B_side'] = test_file['SideB.ViewData.BreakID_B_side'].astype('int64')\n",
    "test_file['SideA.ViewData.BreakID_A_side'] = test_file['SideA.ViewData.BreakID_A_side'].astype('int64')\n",
    "\n",
    "test_file['SideB.ViewData.CUSIP'] = test_file['SideB.ViewData.CUSIP'].str.split(\".\",expand=True)[0]\n",
    "test_file['SideA.ViewData.CUSIP'] = test_file['SideA.ViewData.CUSIP'].str.split(\".\",expand=True)[0]\n",
    "\n",
    "test_file['SideA.ViewData.ISIN'] = test_file['SideA.ViewData.ISIN'].astype(str)\n",
    "test_file['SideB.ViewData.ISIN'] = test_file['SideB.ViewData.ISIN'].astype(str)\n",
    "test_file['SideA.ViewData.CUSIP'] = test_file['SideA.ViewData.CUSIP'].astype(str)\n",
    "test_file['SideB.ViewData.CUSIP'] = test_file['SideB.ViewData.CUSIP'].astype(str)\n",
    "test_file['SideA.ViewData.Currency'] = test_file['SideA.ViewData.Currency'].astype(str)\n",
    "test_file['SideB.ViewData.Currency'] = test_file['SideB.ViewData.Currency'].astype(str)\n",
    "\n",
    "test_file['SideA.ViewData.Trade Date'] = test_file['SideA.ViewData.Trade Date'].astype(str)\n",
    "test_file['SideB.ViewData.Trade Date'] = test_file['SideB.ViewData.Trade Date'].astype(str)\n",
    "test_file['SideA.ViewData.Settle Date'] = test_file['SideA.ViewData.Settle Date'].astype(str)\n",
    "test_file['SideB.ViewData.Settle Date'] = test_file['SideB.ViewData.Settle Date'].astype(str)\n",
    "test_file['SideA.ViewData.Fund'] = test_file['SideA.ViewData.Fund'].astype(str)\n",
    "test_file['SideB.ViewData.Fund'] = test_file['SideB.ViewData.Fund'].astype(str)\n",
    "\n",
    "values_ISIN_A_Side = test_file['SideA.ViewData.ISIN'].values\n",
    "values_ISIN_B_Side = test_file['SideB.ViewData.ISIN'].values\n",
    "#test_file['ISIN_match'] = vec_equals_fun(values_ISIN_A_Side,values_ISIN_B_Side)\n",
    "\n",
    "values_CUSIP_A_Side = test_file['SideA.ViewData.CUSIP'].values\n",
    "values_CUSIP_B_Side = test_file['SideB.ViewData.CUSIP'].values\n",
    "#\n",
    "# values_CUSIP_A_Side = test_file['SideA.ViewData.Currency'].values\n",
    "# values_CUSIP_B_Side = test_file['SideB.ViewData.Currency'].values\n",
    "\n",
    "values_Currency_match_A_Side = test_file['SideA.ViewData.Currency'].values\n",
    "values_Currency_match_B_Side = test_file['SideA.ViewData.Currency'].values\n",
    "\n",
    "values_Trade_Date_match_A_Side = test_file['SideA.ViewData.Trade Date'].values\n",
    "values_Trade_Date_match_B_Side = test_file['SideB.ViewData.Trade Date'].values\n",
    "\n",
    "values_Settle_Date_match_A_Side = test_file['SideA.ViewData.Settle Date'].values\n",
    "values_Settle_Date_match_B_Side = test_file['SideB.ViewData.Settle Date'].values\n",
    "\n",
    "values_Fund_match_A_Side = test_file['SideA.ViewData.Fund'].values\n",
    "values_Fund_match_B_Side = test_file['SideB.ViewData.Fund'].values\n",
    "\n",
    "test_file['ISIN_match'] = vec_equals_fun(values_ISIN_A_Side,values_ISIN_B_Side)\n",
    "test_file['CUSIP_match'] = vec_equals_fun(values_CUSIP_A_Side,values_CUSIP_B_Side)\n",
    "test_file['Currency_match'] = vec_equals_fun(values_Currency_match_A_Side,values_Currency_match_B_Side)\n",
    "test_file['Trade_Date_match'] = vec_equals_fun(values_Trade_Date_match_A_Side,values_Trade_Date_match_B_Side)\n",
    "test_file['Settle_Date_match'] = vec_equals_fun(values_Settle_Date_match_A_Side,values_Settle_Date_match_B_Side)\n",
    "test_file['Fund_match'] = vec_equals_fun(values_Fund_match_A_Side,values_Fund_match_B_Side)\n",
    "\n",
    "test_file['Amount_diff_1'] = test_file['SideA.ViewData.Accounting Net Amount'] - test_file['SideB.ViewData.B-P Net Amount']\n",
    "test_file['Amount_diff_2'] = test_file['SideB.ViewData.Accounting Net Amount'] - test_file['SideA.ViewData.B-P Net Amount']\n",
    "\n",
    "\n",
    "# ## Description code\n",
    "\n",
    "#os.chdir('D:\\\\ViteosModel\\\\OakTree - Pratik Code')#\n",
    "#print(os.getcwd())\n",
    "\n",
    "## TODO - Import a csv file for description category mapping\n",
    "\n",
    "com = pd.read_csv('desc cat with naveen oaktree.csv')\n",
    "#'desc cat with naveen oaktree.csv\n",
    "\n",
    "cat_list = list(set(com['Pairing']))\n",
    "\n",
    "\n",
    "\n",
    "test_file['SideA.desc_cat'] = test_file['SideA.ViewData.Description'].apply(lambda x : descclean(x,cat_list))\n",
    "test_file['SideB.desc_cat'] = test_file['SideB.ViewData.Description'].apply(lambda x : descclean(x,cat_list))\n",
    "\n",
    "test_file['SideA.desc_cat'] = test_file['SideA.desc_cat'].apply(lambda x : currcln(x))\n",
    "test_file['SideB.desc_cat'] = test_file['SideB.desc_cat'].apply(lambda x : currcln(x))\n",
    "\n",
    "com = com.drop(['var','Catogery'], axis = 1)\n",
    "\n",
    "com = com.drop_duplicates()\n",
    "\n",
    "com['Pairing'] = com['Pairing'].apply(lambda x : x.lower())\n",
    "com['replace'] = com['replace'].apply(lambda x : x.lower())\n",
    "\n",
    "\n",
    "test_file['SideA.new_desc_cat'] = test_file['SideA.desc_cat'].apply(lambda x : catcln1(x,com))\n",
    "test_file['SideB.new_desc_cat'] = test_file['SideB.desc_cat'].apply(lambda x : catcln1(x,com))\n",
    "\n",
    "comp = ['inc','stk','corp ','llc','pvt','plc']\n",
    "test_file['SideA.new_desc_cat'] = test_file['SideA.new_desc_cat'].apply(lambda x : 'Company' if x in comp else x)\n",
    "\n",
    "test_file['SideB.new_desc_cat'] = test_file['SideB.new_desc_cat'].apply(lambda x : 'Company' if x in comp else x)\n",
    "\n",
    "test_file['SideA.new_desc_cat'] = test_file['SideA.new_desc_cat'].apply(lambda x : desccat(x))\n",
    "test_file['SideB.new_desc_cat'] = test_file['SideB.new_desc_cat'].apply(lambda x : desccat(x))\n",
    "# ## Prime Broker\n",
    "test_file['new_pb'] = test_file['SideA.ViewData.Mapped Custodian Account'].apply(lambda x : x.split('_')[0] if type(x)==str else x)\n",
    "new_pb_mapping = {'GSIL':'GS','CITIGM':'CITI','JPMNA':'JPM'}\n",
    "test_file['SideA.ViewData.Prime Broker'] = test_file['SideA.ViewData.Prime Broker'].fillna('kkk')\n",
    "test_file['new_pb1'] = test_file.apply(lambda x : x['new_pb'] if x['SideA.ViewData.Prime Broker']=='kkk' else x['SideA.ViewData.Prime Broker'],axis = 1)\n",
    "test_file['Trade_date_diff'] = (pd.to_datetime(test_file['SideA.ViewData.Trade Date']) - pd.to_datetime(test_file['SideB.ViewData.Trade Date'])).dt.days\n",
    "\n",
    "test_file['Settle_date_diff'] = (pd.to_datetime(test_file['SideA.ViewData.Settle Date']) - pd.to_datetime(test_file['SideB.ViewData.Settle Date'])).dt.days\n",
    "\n",
    "############ Fund match new ########\n",
    "\n",
    "values_Fund_match_A_Side = test_file['SideA.ViewData.Fund'].values\n",
    "values_Fund_match_B_Side = test_file['SideB.ViewData.Fund'].values\n",
    "\n",
    "vec_fund_match = np.vectorize(fundmatch)\n",
    "\n",
    "test_file['SideA.ViewData.Fund'] = vec_fund_match(values_Fund_match_A_Side)\n",
    "test_file['SideB.ViewData.Fund'] = vec_fund_match(values_Fund_match_B_Side)\n",
    "\n",
    "### New code for cleaning text variables \n",
    "trans_type_A_side = test_file['SideA.ViewData.Transaction Type']\n",
    "trans_type_B_side = test_file['SideB.ViewData.Transaction Type']\n",
    "\n",
    "asset_type_cat_A_side = test_file['SideA.ViewData.Asset Type Category']\n",
    "asset_type_cat_B_side = test_file['SideB.ViewData.Asset Type Category']\n",
    "\n",
    "invest_type_A_side = test_file['SideA.ViewData.Investment Type']\n",
    "invest_type_B_side = test_file['SideB.ViewData.Investment Type']\n",
    "\n",
    "prime_broker_A_side = test_file['SideA.ViewData.Prime Broker']\n",
    "prime_broker_B_side = test_file['SideB.ViewData.Prime Broker']\n",
    "\n",
    "# LOWER CASE\n",
    "trans_type_A_side = [str(item).lower() for item in trans_type_A_side]\n",
    "trans_type_B_side = [str(item).lower() for item in trans_type_B_side]\n",
    "\n",
    "asset_type_cat_A_side = [str(item).lower() for item in asset_type_cat_A_side]\n",
    "asset_type_cat_B_side = [str(item).lower() for item in asset_type_cat_B_side]\n",
    "\n",
    "invest_type_A_side = [str(item).lower() for item in invest_type_A_side]\n",
    "invest_type_B_side = [str(item).lower() for item in invest_type_B_side]\n",
    "\n",
    "prime_broker_A_side = [str(item).lower() for item in prime_broker_A_side]\n",
    "prime_broker_B_side = [str(item).lower() for item in prime_broker_B_side]\n",
    "\n",
    "split_trans_A_side = [item.split() for item in trans_type_A_side]\n",
    "split_trans_B_side = [item.split() for item in trans_type_B_side]\n",
    "\n",
    "split_asset_A_side = [item.split() for item in asset_type_cat_A_side]\n",
    "split_asset_B_side = [item.split() for item in asset_type_cat_B_side]\n",
    "\n",
    "split_invest_A_side = [item.split() for item in invest_type_A_side]\n",
    "split_invest_B_side = [item.split() for item in invest_type_B_side]\n",
    "\n",
    "split_prime_A_side = [item.split() for item in prime_broker_A_side]\n",
    "split_prime_b_side = [item.split() for item in prime_broker_B_side]\n",
    "\n",
    "## Transacion type\n",
    "\n",
    "remove_nums_A_side = [[item for item in sublist if not is_num(item)] for sublist in split_trans_A_side]\n",
    "remove_nums_B_side = [[item for item in sublist if not is_num(item)] for sublist in split_trans_B_side]\n",
    "\n",
    "remove_dates_A_side = [[item for item in sublist if not (is_date_format(item) or date_edge_cases(item))] for sublist in remove_nums_A_side]\n",
    "remove_dates_B_side = [[item for item in sublist if not (is_date_format(item) or date_edge_cases(item))] for sublist in remove_nums_B_side]\n",
    "\n",
    "\n",
    "# Specific to clients already used on, will have to be edited for other edge cases\n",
    "remove_amts_A_side = [[item for item in sublist if item[0] != '$'] for sublist in remove_dates_A_side]\n",
    "remove_amts_B_side = [[item for item in sublist if item[0] != '$'] for sublist in remove_dates_B_side]\n",
    "\n",
    "\n",
    "clean_adr_A_side = [(['ADR'] if 'adr' in item else item) for item in remove_amts_A_side]\n",
    "clean_adr_B_side = [(['ADR'] if 'adr' in item else item) for item in remove_amts_B_side]\n",
    "\n",
    "clean_tax_A_side = [(item[:2] if '30%' in item else item) for item in clean_adr_A_side]\n",
    "clean_tax_B_side = [(item[:2] if '30%' in item else item) for item in clean_adr_B_side]\n",
    "\n",
    "remove_ons_A_side = [(item[:item.index('on')] if 'on' in item else item) for item in clean_tax_A_side]\n",
    "remove_ons_B_side = [(item[:item.index('on')] if 'on' in item else item) for item in clean_tax_B_side]\n",
    "\n",
    "clean_eqswap_A_side = [(item[1:] if 'eqswap' in item else item) for item in remove_ons_A_side]\n",
    "clean_eqswap_B_side = [(item[1:] if 'eqswap' in item else item) for item in remove_ons_B_side]\n",
    "\n",
    "remove_mh_A_side = [[item for item in sublist if 'mh' not in item] for sublist in clean_eqswap_A_side]\n",
    "remove_mh_B_side = [[item for item in sublist if 'mh' not in item] for sublist in clean_eqswap_B_side]\n",
    "\n",
    "remove_ats_A_side = [(item[:item.index('@')] if '@' in item else item) for item in remove_mh_A_side]\n",
    "remove_ats_B_side = [(item[:item.index('@')] if '@' in item else item) for item in remove_mh_B_side]\n",
    "\n",
    "cleaned_trans_types_A_side = [' '.join(item) for item in remove_ats_A_side]\n",
    "cleaned_trans_types_B_side = [' '.join(item) for item in remove_ats_B_side]\n",
    "\n",
    "# # INVESTMENT TYPE\n",
    "\n",
    "remove_nums_i_A_side = [[item for item in sublist if not is_num(item)] for sublist in split_invest_A_side]\n",
    "remove_nums_i_B_side = [[item for item in sublist if not is_num(item)] for sublist in split_invest_B_side]\n",
    "\n",
    "remove_dates_i_A_side = [[item for item in sublist if not is_date_format(item)] for sublist in remove_nums_i_A_side]\n",
    "remove_dates_i_B_side = [[item for item in sublist if not is_date_format(item)] for sublist in remove_nums_i_B_side]\n",
    "\n",
    "cleaned_invest_A_side = [' '.join(item) for item in remove_dates_i_A_side]\n",
    "cleaned_invest_B_side = [' '.join(item) for item in remove_dates_i_B_side]\n",
    "\n",
    "remove_nums_a_A_side = [[item for item in sublist if not is_num(item)] for sublist in split_asset_A_side]\n",
    "remove_nums_a_B_side = [[item for item in sublist if not is_num(item)] for sublist in split_asset_B_side]\n",
    "\n",
    "remove_dates_a_A_side = [[item for item in sublist if not is_date_format(item)] for sublist in remove_nums_a_A_side]\n",
    "remove_dates_a_B_side = [[item for item in sublist if not is_date_format(item)] for sublist in remove_nums_a_B_side]\n",
    "\n",
    "cleaned_asset_A_side = [' '.join(item) for item in remove_dates_a_A_side]\n",
    "cleaned_asset_B_side = [' '.join(item) for item in remove_dates_a_B_side]\n",
    "\n",
    "test_file['SideA.ViewData.Transaction Type'] = cleaned_trans_types_A_side\n",
    "test_file['SideB.ViewData.Transaction Type'] = cleaned_trans_types_B_side\n",
    "\n",
    "test_file['SideA.ViewData.Investment Type'] = cleaned_invest_A_side\n",
    "test_file['SideB.ViewData.Investment Type'] = cleaned_invest_B_side\n",
    "\n",
    "test_file['SideA.ViewData.Asset Category Type'] = cleaned_asset_A_side\n",
    "test_file['SideB.ViewData.Asset Category Type'] = cleaned_asset_B_side\n",
    "\n",
    "values_transaction_type_match_A_Side = test_file['SideA.ViewData.Transaction Type'].values\n",
    "values_transaction_type_match_B_Side = test_file['SideB.ViewData.Transaction Type'].values\n",
    "\n",
    "vec_tt_match = np.vectorize(mhreplaced)\n",
    "\n",
    "test_file['SideA.ViewData.Transaction Type'] = vec_tt_match(values_transaction_type_match_A_Side)\n",
    "test_file['SideB.ViewData.Transaction Type'] = vec_tt_match(values_transaction_type_match_B_Side)\n",
    "\n",
    "test_file.loc[test_file['SideA.ViewData.Transaction Type']=='int','SideA.ViewData.Transaction Type'] = 'interest'\n",
    "test_file.loc[test_file['SideA.ViewData.Transaction Type']=='wires','SideA.ViewData.Transaction Type'] = 'wire'\n",
    "test_file.loc[test_file['SideA.ViewData.Transaction Type']=='dividends','SideA.ViewData.Transaction Type'] = 'dividend'\n",
    "test_file.loc[test_file['SideA.ViewData.Transaction Type']=='miscellaneous','SideA.ViewData.Transaction Type'] = 'misc'\n",
    "test_file.loc[test_file['SideA.ViewData.Transaction Type']=='div','SideA.ViewData.Transaction Type'] = 'dividend'\n",
    "\n",
    "test_file['SideA.ViewData.Investment Type'] = test_file['SideA.ViewData.Investment Type'].apply(lambda x: x.replace('eqty','equity'))\n",
    "test_file['SideA.ViewData.Investment Type'] = test_file['SideA.ViewData.Investment Type'].apply(lambda x: x.replace('options','option'))\n",
    "test_file['SideA.ViewData.Investment Type'] = test_file['SideA.ViewData.Investment Type'].apply(lambda x: x.replace('eqt','equity'))\n",
    "test_file['SideA.ViewData.Investment Type'] = test_file['SideA.ViewData.Investment Type'].apply(lambda x: x.replace('eqty','equity'))\n",
    "\n",
    "test_file['ViewData.Combined Transaction Type'] = test_file['SideA.ViewData.Transaction Type'].astype(str) +  test_file['SideB.ViewData.Transaction Type'].astype(str)\n",
    "test_file['ViewData.Combined Fund'] = test_file['SideA.ViewData.Fund'].astype(str) + test_file['SideB.ViewData.Fund'].astype(str)\n",
    "\n",
    "test_file['Combined_Investment_Type'] = test_file['SideA.ViewData.Investment Type'].astype(str) + test_file['SideB.ViewData.Investment Type'].astype(str)\n",
    "\n",
    "test_file['Combined_Asset_Type_Category'] = test_file['SideA.ViewData.Asset Category Type'].astype(str) + test_file['SideB.ViewData.Asset Category Type'].astype(str)\n",
    "\n",
    "    \n",
    "vec_nan_fun = np.vectorize(nan_fun)\n",
    "values_ISIN_A_Side = test_file['SideA.ViewData.ISIN'].values\n",
    "values_ISIN_B_Side = test_file['SideB.ViewData.ISIN'].values\n",
    "test_file['SideA.ISIN_NA'] = vec_nan_fun(values_ISIN_A_Side)\n",
    "test_file['SideB.ISIN_NA'] = vec_nan_fun(values_ISIN_A_Side)\n",
    "\n",
    "vec_a_key_match_fun = np.vectorize(a_keymatch)\n",
    "vec_b_key_match_fun = np.vectorize(b_keymatch)\n",
    "\n",
    "values_ISIN_A_Side = test_file['SideA.ViewData.ISIN'].values\n",
    "values_ISIN_B_Side = test_file['SideB.ViewData.ISIN'].values\n",
    "\n",
    "values_CUSIP_A_Side = test_file['SideA.ViewData.CUSIP'].values\n",
    "values_CUSIP_B_Side = test_file['SideB.ViewData.CUSIP'].values\n",
    "\n",
    "test_file['SideB.ViewData.key_NAN']= vec_a_key_match_fun(values_CUSIP_B_Side,values_ISIN_B_Side)[0]\n",
    "test_file['SideB.ViewData.Common_key'] = vec_a_key_match_fun(values_CUSIP_B_Side,values_ISIN_B_Side)[1]\n",
    "test_file['SideA.ViewData.key_NAN'] = vec_b_key_match_fun(values_CUSIP_A_Side,values_ISIN_A_Side)[0]\n",
    "test_file['SideA.ViewData.Common_key'] = vec_b_key_match_fun(values_CUSIP_A_Side,values_ISIN_A_Side)[1]\n",
    "\n",
    "vec_nan_equal_fun = np.vectorize(nan_equals_fun)\n",
    "values_key_NAN_B_Side = test_file['SideB.ViewData.key_NAN'].values\n",
    "values_key_NAN_A_Side = test_file['SideA.ViewData.key_NAN'].values\n",
    "test_file['All_key_nan'] = vec_nan_equal_fun(values_key_NAN_B_Side,values_key_NAN_A_Side )\n",
    "\n",
    "test_file['SideB.ViewData.Common_key'] = test_file['SideB.ViewData.Common_key'].astype(str)\n",
    "test_file['SideA.ViewData.Common_key'] = test_file['SideA.ViewData.Common_key'].astype(str)\n",
    "\n",
    "vec_new_key_match_fun = np.vectorize(new_key_match_fun)\n",
    "values_Common_key_B_Side = test_file['SideB.ViewData.Common_key'].values\n",
    "values_Common_key_A_Side = test_file['SideA.ViewData.Common_key'].values\n",
    "values_All_key_NAN = test_file['All_key_nan'].values\n",
    "\n",
    "test_file['new_key_match']= vec_new_key_match_fun(values_Common_key_B_Side,values_Common_key_A_Side,values_All_key_NAN)\n",
    "\n",
    "test_file['amount_percent'] = (test_file['SideA.ViewData.B-P Net Amount']/test_file['SideB.ViewData.Accounting Net Amount']*100)\n",
    "\n",
    "test_file['SideB.ViewData.Investment Type'] = test_file['SideB.ViewData.Investment Type'].apply(lambda x: str(x).lower())\n",
    "test_file['SideA.ViewData.Investment Type'] = test_file['SideA.ViewData.Investment Type'].apply(lambda x: str(x).lower())\n",
    "\n",
    "test_file['SideB.ViewData.Prime Broker'] = test_file['SideB.ViewData.Prime Broker'].apply(lambda x: str(x).lower())\n",
    "test_file['SideA.ViewData.Prime Broker'] = test_file['SideA.ViewData.Prime Broker'].apply(lambda x: str(x).lower())\n",
    "\n",
    "test_file['SideB.ViewData.Asset Type Category'] = test_file['SideB.ViewData.Asset Type Category'].apply(lambda x: str(x).lower())\n",
    "test_file['SideA.ViewData.Asset Type Category'] = test_file['SideA.ViewData.Asset Type Category'].apply(lambda x: str(x).lower())\n",
    "\n",
    "test_file['ViewData.Combined Transaction Type'] = test_file['ViewData.Combined Transaction Type'].apply(lambda x: x.replace('jnl','journal'))\n",
    "\n",
    "test_file['SideA.ViewData.Transaction Type'] = test_file['SideA.ViewData.Transaction Type'].apply(lambda x: x.replace('cover short','covershort'))\n",
    "\n",
    "trade_types_A = ['buy', 'sell', 'covershort','sellshort',\n",
    "       'fx', 'fx settlement', 'sell short',\n",
    "       'trade not to be reported_buy', 'covershort','ptbl','ptss', 'ptcs', 'ptcl']\n",
    "trade_types_B = ['trade not to be reported_buy','buy', 'sellshort', 'sell', 'covershort',\n",
    "       'spotfx', 'forwardfx',\n",
    "       'trade not to be reported_sell',\n",
    "       'trade not to be reported_sellshort',\n",
    "       'trade not to be reported_covershort']\n",
    "\n",
    "test_file['SideA.TType'] = test_file.apply(lambda x: \"Trade\" if x['SideA.ViewData.Transaction Type'] in trade_types_A else \"Non-Trade\", axis=1)\n",
    "test_file['SideB.TType'] = test_file.apply(lambda x: \"Trade\" if x['SideB.ViewData.Transaction Type'] in trade_types_B else \"Non-Trade\", axis=1)\n",
    "\n",
    "test_file['Combined_Desc'] = test_file['SideA.new_desc_cat'] + test_file['SideB.new_desc_cat']\n",
    "\n",
    "test_file['Combined_TType'] = test_file['SideA.TType'].astype(str) + test_file['SideB.TType'].astype(str)\n",
    "\n",
    "for feature in ['SideA.Date','SideB.Date','SideA.ViewData.Settle Date','SideB.ViewData.Settle Date']:\n",
    "    #train_full_new12[feature] = le.fit_transform(train_full_new12[feature])\n",
    "    test_file[feature] = pd.to_datetime(test_file[feature],errors = 'coerce').dt.weekday\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3005, 28)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ## UMR Mapping\n",
    "## TODO Import HIstorical UMR FILE for Transaction Type mapping\n",
    "oaktree_umr = pd.read_csv('OakTree_UMR.csv')\n",
    "\n",
    "test_file['tt_map_flag'] = test_file.apply(lambda x: 1 if x['ViewData.Combined Transaction Type'] in oaktree_umr['ViewData.Combined Transaction Type'].unique() else 0, axis=1)\n",
    "\n",
    "test_file['abs_amount_flag'] = test_file.apply(lambda x: 1 if x['SideB.ViewData.Accounting Net Amount'] == x['SideA.ViewData.B-P Net Amount']*(-1) else 0, axis=1)\n",
    "\n",
    "test_file = test_file[~test_file['SideB.ViewData.Settle Date'].isnull()]\n",
    "test_file = test_file[~test_file['SideA.ViewData.Settle Date'].isnull()]\n",
    "\n",
    "test_file = test_file.reset_index().drop('index',1)\n",
    "test_file['SideA.ViewData.Settle Date'] = test_file['SideA.ViewData.Settle Date'].astype(int)\n",
    "test_file['SideB.ViewData.Settle Date'] = test_file['SideB.ViewData.Settle Date'].astype(int)\n",
    "\n",
    "\n",
    "# ## Test file served into the model\n",
    "\n",
    "test_file2 = test_file.copy()\n",
    "\n",
    "X_test = test_file2[model_cols]\n",
    "\n",
    "X_test = X_test.reset_index()\n",
    "X_test = X_test.drop('index',1)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "X_test = X_test.drop_duplicates()\n",
    "X_test = X_test.reset_index()\n",
    "X_test = X_test.drop('index',1)\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "# ## Model Pickle file import\n",
    "## TODO Import Pickle file for 1st Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.B-P Net Amount</th>\n",
       "      <th>SideB.ViewData.Accounting Net Amount</th>\n",
       "      <th>Trade_Date_match</th>\n",
       "      <th>Settle_Date_match</th>\n",
       "      <th>Amount_diff_2</th>\n",
       "      <th>Trade_date_diff</th>\n",
       "      <th>Settle_date_diff</th>\n",
       "      <th>SideA.ISIN_NA</th>\n",
       "      <th>SideB.ISIN_NA</th>\n",
       "      <th>ViewData.Combined Transaction Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SideA.ViewData.Settle Date</th>\n",
       "      <th>SideB.ViewData.Settle Date</th>\n",
       "      <th>SideA.ViewData._ID</th>\n",
       "      <th>SideB.ViewData._ID</th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "      <th>SideB.ViewData.Status</th>\n",
       "      <th>SideB.ViewData.BreakID_B_side</th>\n",
       "      <th>SideA.ViewData.Status</th>\n",
       "      <th>SideA.ViewData.BreakID_A_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123085.00</td>\n",
       "      <td>119500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3585.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paydownpaydown</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5fd051d515545831e8a1c686</td>\n",
       "      <td>5fd051d515545831e8a1c686</td>\n",
       "      <td>25_3791135288_Advent Geneva</td>\n",
       "      <td>15_3791133038_BNP Paribas</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1648950484</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1648950484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123085.00</td>\n",
       "      <td>21000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-102085.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paydowninterest</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5fd051d515545831e8a1c686</td>\n",
       "      <td>5fd051d515545831e8a1c66c</td>\n",
       "      <td>3_3791135288_Advent Geneva</td>\n",
       "      <td>15_3791133038_BNP Paribas</td>\n",
       "      <td>OB</td>\n",
       "      <td>1648950497</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1648950484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123085.00</td>\n",
       "      <td>3585.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-119500.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paydowncorp</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5fd051d515545831e8a1c686</td>\n",
       "      <td>5fd051d515545831e8a1c66d</td>\n",
       "      <td>3_3791139052_Advent Geneva</td>\n",
       "      <td>15_3791133038_BNP Paribas</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1653591430</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1648950484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946.85</td>\n",
       "      <td>119500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>117553.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corppaydown</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5fd051d515545831e8a1c66d</td>\n",
       "      <td>5fd051d515545831e8a1c686</td>\n",
       "      <td>25_3791135288_Advent Geneva</td>\n",
       "      <td>14_3791133038_BNP Paribas</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1648950484</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1653591430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1946.85</td>\n",
       "      <td>21000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19053.15</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corpinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5fd051d515545831e8a1c66d</td>\n",
       "      <td>5fd051d515545831e8a1c66c</td>\n",
       "      <td>3_3791135288_Advent Geneva</td>\n",
       "      <td>14_3791133038_BNP Paribas</td>\n",
       "      <td>OB</td>\n",
       "      <td>1648950497</td>\n",
       "      <td>SMB-OB</td>\n",
       "      <td>1653591430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>139.01</td>\n",
       "      <td>434.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295.07</td>\n",
       "      <td>33.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sellinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5fd076e21554581778dd3df3</td>\n",
       "      <td>5fd076e21554581778dd3e00</td>\n",
       "      <td>1_3791001046_Advent Geneva</td>\n",
       "      <td>1_3791071149_US BANK</td>\n",
       "      <td>OB</td>\n",
       "      <td>1469956890</td>\n",
       "      <td>OB</td>\n",
       "      <td>1563203798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>139.01</td>\n",
       "      <td>581.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>442.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sellpay</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5fd076e21554581778dd3df3</td>\n",
       "      <td>5fd076e21554581778dd3df8</td>\n",
       "      <td>2_3791044155_Advent Geneva</td>\n",
       "      <td>1_3791071149_US BANK</td>\n",
       "      <td>OB</td>\n",
       "      <td>1527672096</td>\n",
       "      <td>OB</td>\n",
       "      <td>1563203798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>139.01</td>\n",
       "      <td>484.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>344.99</td>\n",
       "      <td>61.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sellinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5fd076e21554581778dd3df3</td>\n",
       "      <td>5fd076e21554581778dd3dff</td>\n",
       "      <td>1_379962666_Advent Geneva</td>\n",
       "      <td>1_3791071149_US BANK</td>\n",
       "      <td>OB</td>\n",
       "      <td>1420803037</td>\n",
       "      <td>OB</td>\n",
       "      <td>1563203798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>139.01</td>\n",
       "      <td>476.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>337.71</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sellinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5fd076e21554581778dd3df3</td>\n",
       "      <td>5fd076e21554581778dd3dfd</td>\n",
       "      <td>1_3791126966_Advent Geneva</td>\n",
       "      <td>1_3791071149_US BANK</td>\n",
       "      <td>OB</td>\n",
       "      <td>1636975364</td>\n",
       "      <td>OB</td>\n",
       "      <td>1563203798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>139.01</td>\n",
       "      <td>499.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>360.90</td>\n",
       "      <td>92.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sellinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5fd076e21554581778dd3df3</td>\n",
       "      <td>5fd076e21554581778dd3df6</td>\n",
       "      <td>1_379919467_Advent Geneva</td>\n",
       "      <td>1_3791071149_US BANK</td>\n",
       "      <td>OB</td>\n",
       "      <td>1363640741</td>\n",
       "      <td>OB</td>\n",
       "      <td>1563203798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3005 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SideA.ViewData.B-P Net Amount  SideB.ViewData.Accounting Net Amount  \\\n",
       "0                         123085.00                             119500.00   \n",
       "1                         123085.00                              21000.00   \n",
       "2                         123085.00                               3585.00   \n",
       "3                           1946.85                             119500.00   \n",
       "4                           1946.85                              21000.00   \n",
       "...                             ...                                   ...   \n",
       "3000                         139.01                                434.08   \n",
       "3001                         139.01                                581.58   \n",
       "3002                         139.01                                484.00   \n",
       "3003                         139.01                                476.72   \n",
       "3004                         139.01                                499.91   \n",
       "\n",
       "      Trade_Date_match  Settle_Date_match  Amount_diff_2  Trade_date_diff  \\\n",
       "0                    1                  1       -3585.00              0.0   \n",
       "1                    0                  0     -102085.00             -1.0   \n",
       "2                    1                  1     -119500.00              0.0   \n",
       "3                    1                  1      117553.15              0.0   \n",
       "4                    0                  0       19053.15             -1.0   \n",
       "...                ...                ...            ...              ...   \n",
       "3000                 0                  0         295.07             33.0   \n",
       "3001                 1                  0         442.57              0.0   \n",
       "3002                 0                  0         344.99             61.0   \n",
       "3003                 0                  0         337.71            -61.0   \n",
       "3004                 0                  0         360.90             92.0   \n",
       "\n",
       "      Settle_date_diff  SideA.ISIN_NA  SideB.ISIN_NA  \\\n",
       "0                    0              0              0   \n",
       "1                   -1              0              0   \n",
       "2                    0              0              0   \n",
       "3                    0              0              0   \n",
       "4                   -1              0              0   \n",
       "...                ...            ...            ...   \n",
       "3000                53              1              1   \n",
       "3001                20              1              1   \n",
       "3002                81              1              1   \n",
       "3003               -41              1              1   \n",
       "3004               112              1              1   \n",
       "\n",
       "     ViewData.Combined Transaction Type  ... SideA.ViewData.Settle Date  \\\n",
       "0                        paydownpaydown  ...                          3   \n",
       "1                       paydowninterest  ...                          3   \n",
       "2                           paydowncorp  ...                          3   \n",
       "3                           corppaydown  ...                          3   \n",
       "4                          corpinterest  ...                          3   \n",
       "...                                 ...  ...                        ...   \n",
       "3000                       sellinterest  ...                          1   \n",
       "3001                            sellpay  ...                          1   \n",
       "3002                       sellinterest  ...                          1   \n",
       "3003                       sellinterest  ...                          1   \n",
       "3004                       sellinterest  ...                          1   \n",
       "\n",
       "     SideB.ViewData.Settle Date        SideA.ViewData._ID  \\\n",
       "0                             3  5fd051d515545831e8a1c686   \n",
       "1                             4  5fd051d515545831e8a1c686   \n",
       "2                             3  5fd051d515545831e8a1c686   \n",
       "3                             3  5fd051d515545831e8a1c66d   \n",
       "4                             4  5fd051d515545831e8a1c66d   \n",
       "...                         ...                       ...   \n",
       "3000                          4  5fd076e21554581778dd3df3   \n",
       "3001                          2  5fd076e21554581778dd3df3   \n",
       "3002                          4  5fd076e21554581778dd3df3   \n",
       "3003                          0  5fd076e21554581778dd3df3   \n",
       "3004                          1  5fd076e21554581778dd3df3   \n",
       "\n",
       "            SideB.ViewData._ID  SideB.ViewData.Side0_UniqueIds  \\\n",
       "0     5fd051d515545831e8a1c686     25_3791135288_Advent Geneva   \n",
       "1     5fd051d515545831e8a1c66c      3_3791135288_Advent Geneva   \n",
       "2     5fd051d515545831e8a1c66d      3_3791139052_Advent Geneva   \n",
       "3     5fd051d515545831e8a1c686     25_3791135288_Advent Geneva   \n",
       "4     5fd051d515545831e8a1c66c      3_3791135288_Advent Geneva   \n",
       "...                        ...                             ...   \n",
       "3000  5fd076e21554581778dd3e00      1_3791001046_Advent Geneva   \n",
       "3001  5fd076e21554581778dd3df8      2_3791044155_Advent Geneva   \n",
       "3002  5fd076e21554581778dd3dff       1_379962666_Advent Geneva   \n",
       "3003  5fd076e21554581778dd3dfd      1_3791126966_Advent Geneva   \n",
       "3004  5fd076e21554581778dd3df6       1_379919467_Advent Geneva   \n",
       "\n",
       "      SideA.ViewData.Side1_UniqueIds SideB.ViewData.Status  \\\n",
       "0          15_3791133038_BNP Paribas                SMB-OB   \n",
       "1          15_3791133038_BNP Paribas                    OB   \n",
       "2          15_3791133038_BNP Paribas                SMB-OB   \n",
       "3          14_3791133038_BNP Paribas                SMB-OB   \n",
       "4          14_3791133038_BNP Paribas                    OB   \n",
       "...                              ...                   ...   \n",
       "3000            1_3791071149_US BANK                    OB   \n",
       "3001            1_3791071149_US BANK                    OB   \n",
       "3002            1_3791071149_US BANK                    OB   \n",
       "3003            1_3791071149_US BANK                    OB   \n",
       "3004            1_3791071149_US BANK                    OB   \n",
       "\n",
       "      SideB.ViewData.BreakID_B_side  SideA.ViewData.Status  \\\n",
       "0                        1648950484                 SMB-OB   \n",
       "1                        1648950497                 SMB-OB   \n",
       "2                        1653591430                 SMB-OB   \n",
       "3                        1648950484                 SMB-OB   \n",
       "4                        1648950497                 SMB-OB   \n",
       "...                             ...                    ...   \n",
       "3000                     1469956890                     OB   \n",
       "3001                     1527672096                     OB   \n",
       "3002                     1420803037                     OB   \n",
       "3003                     1636975364                     OB   \n",
       "3004                     1363640741                     OB   \n",
       "\n",
       "      SideA.ViewData.BreakID_A_side  \n",
       "0                        1648950484  \n",
       "1                        1648950484  \n",
       "2                        1648950484  \n",
       "3                        1653591430  \n",
       "4                        1653591430  \n",
       "...                             ...  \n",
       "3000                     1563203798  \n",
       "3001                     1563203798  \n",
       "3002                     1563203798  \n",
       "3003                     1563203798  \n",
       "3004                     1563203798  \n",
       "\n",
       "[3005 rows x 28 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'OakTree_final_model2.sav'\n",
    "\n",
    "clf = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# ## Predictions\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions = clf.predict(X_test.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))\n",
    "# Probabilities for each class\n",
    "rf_probs = clf.predict_proba(X_test.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 1]\n",
    "\n",
    "probability_class_0 = clf.predict_proba(X_test.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side','SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 0]\n",
    "probability_class_1 = clf.predict_proba(X_test.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 1]\n",
    "\n",
    "probability_class_2 = clf.predict_proba(X_test.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side','SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 2]\n",
    "\n",
    "X_test['Predicted_action'] = rf_predictions\n",
    "X_test['probability_No_pair'] = probability_class_0\n",
    "X_test['probability_UMB'] = probability_class_1\n",
    "X_test['probability_UMR'] = probability_class_2\n",
    "X_test['Predicted_action'].value_counts()\n",
    "\n",
    "# ## Two Step Modeling\n",
    "\n",
    "X_test2 = test_file[model_cols_2]\n",
    "X_test2 = X_test2.reset_index()\n",
    "X_test2 = X_test2.drop('index',1)\n",
    "X_test2 = X_test2.fillna(0)\n",
    "\n",
    "X_test2.shape\n",
    "X_test2 = X_test2.drop_duplicates()\n",
    "X_test2 = X_test2.reset_index()\n",
    "X_test2 = X_test2.drop('index',1)\n",
    "\n",
    "X_test2.shape\n",
    "\n",
    "## TODO Import MOdel2 as per the two step modelling process\n",
    "\n",
    "filename2 = 'OakTree_final_model2_step_two.sav'\n",
    "clf2 = pickle.load(open(filename2, 'rb'))\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions2 = clf2.predict(X_test2.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs2 = clf2.predict_proba(X_test2.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 1]\n",
    "\n",
    "probability_class_0_two = clf2.predict_proba(X_test2.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side','SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 0]\n",
    "probability_class_1_two = clf2.predict_proba(X_test2.drop(['SideB.ViewData.Status','SideB.ViewData.BreakID_B_side', 'SideA.ViewData.Status','SideA.ViewData.BreakID_A_side','SideA.ViewData._ID','SideB.ViewData._ID','SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds'],1))[:, 1]\n",
    "\n",
    "X_test2['Predicted_action_2'] = rf_predictions2\n",
    "X_test2['probability_No_pair_2'] = probability_class_0_two\n",
    "X_test2['probability_UMB_2'] = probability_class_1_two\n",
    "\n",
    "X_test = pd.concat([X_test, X_test2[['Predicted_action_2','probability_No_pair_2','probability_UMB_2']]],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes made on 25-11-2020.\n",
    "#filepaths_X_test = '\\\\\\\\vitblrdevcons01\\\\Raman  Strategy ML 2.0\\\\All_Data\\\\' + client + '\\\\X_Test_for_Pratik_setup_' + setup_code + '_date_' + str(date_i) + '_2.csv'\n",
    "#X_test.to_csv(filepaths_X_test)\n",
    "\n",
    "# ## New Aggregation\n",
    "X_test['Tolerance_level'] = np.abs(X_test['probability_UMB_2'] - X_test['probability_No_pair_2'])\n",
    "b_side_agg = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "a_side_agg = X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "\n",
    "\n",
    "# ## UMR segregation\n",
    "umr_ids_0 = umr_seg(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(umr_ids_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 36)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['SideB.ViewData.Side0_UniqueIds'].isin(umr_ids_0) & (X_test['Predicted_action']=='UMR_One_to_One')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_umr_table = X_test[X_test['SideB.ViewData.Side0_UniqueIds'].isin(umr_ids_0) & (X_test['Predicted_action']=='UMR_One_to_One')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duplicate_ids_final_umr_table_Side0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6025cb27cd48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduplicate_ids_final_umr_table_Side0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mfinal_umr_table_duplicates_Side0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_umr_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfinal_umr_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduplicate_ids_final_umr_table_Side0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfinal_umr_table_duplicates_Side0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_umr_table_duplicates_Side0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideA.ViewData.Side1_UniqueIds'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideB.ViewData.BreakID_B_side'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideA.ViewData.BreakID_A_side'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Predicted_action'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_No_pair'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_UMB'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_UMR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#,'probability_UMT']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfinal_umr_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_umr_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfinal_umr_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduplicate_ids_final_umr_table_Side0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfinal_umr_table_side0_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_umr_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'duplicate_ids_final_umr_table_Side0' is not defined"
     ]
    }
   ],
   "source": [
    "if(len(duplicate_ids_final_umr_table_Side0) != 0):\n",
    "    final_umr_table_duplicates_Side0 = final_umr_table[final_umr_table['SideB.ViewData.Side0_UniqueIds'].isin(duplicate_ids_final_umr_table_Side0)]\n",
    "    final_umr_table_duplicates_Side0 = final_umr_table_duplicates_Side0[['SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds','SideB.ViewData.BreakID_B_side','SideA.ViewData.BreakID_A_side','Predicted_action','probability_No_pair','probability_UMB','probability_UMR']]#,'probability_UMT']]\n",
    "    final_umr_table = final_umr_table[~final_umr_table['SideB.ViewData.Side0_UniqueIds'].isin(duplicate_ids_final_umr_table_Side0)]\n",
    "    final_umr_table_side0_ids = list(set(final_umr_table['SideB.ViewData.Side0_UniqueIds']))\n",
    "    side0_umr_ids_to_remove_from_final_open_table = final_umr_table_side0_ids + list(duplicate_ids_final_umr_table_Side0)\n",
    "    \n",
    "else:\n",
    "    final_umr_table_duplicates_Side0 = pd.DataFrame()\n",
    "    final_umr_table_side0_ids = list(set(final_umr_table['SideB.ViewData.Side0_UniqueIds']))\n",
    "    side0_umr_ids_to_remove_from_final_open_table = final_umr_table_side0_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(duplicate_ids_final_umr_table_Side1) != 0):\n",
    "    final_umr_table_duplicates_Side1 = final_umr_table[final_umr_table['SideA.ViewData.Side1_UniqueIds'].isin(duplicate_ids_final_umr_table_Side1)]\n",
    "    final_umr_table_duplicates_Side1 = final_umr_table_duplicates_Side1[['SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds','SideB.ViewData.BreakID_B_side','SideA.ViewData.BreakID_A_side','Predicted_action','probability_No_pair','probability_UMB','probability_UMR']]#,'probability_UMT']]\n",
    "    final_umr_table = final_umr_table[~final_umr_table['SideA.ViewData.Side1_UniqueIds'].isin(duplicate_ids_final_umr_table_Side1)]\n",
    "    final_umr_table_side1_ids = list(set(final_umr_table['SideA.ViewData.Side1_UniqueIds'])) \n",
    "    side1_umr_ids_to_remove_from_final_open_table = final_umr_table_side1_ids + list(duplicate_ids_final_umr_table_Side1)\n",
    "\n",
    "else:\n",
    "    final_umr_table_duplicates_Side1 = pd.DataFrame()\n",
    "    final_umr_table_side1_ids = list(set(final_umr_table['SideA.ViewData.Side1_UniqueIds']))\n",
    "    side1_umr_ids_to_remove_from_final_open_table = final_umr_table_side1_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(side1_umr_ids_to_remove_from_final_open_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 1st Prediction Table for One to One UMR\n",
    "    \n",
    "\n",
    "final_umr_table = final_umr_table[['SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds','SideB.ViewData.BreakID_B_side','SideA.ViewData.BreakID_A_side','Predicted_action','probability_No_pair','probability_UMB','probability_UMR']]\n",
    "\n",
    "# ## No-Pair segregation\n",
    "\n",
    "no_pair_ids_b_side, no_pair_ids_a_side = no_pair_seg(X_test)\n",
    "\n",
    "X_test[(X_test['SideA.ViewData.Side1_UniqueIds'].isin(no_pair_ids_a_side))]['Predicted_action_2'].value_counts()\n",
    "\n",
    "X_test.groupby(['SideA.ViewData.Side1_UniqueIds'])['Predicted_action_2'].unique().reset_index()\n",
    "\n",
    "X_test[X_test['SideA.ViewData.Side1_UniqueIds'].isin(no_pair_ids_a_side)]['Predicted_action_2'].value_counts()\n",
    "\n",
    "final_open_table = X_test[(X_test['SideB.ViewData.Side0_UniqueIds'].isin(no_pair_ids_b_side)) | (X_test['SideA.ViewData.Side1_UniqueIds'].isin(no_pair_ids_a_side))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'side1_umr_ids_to_remove_from_final_open_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c3fcd0880762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_open_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_open_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfinal_open_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideA.ViewData.Side1_UniqueIds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside1_umr_ids_to_remove_from_final_open_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_open_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_open_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfinal_open_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mside0_umr_ids_to_remove_from_final_open_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinal_open_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_open_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SideB.ViewData.Side0_UniqueIds'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideA.ViewData.Side1_UniqueIds'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideB.ViewData.BreakID_B_side'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SideA.ViewData.BreakID_A_side'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Predicted_action_2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_No_pair_2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_UMB_2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'probability_UMR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'side1_umr_ids_to_remove_from_final_open_table' is not defined"
     ]
    }
   ],
   "source": [
    "final_open_table = final_open_table[~final_open_table['SideA.ViewData.Side1_UniqueIds'].isin(side1_umr_ids_to_remove_from_final_open_table)]\n",
    "final_open_table = final_open_table[~final_open_table['SideB.ViewData.Side0_UniqueIds'].isin(side0_umr_ids_to_remove_from_final_open_table)]\n",
    "\n",
    "final_open_table = final_open_table[['SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds','SideB.ViewData.BreakID_B_side','SideA.ViewData.BreakID_A_side','Predicted_action_2','probability_No_pair_2','probability_UMB_2','probability_UMR']]\n",
    "\n",
    "final_open_table['probability_UMR'] = 0.00010\n",
    "final_open_table = final_open_table.rename(columns = {'Predicted_action_2':'Predicted_action','probability_No_pair_2':'probability_No_pair','probability_UMB_2':'probability_UMB'})\n",
    "\n",
    "\n",
    "b_side_open_table = final_open_table.groupby('SideB.ViewData.Side0_UniqueIds')[['probability_No_pair','probability_UMB','probability_UMR']].mean().reset_index()\n",
    "a_side_open_table = final_open_table.groupby('SideA.ViewData.Side1_UniqueIds')[['probability_No_pair','probability_UMB','probability_UMR']].mean().reset_index()\n",
    "\n",
    "a_side_open_table = a_side_open_table[a_side_open_table['SideA.ViewData.Side1_UniqueIds'].isin(no_pair_ids_a_side)]\n",
    "b_side_open_table = b_side_open_table[b_side_open_table['SideB.ViewData.Side0_UniqueIds'].isin(no_pair_ids_b_side)]\n",
    "\n",
    "b_side_open_table = b_side_open_table.reset_index().drop('index',1)\n",
    "a_side_open_table = a_side_open_table.reset_index().drop('index',1)\n",
    "\n",
    "final_no_pair_table = pd.concat([a_side_open_table,b_side_open_table], axis=0)\n",
    "final_no_pair_table = final_no_pair_table.reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_no_pair_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-82c98a5339dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_no_pair_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_no_pair_table' is not defined"
     ]
    }
   ],
   "source": [
    "final_no_pair_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#final_no_pair_table = pd.merge(final_no_pair_table, final_open_table[['SideA.ViewData.Side1_UniqueIds','SideA.ViewData.BreakID_A_side']].drop_duplicates(), on = 'SideA.ViewData.Side1_UniqueIds', how='left')\n",
    "#final_no_pair_table = pd.merge(final_no_pair_table, final_open_table[['SideB.ViewData.Side0_UniqueIds','SideB.ViewData.BreakID_B_side']].drop_duplicates(), on = 'SideB.ViewData.Side0_UniqueIds', how='left')\n",
    "#\n",
    "\n",
    "final_no_pair_table = normalize_final_no_pair_table_col_names(fun_final_no_pair_table = final_no_pair_table)\n",
    "final_no_pair_table_copy = final_no_pair_table.copy()\n",
    "\n",
    "final_no_pair_table_copy['ViewData.Side0_UniqueIds'] = final_no_pair_table_copy['ViewData.Side0_UniqueIds'].astype(str)\n",
    "final_no_pair_table_copy['ViewData.Side1_UniqueIds'] = final_no_pair_table_copy['ViewData.Side1_UniqueIds'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViewData.Side1_UniqueIds</th>\n",
       "      <th>ViewData.Side0_UniqueIds</th>\n",
       "      <th>probability_No_pair</th>\n",
       "      <th>probability_UMB</th>\n",
       "      <th>probability_UMR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100_3791127028_The Bank of New York Mellon</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.934582</td>\n",
       "      <td>0.065418</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100_3791149966_Royal Bank of Canada</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>101_3791149966_Royal Bank of Canada</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>102_3791149966_Royal Bank of Canada</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>103_3791149966_Royal Bank of Canada</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>756</td>\n",
       "      <td>nan</td>\n",
       "      <td>98_3791149966_Advent Geneva</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>757</td>\n",
       "      <td>nan</td>\n",
       "      <td>99_3791149966_Advent Geneva</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>758</td>\n",
       "      <td>nan</td>\n",
       "      <td>9_3791025073_Advent Geneva</td>\n",
       "      <td>0.997568</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>759</td>\n",
       "      <td>nan</td>\n",
       "      <td>9_3791149051_Advent Geneva</td>\n",
       "      <td>0.949525</td>\n",
       "      <td>0.050475</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>nan</td>\n",
       "      <td>9_3791149966_Advent Geneva</td>\n",
       "      <td>0.998337</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>761 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ViewData.Side1_UniqueIds     ViewData.Side0_UniqueIds  \\\n",
       "0    100_3791127028_The Bank of New York Mellon                          nan   \n",
       "1           100_3791149966_Royal Bank of Canada                          nan   \n",
       "2           101_3791149966_Royal Bank of Canada                          nan   \n",
       "3           102_3791149966_Royal Bank of Canada                          nan   \n",
       "4           103_3791149966_Royal Bank of Canada                          nan   \n",
       "..                                          ...                          ...   \n",
       "756                                         nan  98_3791149966_Advent Geneva   \n",
       "757                                         nan  99_3791149966_Advent Geneva   \n",
       "758                                         nan   9_3791025073_Advent Geneva   \n",
       "759                                         nan   9_3791149051_Advent Geneva   \n",
       "760                                         nan   9_3791149966_Advent Geneva   \n",
       "\n",
       "     probability_No_pair  probability_UMB  probability_UMR  \n",
       "0               0.934582         0.065418           0.0001  \n",
       "1               0.998973         0.001027           0.0001  \n",
       "2               0.998908         0.001092           0.0001  \n",
       "3               0.998973         0.001027           0.0001  \n",
       "4               0.998908         0.001092           0.0001  \n",
       "..                   ...              ...              ...  \n",
       "756             0.998304         0.001696           0.0001  \n",
       "757             0.998304         0.001696           0.0001  \n",
       "758             0.997568         0.002432           0.0001  \n",
       "759             0.949525         0.050475           0.0001  \n",
       "760             0.998337         0.001663           0.0001  \n",
       "\n",
       "[761 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_no_pair_table_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "final_no_pair_table_copy.loc[final_no_pair_table_copy['ViewData.Side0_UniqueIds']=='None','Side0_1_UniqueIds'] = final_no_pair_table_copy['ViewData.Side1_UniqueIds']\n",
    "final_no_pair_table_copy.loc[final_no_pair_table_copy['ViewData.Side1_UniqueIds']=='None','Side0_1_UniqueIds'] = final_no_pair_table_copy['ViewData.Side0_UniqueIds']\n",
    "\n",
    "final_no_pair_table_copy.loc[final_no_pair_table_copy['ViewData.Side0_UniqueIds']=='nan','Side0_1_UniqueIds'] = final_no_pair_table_copy['ViewData.Side1_UniqueIds']\n",
    "final_no_pair_table_copy.loc[final_no_pair_table_copy['ViewData.Side1_UniqueIds']=='nan','Side0_1_UniqueIds'] = final_no_pair_table_copy['ViewData.Side0_UniqueIds']\n",
    "\n",
    "del final_no_pair_table_copy['ViewData.Side0_UniqueIds']\n",
    "del final_no_pair_table_copy['ViewData.Side1_UniqueIds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62_3791114597_Advent Geneva     25\n",
       "44_3791011889_Advent Geneva     25\n",
       "60_3791001204_Advent Geneva     25\n",
       "61_3791001204_Advent Geneva     25\n",
       "64_3791114597_Advent Geneva     25\n",
       "                                ..\n",
       "107_3791006998_Advent Geneva     1\n",
       "423_3791088743_Advent Geneva     1\n",
       "14_3791006998_Advent Geneva      1\n",
       "99_3791118350_Advent Geneva      1\n",
       "11_3791118350_Advent Geneva      1\n",
       "Name: SideB.ViewData.Side0_UniqueIds, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OTM,MTO,OTO code begin\n",
    "\n",
    "# ## Remove Open Ids\n",
    "\n",
    "umr_ids_a_side = final_umr_table['SideA.ViewData.Side1_UniqueIds'].unique()\n",
    "umr_ids_b_side = final_umr_table['SideB.ViewData.Side0_UniqueIds'].unique()\n",
    "\n",
    "### Remove Open IDs\n",
    "\n",
    "X_test_left = X_test[~(X_test['SideB.ViewData.Side0_UniqueIds'].isin(no_pair_ids_b_side))]\n",
    "X_test_left = X_test_left[~(X_test_left['SideA.ViewData.Side1_UniqueIds'].isin(no_pair_ids_a_side))]\n",
    "\n",
    "## Remove UMR IDs\n",
    "\n",
    "X_test_left = X_test_left[~(X_test_left['SideA.ViewData.Side1_UniqueIds'].isin(umr_ids_a_side))]\n",
    "X_test_left = X_test_left[~(X_test_left['SideB.ViewData.Side0_UniqueIds'].isin(umr_ids_b_side))]\n",
    "\n",
    "\n",
    "X_test_left = X_test_left.reset_index().drop('index',1)\n",
    "\n",
    "# ## One to One UMB segregation\n",
    "\n",
    "X_test_left['Predicted_action_2'].value_counts()\n",
    "\n",
    "### IDs left after removing UMR ids from 0 and 1 side\n",
    "\n",
    "X_test_left = X_test_left[~(X_test_left['SideA.ViewData.Side1_UniqueIds'].isin(final_umr_table['SideA.ViewData.Side1_UniqueIds']))]\n",
    "\n",
    "X_test_left = X_test_left[~(X_test_left['SideB.ViewData.Side0_UniqueIds'].isin(final_umr_table['SideB.ViewData.Side0_UniqueIds']))]\n",
    "\n",
    "X_test_left.shape\n",
    "X_test_left['Predicted_action_2'].value_counts()\n",
    "\n",
    "X_test_left = X_test_left.drop(['SideB.ViewData._ID','SideA.ViewData._ID'],1).drop_duplicates()\n",
    "X_test_left = X_test_left.reset_index().drop('index',1)\n",
    "\n",
    "for key in X_test_left['SideB.ViewData.Side0_UniqueIds'].unique():\n",
    "    umb_ids_1 = X_test_left[(X_test_left['SideB.ViewData.Side0_UniqueIds']==key) & (X_test_left['Predicted_action_2']=='UMB_One_to_One')]['SideA.ViewData.Side1_UniqueIds'].unique()\n",
    "\n",
    "X_test_left['SideB.ViewData.Side0_UniqueIds'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before changes on 17-12-2020\n",
    "# # ## UMR One to Many and Many to One \n",
    "\n",
    "# # ### One to Many\n",
    "# cliff_for_loop = 16\n",
    "\n",
    "# threshold_0 = X_test['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count')\n",
    "# threshold_0_umb = threshold_0[threshold_0['count']>cliff_for_loop]['index'].unique()\n",
    "# threshold_0_without_umb = threshold_0[threshold_0['count']<=cliff_for_loop]['index'].unique()\n",
    "\n",
    "# exceptions_0_umb = X_test[X_test['Predicted_action_2']=='UMB_One_to_One']['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count')\n",
    "# exceptions_0_umb_ids = exceptions_0_umb[exceptions_0_umb['count']>cliff_for_loop]['index'].unique()\n",
    "\n",
    "# many_ids_1 = []\n",
    "# one_id_0 = []\n",
    "# amount_array =[]\n",
    "# for key in X_test[~((X_test['SideB.ViewData.Side0_UniqueIds'].isin(exceptions_0_umb_ids)) | (X_test['SideB.ViewData.Side0_UniqueIds'].isin(final_umr_table['SideB.ViewData.Side0_UniqueIds'])))]['SideB.ViewData.Side0_UniqueIds'].unique():\n",
    "#     print(key)\n",
    "    \n",
    "#     if key in threshold_0_umb:\n",
    "\n",
    "#         values =  X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideA.ViewData.B-P Net Amount'].values\n",
    "#         net_sum = X_test[X_test['SideB.ViewData.Side0_UniqueIds']==key]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "\n",
    "#         #memo = dict()\n",
    "#         #print(values)\n",
    "#         #print(net_sum)\n",
    "\n",
    "#         if subSum(values,net_sum) == []: \n",
    "#             #print(\"There are no valid subsets.\")\n",
    "#             amount_array = ['NULL']\n",
    "#         else:\n",
    "#             amount_array = subSum(values,net_sum)\n",
    "\n",
    "#             id1_aggregation = X_test[(X_test['SideA.ViewData.B-P Net Amount'].isin(amount_array)) & (X_test['SideB.ViewData.Side0_UniqueIds']==key)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "#             id0_unique = key       \n",
    "\n",
    "#             if len(id1_aggregation)>1: \n",
    "#                 many_ids_1.append(id1_aggregation)\n",
    "#                 one_id_0.append(id0_unique)\n",
    "#             else:\n",
    "#                 pass\n",
    "            \n",
    "#     else:\n",
    "#         values =  X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key)]['SideA.ViewData.B-P Net Amount'].values\n",
    "#         net_sum = X_test[X_test['SideB.ViewData.Side0_UniqueIds']==key]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "\n",
    "#         #memo = dict()\n",
    "#         #print(values)\n",
    "#         #print(net_sum)\n",
    "\n",
    "#         if subSum(values,net_sum) == []: \n",
    "#             #print(\"There are no valid subsets.\")\n",
    "#             amount_array = ['NULL']\n",
    "#         else:\n",
    "#             amount_array = subSum(values,net_sum)\n",
    "\n",
    "#             id1_aggregation = X_test[(X_test['SideA.ViewData.B-P Net Amount'].isin(amount_array)) & (X_test['SideB.ViewData.Side0_UniqueIds']==key)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "#             id0_unique = key       \n",
    "\n",
    "#             if len(id1_aggregation)>1: \n",
    "#                 many_ids_1.append(id1_aggregation)\n",
    "#                 one_id_0.append(id0_unique)\n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "# umr_otm_table = pd.DataFrame(one_id_0)\n",
    "\n",
    "# if(umr_otm_table.empty == False):\n",
    "#     umr_otm_table.columns = ['SideB.ViewData.Side0_UniqueIds']\n",
    "#     umr_otm_table['SideA.ViewData.Side1_UniqueIds'] =many_ids_1 \n",
    "# else:\n",
    "#     temp_umr_otm_table_message = 'No One to many found'\n",
    "#     print(temp_umr_otm_table_message)\n",
    "\n",
    "\n",
    "# # ## Removing duplicate IDs from side 1\n",
    "\n",
    "# if(len(many_ids_1) == 0):\n",
    "#     unique_many_ids_1 = ['None']\n",
    "# else:\n",
    "#     unique_many_ids_1 = np.unique(np.concatenate(many_ids_1))\n",
    "\n",
    "# dup_ids_0 = []\n",
    "# for i in unique_many_ids_1:\n",
    "#     count =0\n",
    "#     for j in many_ids_1:\n",
    "#         if i in j:\n",
    "#             count = count+1\n",
    "#             if count==2:\n",
    "#                 dup_ids_0.append(i)\n",
    "#                 break             \n",
    "            \n",
    "# dup_array_0 = []\n",
    "# for i in many_ids_1:\n",
    "#     #print(i)\n",
    "#     if any(x in dup_ids_0 for x in i):\n",
    "#         dup_array_0.append(i)\n",
    "        \n",
    "\n",
    "# ### Converting array to list\n",
    "# dup_array_0_list = []\n",
    "# for i in dup_array_0:\n",
    "#     dup_array_0_list.append(list(i))\n",
    "    \n",
    "# many_ids_1_list =[] \n",
    "# for j in many_ids_1:\n",
    "#     many_ids_1_list.append(list(j))\n",
    "    \n",
    "    \n",
    "# filtered_otm = [i for i in many_ids_1_list if not i in dup_array_0_list]\n",
    "\n",
    "# one_id_0_final = []\n",
    "# for i, j in zip(many_ids_1_list, one_id_0):\n",
    "#     if i in filtered_otm:\n",
    "#         one_id_0_final.append(j) \n",
    "\n",
    "# umr_otm_table = umr_otm_table[umr_otm_table['SideB.ViewData.Side0_UniqueIds'].isin(one_id_0_final)]\n",
    "\n",
    "# filtered_otm_flat = [item for sublist in filtered_otm for item in sublist]\n",
    "\n",
    "\n",
    "# # ## Including UMR double count into OTM\n",
    "# umr_double_count = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].value_counts().reset_index(name='count')\n",
    "# umr_double_count = umr_double_count[(umr_double_count['Predicted_action']=='UMR_One_to_One') & (umr_double_count['count']==2)]\n",
    "\n",
    "# umr_double_count_left = umr_double_count[~umr_double_count['SideB.ViewData.Side0_UniqueIds'].isin(umr_otm_table['SideB.ViewData.Side0_UniqueIds'].unique())]\n",
    "\n",
    "# pb_ids_otm_left = []\n",
    "# acc_id_single = []\n",
    "\n",
    "# for key in umr_double_count_left['SideB.ViewData.Side0_UniqueIds'].unique():\n",
    "#     acc_amount = X_test[X_test['SideB.ViewData.Side0_UniqueIds']==key]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "#     pb_ids_otm = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & ((X_test['SideB.ViewData.Accounting Net Amount']==X_test['SideA.ViewData.B-P Net Amount']) | (X_test['SideB.ViewData.Accounting Net Amount']== (-1)*X_test['SideA.ViewData.B-P Net Amount']))]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "#     pb_ids_otm_left.append(pb_ids_otm)\n",
    "#     acc_id_single.append(key)\n",
    "\n",
    "# umr_otm_table_double_count = pd.DataFrame(acc_id_single)\n",
    "# if(umr_otm_table_double_count.shape[0] != 0):\n",
    "#     umr_otm_table_double_count.columns = ['SideB.ViewData.Side0_UniqueIds']\n",
    "\n",
    "#     umr_otm_table_double_count['SideA.ViewData.Side1_UniqueIds'] = pb_ids_otm_left\n",
    "\n",
    "#     umr_otm_table_final = pd.concat([umr_otm_table, umr_otm_table_double_count], axis=0)\n",
    "# else:\n",
    "#     umr_otm_table_final = umr_otm_table.copy()\n",
    "    \n",
    "# if(umr_otm_table_final.empty == False):\n",
    "#     umr_otm_table_final = umr_otm_table_final.reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# After changes on 17-12-2020\n",
    "cliff_for_loop = 16\n",
    "\n",
    "threshold_0 = X_test['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count')\n",
    "threshold_0_umb = threshold_0[threshold_0['count']>cliff_for_loop]['index'].unique()\n",
    "threshold_0_without_umb = threshold_0[threshold_0['count']<=cliff_for_loop]['index'].unique()\n",
    "\n",
    "exceptions_0_umb = X_test[X_test['Predicted_action_2']!='UMR_One_to_One']['SideB.ViewData.Side0_UniqueIds'].value_counts().reset_index(name='count')\n",
    "exceptions_0_umb_ids = exceptions_0_umb[exceptions_0_umb['count']>cliff_for_loop]['index'].unique()\n",
    "\n",
    "def subSum(numbers,total):\n",
    "    for length in range(1, 3):\n",
    "        if len(numbers) < length or length < 1:\n",
    "            return []\n",
    "        for index,number in enumerate(numbers):\n",
    "            if length == 1 and np.isclose(number, total, atol=0.25).any():\n",
    "                return [number]\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset: \n",
    "                return [number] + subset\n",
    "        return []\n",
    "               \n",
    "\n",
    "#null_value ='No'\n",
    "many_ids_1 = []\n",
    "one_id_0 = []\n",
    "amount_array =[]\n",
    "\n",
    "loop_count = 0\n",
    "for key in exceptions_0_umb['index'].unique():\n",
    "#for key in ['553_1251128974_Advent Geneva','12_3791149966_Advent Geneva']:\n",
    "    loop_count = loop_count + 1\n",
    "    print(loop_count)\n",
    "    if key in exceptions_0_umb_ids:\n",
    "        sort_data = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & (X_test['Predicted_action_2']!='UMR_One_to_One')].sort_values(by = ['probability_UMB_2'], ascending =[False])\n",
    "        sort_data = sort_data.reset_index().drop('index',1)\n",
    "#        Change made on 17-12-2020. As per Pratik, we will take the first 15 values, as oaktree is smaller data. For weiss, we take 8 as weiss is too big and it takes too much time with value of 15\n",
    "#        sort_data = sort_data.loc[0:10,:]\n",
    "        sort_data = sort_data.loc[0:10,:]\n",
    "        sort_data = sort_data.drop_duplicates(subset=['SideA.ViewData.B-P Net Amount'])\n",
    "        sort_data = sort_data.reset_index().drop('index',1)\n",
    "        #print(sort_data)\n",
    "\n",
    "        values =  sort_data['SideA.ViewData.B-P Net Amount'].values\n",
    "        net_sum = sort_data['SideB.ViewData.Accounting Net Amount'].max()\n",
    "\n",
    "        #memo = dict()\n",
    "        #print(values)\n",
    "        #print(net_sum)\n",
    "\n",
    "        if subSum(values,net_sum) == []: \n",
    "            #print(\"There are no valid subsets.\")\n",
    "            amount_array = ['NULL']\n",
    "        else:\n",
    "            amount_array = subSum(values,net_sum)\n",
    "\n",
    "            id1_aggregation = sort_data[(sort_data['SideA.ViewData.B-P Net Amount'].isin(amount_array)) & (sort_data['SideB.ViewData.Side0_UniqueIds']==key)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "            id0_unique = key       \n",
    "\n",
    "            if len(id1_aggregation)>1: \n",
    "                many_ids_1.append(id1_aggregation)\n",
    "                one_id_0.append(id0_unique)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        sort_data2 = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & (X_test['Predicted_action_2']!='UMR_One_to_One')].sort_values(by = ['probability_UMB_2'], ascending =[False])\n",
    "        sort_data2 = sort_data2.reset_index().drop('index',1)\n",
    "\n",
    "#        Change made on 08-12-2020. As per Pratik, we will take the first 8 values, not 10 in order to not overpredict otm and mto umrs\n",
    "#        sort_data2 = sort_data2.loc[0:10,:]\n",
    "        sort_data2 = sort_data2.loc[0:10,:]\n",
    "        \n",
    "        sort_data2 = sort_data2.drop_duplicates(subset=['SideA.ViewData.B-P Net Amount'])\n",
    "        sort_data2 = sort_data2.reset_index().drop('index',1)\n",
    "        \n",
    "\n",
    "        values =  sort_data2['SideA.ViewData.B-P Net Amount'].values\n",
    "        net_sum = sort_data2['SideB.ViewData.Accounting Net Amount'].max()\n",
    "        #values =  X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideA.ViewData.B-P Net Amount'].values\n",
    "        #net_sum = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key)& (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "\n",
    "        #memo = dict()\n",
    "        #print(values)\n",
    "        #print(net_sum)\n",
    "\n",
    "        if subSum(values,net_sum) == []: \n",
    "            #print(\"There are no valid subsets.\")\n",
    "            amount_array = ['NULL']\n",
    "        else:\n",
    "            amount_array = subSum(values,net_sum)\n",
    "\n",
    "            id1_aggregation = sort_data2[(sort_data2['SideA.ViewData.B-P Net Amount'].isin(amount_array)) & (sort_data2['SideB.ViewData.Side0_UniqueIds']==key)]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "            id0_unique = key       \n",
    "\n",
    "            if len(id1_aggregation)>1: \n",
    "                many_ids_1.append(id1_aggregation)\n",
    "                one_id_0.append(id0_unique)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "umr_otm_table = pd.DataFrame(one_id_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End change\n",
    "\n",
    "\n",
    "if umr_otm_table.empty == False:\n",
    "    umr_otm_table.columns = ['SideB.ViewData.Side0_UniqueIds']\n",
    "    umr_otm_table['SideA.ViewData.Side1_UniqueIds'] =many_ids_1\n",
    "else:\n",
    "    print('No One to Many found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7_3791139058_Advent Geneva</td>\n",
       "      <td>[3_3791139058_Credit Suisse, 5_3791139058_Cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8_3791139405_Advent Geneva</td>\n",
       "      <td>[31_3791137060_Northern Trust, 30_3791137060_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225_3791127144_Advent Geneva</td>\n",
       "      <td>[112_3791139278_State Street, 111_3791139278_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89_3791139278_Advent Geneva</td>\n",
       "      <td>[112_3791139278_State Street, 111_3791139278_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82_3791139278_Advent Geneva</td>\n",
       "      <td>[112_3791139278_State Street, 111_3791139278_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62_3791139105_Advent Geneva</td>\n",
       "      <td>[97_3791133104_The Bank of New York Mellon, 2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131_3791139278_Advent Geneva</td>\n",
       "      <td>[50_3791139278_State Street, 48_3791139278_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52_3791139278_Advent Geneva</td>\n",
       "      <td>[68_3791137344_State Street, 67_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58_3791139278_Advent Geneva</td>\n",
       "      <td>[71_3791137344_State Street, 70_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SideB.ViewData.Side0_UniqueIds  \\\n",
       "0     7_3791139058_Advent Geneva   \n",
       "1     8_3791139405_Advent Geneva   \n",
       "2   225_3791127144_Advent Geneva   \n",
       "3    89_3791139278_Advent Geneva   \n",
       "4    82_3791139278_Advent Geneva   \n",
       "5    62_3791139105_Advent Geneva   \n",
       "6   131_3791139278_Advent Geneva   \n",
       "7    52_3791139278_Advent Geneva   \n",
       "8    58_3791139278_Advent Geneva   \n",
       "\n",
       "                      SideA.ViewData.Side1_UniqueIds  \n",
       "0  [3_3791139058_Credit Suisse, 5_3791139058_Cred...  \n",
       "1  [31_3791137060_Northern Trust, 30_3791137060_N...  \n",
       "2  [112_3791139278_State Street, 111_3791139278_S...  \n",
       "3  [112_3791139278_State Street, 111_3791139278_S...  \n",
       "4  [112_3791139278_State Street, 111_3791139278_S...  \n",
       "5  [97_3791133104_The Bank of New York Mellon, 2_...  \n",
       "6  [50_3791139278_State Street, 48_3791139278_Sta...  \n",
       "7  [68_3791137344_State Street, 67_3791137344_Sta...  \n",
       "8  [71_3791137344_State Street, 70_3791137344_Sta...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_otm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[X_test['SideB.ViewData.Side0_UniqueIds']=='12_3791149966_Advent Geneva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## Removing duplicate IDs from side 1\n",
    "\n",
    "if len(many_ids_1)!=0:\n",
    "    unique_many_ids_1 = np.unique(np.concatenate(many_ids_1))\n",
    "else:\n",
    "    unique_many_ids_1 = np.array(['None'])\n",
    "\n",
    "dup_ids_0 = []\n",
    "for i in unique_many_ids_1:\n",
    "    count =0\n",
    "    for j in many_ids_1:\n",
    "        if i in j:\n",
    "            count = count+1\n",
    "            if count==2:\n",
    "                dup_ids_0.append(i)\n",
    "                break             \n",
    "            \n",
    "dup_array_0 = []\n",
    "for i in many_ids_1:\n",
    "    #print(i)\n",
    "    if any(x in dup_ids_0 for x in i):\n",
    "        dup_array_0.append(i)\n",
    "        \n",
    "\n",
    "### Converting array to list\n",
    "dup_array_0_list = []\n",
    "for i in dup_array_0:\n",
    "    dup_array_0_list.append(list(i))\n",
    "    \n",
    "many_ids_1_list =[] \n",
    "for j in many_ids_1:\n",
    "    many_ids_1_list.append(list(j))\n",
    "    \n",
    "    \n",
    "filtered_otm = [i for i in many_ids_1_list if not i in dup_array_0_list]\n",
    "\n",
    "one_id_0_final = []\n",
    "for i, j in zip(many_ids_1_list, one_id_0):\n",
    "    if i in filtered_otm:\n",
    "        one_id_0_final.append(j) \n",
    "\n",
    "#meo[meo['ViewData.Side0_UniqueIds'] =='162_153156748_Advent Geneva']\n",
    "\n",
    "if len(one_id_0_final)!=0:\n",
    "    #unique_many_ids_1 = np.unique(np.concatenate(many_ids_1))\n",
    "    one_id_0_final = one_id_0_final\n",
    "else:\n",
    "    one_id_0_final = np.array(['None'])\n",
    "    \n",
    "if umr_otm_table.empty == False:    \n",
    "    umr_otm_table = umr_otm_table[umr_otm_table['SideB.ViewData.Side0_UniqueIds'].isin(one_id_0_final)]\n",
    "\n",
    "filtered_otm_flat = [item for sublist in filtered_otm for item in sublist]\n",
    "\n",
    "# ## Including UMR double count into OTM\n",
    "\n",
    "umr_double_count = X_test.groupby(['SideB.ViewData.Side0_UniqueIds'])['Predicted_action'].value_counts().reset_index(name='count')\n",
    "umr_double_count = umr_double_count[(umr_double_count['Predicted_action']=='UMR_One_to_One') & (umr_double_count['count']==2)]\n",
    "\n",
    "\n",
    "if umr_otm_table.empty == False:\n",
    "    sideb_unique = umr_otm_table['SideB.ViewData.Side0_UniqueIds'].unique()\n",
    "else:\n",
    "    sideb_unique =['None']\n",
    "if umr_double_count.empty == False:\n",
    "\n",
    "    umr_double_count_left = umr_double_count[~umr_double_count['SideB.ViewData.Side0_UniqueIds'].isin(sideb_unique)]\n",
    "\n",
    "pb_ids_otm_left = []\n",
    "acc_id_single = []\n",
    "\n",
    "for key in umr_double_count_left['SideB.ViewData.Side0_UniqueIds'].unique():\n",
    "    acc_amount = X_test[X_test['SideB.ViewData.Side0_UniqueIds']==key]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "    pb_ids_otm = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & ((X_test['SideB.ViewData.Accounting Net Amount']==X_test['SideA.ViewData.B-P Net Amount']) | (X_test['SideB.ViewData.Accounting Net Amount']== (-1)*X_test['SideA.ViewData.B-P Net Amount']))]['SideA.ViewData.Side1_UniqueIds'].values\n",
    "    pb_ids_otm_left.append(pb_ids_otm)\n",
    "    acc_id_single.append(key)\n",
    "    \n",
    "umr_otm_table_double_count = pd.DataFrame(acc_id_single)\n",
    "umr_otm_table_double_count.columns = ['SideB.ViewData.Side0_UniqueIds']\n",
    "\n",
    "umr_otm_table_double_count['SideA.ViewData.Side1_UniqueIds'] = pb_ids_otm_left\n",
    "\n",
    "umr_otm_table_final = pd.concat([umr_otm_table, umr_otm_table_double_count], axis=0)\n",
    "\n",
    "umr_otm_table_final = umr_otm_table_final.reset_index().drop('index',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7_3791139058_Advent Geneva</td>\n",
       "      <td>[3_3791139058_Credit Suisse, 5_3791139058_Cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8_3791139405_Advent Geneva</td>\n",
       "      <td>[31_3791137060_Northern Trust, 30_3791137060_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62_3791139105_Advent Geneva</td>\n",
       "      <td>[97_3791133104_The Bank of New York Mellon, 2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131_3791139278_Advent Geneva</td>\n",
       "      <td>[50_3791139278_State Street, 48_3791139278_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52_3791139278_Advent Geneva</td>\n",
       "      <td>[68_3791137344_State Street, 67_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58_3791139278_Advent Geneva</td>\n",
       "      <td>[71_3791137344_State Street, 70_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>695_379919610_Advent Geneva</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SideB.ViewData.Side0_UniqueIds  \\\n",
       "0     7_3791139058_Advent Geneva   \n",
       "1     8_3791139405_Advent Geneva   \n",
       "2    62_3791139105_Advent Geneva   \n",
       "3   131_3791139278_Advent Geneva   \n",
       "4    52_3791139278_Advent Geneva   \n",
       "5    58_3791139278_Advent Geneva   \n",
       "6    695_379919610_Advent Geneva   \n",
       "\n",
       "                      SideA.ViewData.Side1_UniqueIds  \n",
       "0  [3_3791139058_Credit Suisse, 5_3791139058_Cred...  \n",
       "1  [31_3791137060_Northern Trust, 30_3791137060_N...  \n",
       "2  [97_3791133104_The Bank of New York Mellon, 2_...  \n",
       "3  [50_3791139278_State Street, 48_3791139278_Sta...  \n",
       "4  [68_3791137344_State Street, 67_3791137344_Sta...  \n",
       "5  [71_3791137344_State Street, 70_3791137344_Sta...  \n",
       "6                                                 []  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_otm_table_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before changes on 17-12-2020\n",
    "# # ### Many to One\n",
    "\n",
    "# cliff_for_loop = 16\n",
    "\n",
    "# threshold_1 = X_test['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count')\n",
    "# threshold_1_umb = threshold_1[threshold_1['count']>cliff_for_loop]['index'].unique()\n",
    "# threshold_1_without_umb = threshold_1[threshold_1['count']<=cliff_for_loop]['index'].unique()\n",
    "\n",
    "# exceptions_1_umb = X_test[X_test['Predicted_action_2']=='UMB_One_to_One']['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count')\n",
    "# exceptions_1_umb_ids = exceptions_1_umb[exceptions_1_umb['count']>cliff_for_loop]['index'].unique()\n",
    "\n",
    "# def subSum(numbers,total):\n",
    "#     for length in range(1, 4):\n",
    "#         if len(numbers) < length or length < 1:\n",
    "#             return []\n",
    "#         for index,number in enumerate(numbers):\n",
    "#             if length == 1 and np.isclose(number, total,atol=0.25).any():\n",
    "#                 return [number]\n",
    "#             subset = subSum(numbers[index+1:],total-number)\n",
    "#             if subset: \n",
    "#                 return [number] + subset\n",
    "#         return []\n",
    "\n",
    "# many_ids_0 = []\n",
    "# one_id_1 = []\n",
    "# amount_array2 =[]\n",
    "# for key in X_test[~((X_test['SideA.ViewData.Side1_UniqueIds'].isin(exceptions_1_umb_ids)) |(X_test['SideA.ViewData.Side1_UniqueIds'].isin(final_umr_table['SideA.ViewData.Side1_UniqueIds'])))]['SideA.ViewData.Side1_UniqueIds'].unique():\n",
    "#     #if key not in ['1174_379879573_State Street','201_379823765_State Street']:\n",
    "#     print(key)\n",
    "#     if key in threshold_1_umb:\n",
    "\n",
    "#         values2 =  X_test[(X_test['SideA.ViewData.Side1_UniqueIds']==key) & (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideB.ViewData.Accounting Net Amount'].values\n",
    "#         net_sum2 = X_test[X_test['SideA.ViewData.Side1_UniqueIds']==key]['SideA.ViewData.B-P Net Amount'].max()\n",
    "\n",
    "#         #memo = dict()\n",
    "\n",
    "#         if subSum(values2,net_sum2) == []: \n",
    "#             amount_array2 =[]\n",
    "#             #print(\"There are no valid subsets.\")\n",
    "\n",
    "#         else:\n",
    "#             amount_array2 = subSum(values2,net_sum2)\n",
    "\n",
    "#             id0_aggregation = X_test[(X_test['SideB.ViewData.Accounting Net Amount'].isin(amount_array2)) & (X_test['SideA.ViewData.Side1_UniqueIds']==key)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "#             id1_unique = key       \n",
    "\n",
    "#             if len(id0_aggregation)>1: \n",
    "#                 many_ids_0.append(id0_aggregation)\n",
    "#                 one_id_1.append(id1_unique)\n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "#     else:\n",
    "#         values2 =  X_test[(X_test['SideA.ViewData.Side1_UniqueIds']==key)]['SideB.ViewData.Accounting Net Amount'].values\n",
    "#         net_sum2 = X_test[X_test['SideA.ViewData.Side1_UniqueIds']==key]['SideA.ViewData.B-P Net Amount'].max()\n",
    "\n",
    "#         #memo = dict()\n",
    "\n",
    "#         if subSum(values2,net_sum2) == []: \n",
    "#             amount_array2 =[]\n",
    "#             #print(\"There are no valid subsets.\")\n",
    "\n",
    "#         else:\n",
    "#             amount_array2 = subSum(values2,net_sum2)\n",
    "\n",
    "#             id0_aggregation = X_test[(X_test['SideB.ViewData.Accounting Net Amount'].isin(amount_array2)) & (X_test['SideA.ViewData.Side1_UniqueIds']==key)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "#             id1_unique = key       \n",
    "\n",
    "#             if len(id0_aggregation)>1: \n",
    "#                 many_ids_0.append(id0_aggregation)\n",
    "#                 one_id_1.append(id1_unique)\n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "# umr_mto_table = pd.DataFrame(one_id_1)\n",
    "# if(umr_mto_table.empty == False):\n",
    "#     umr_mto_table.columns = ['SideA.ViewData.Side1_UniqueIds']\n",
    "#     umr_mto_table['SideB.ViewData.Side0_UniqueIds'] =many_ids_0 \n",
    "# #    umr_mto_table = umr_mto_table[umr_mto_table['SideA.ViewData.Side1_UniqueIds'].isin(one_id_1_final)]\n",
    "# #    for i in range(0,umr_mto_table.shape[0]):\n",
    "# #        umr_mto_table['BreakID_Side0'].iloc[i] = list(meo_df[meo_df['ViewData.Side0_UniqueIds'].isin(umr_mto_table['SideB.ViewData.Side0_UniqueIds'].values[i])]['ViewData.BreakID'])\n",
    "#         #        fun_otm_mto_df['BreakID_Side1'].iloc[i] = list(fun_meo_df[fun_meo_df['ViewData.Side1_UniqueIds'].isin(fun_otm_mto_df['SideA.ViewData.Side1_UniqueIds'].iloc[i])]['ViewData.BreakID'])\n",
    "\n",
    "# else:\n",
    "#     temp_umr_mto_table_message = 'No Many to One found'\n",
    "#     print(temp_umr_mto_table_message)\n",
    "\n",
    "# # ## Removing duplicate IDs from side 0\n",
    "\n",
    "# if(len(many_ids_0) == 0):\n",
    "#     unique_many_ids_0 = ['None']\n",
    "# else:\n",
    "#     unique_many_ids_0 = np.unique(np.concatenate(many_ids_0))\n",
    "\n",
    "# dup_ids_1 = []\n",
    "# for i in unique_many_ids_0:\n",
    "#     count =0\n",
    "#     for j in many_ids_0:\n",
    "#         if i in j:\n",
    "#             count = count+1\n",
    "#             if count==2:\n",
    "#                 dup_ids_1.append(i)\n",
    "#                 break             \n",
    "            \n",
    "# dup_array_1 = []\n",
    "# for i in many_ids_0:\n",
    "#     #print(i)\n",
    "#     if any(x in dup_ids_1 for x in i):\n",
    "#         dup_array_1.append(i)\n",
    "        \n",
    "\n",
    "# ### Converting array to list\n",
    "# dup_array_1_list = []\n",
    "# for i in dup_array_1:\n",
    "#     dup_array_1_list.append(list(i))\n",
    "    \n",
    "# many_ids_0_list =[] \n",
    "# for j in many_ids_0:\n",
    "#     many_ids_0_list.append(list(j))\n",
    "    \n",
    "    \n",
    "# filtered_mto = [i for i in many_ids_0_list if not i in dup_array_1_list]\n",
    "\n",
    "# one_id_1_final = []\n",
    "# for i, j in zip(many_ids_0_list, one_id_1):\n",
    "#     if i in filtered_mto:\n",
    "#         one_id_1_final.append(j) \n",
    "\n",
    "\n",
    "# #pd.set_option('max_columns',50)\n",
    "# if(umr_mto_table.empty == False):\n",
    "#     umr_mto_table = umr_mto_table[umr_mto_table['SideA.ViewData.Side1_UniqueIds'].isin(one_id_1_final)]\n",
    "#     umr_mto_table['BreakID_Side0'] = umr_mto_table.apply(lambda x: list(meo_df[meo_df['ViewData.Side0_UniqueIds'].isin(umr_otm_table_final['SideB.ViewData.Side0_UniqueIds'])]['ViewData.BreakID']), axis=1)\n",
    "#     for i in range(0,umr_mto_table.shape[0]):\n",
    "#         umr_mto_table['BreakID_Side0'].iloc[i] = list(meo_df[meo_df['ViewData.Side0_UniqueIds'].isin(umr_mto_table['SideB.ViewData.Side0_UniqueIds'].values[i])]['ViewData.BreakID'])#        fun_otm_mto_df['BreakID_Side1'].iloc[i] = list(fun_meo_df[fun_meo_df['ViewData.Side1_UniqueIds'].isin(fun_otm_mto_df['SideA.ViewData.Side1_UniqueIds'].iloc[i])]['ViewData.BreakID'])\n",
    "\n",
    "# else:\n",
    "#     temp_umr_mto_table_message = 'No Many to One found'\n",
    "#     print(temp_umr_mto_table_message)\n",
    "\n",
    "\n",
    "# filtered_mto_flat = [item for sublist in filtered_mto for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "cliff_for_loop = 17\n",
    "\n",
    "threshold_1 = X_test['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count')\n",
    "threshold_1_umb = threshold_1[threshold_1['count']>cliff_for_loop]['index'].unique()\n",
    "threshold_1_without_umb = threshold_1[threshold_1['count']<=cliff_for_loop]['index'].unique()\n",
    "\n",
    "exceptions_1_umb = X_test[X_test['Predicted_action_2']!='UMR_One_to_One']['SideA.ViewData.Side1_UniqueIds'].value_counts().reset_index(name='count')\n",
    "exceptions_1_umb_ids = exceptions_1_umb[exceptions_1_umb['count']>cliff_for_loop]['index'].unique()\n",
    "\n",
    "def subSum(numbers,total):\n",
    "    for length in range(1, 3):\n",
    "        if len(numbers) < length or length < 1:\n",
    "            return []\n",
    "        for index,number in enumerate(numbers):\n",
    "            if length == 1 and np.isclose(number, total, atol=0.02).any():\n",
    "                return [number]\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset: \n",
    "                return [number] + subset\n",
    "        return []\n",
    "               \n",
    "#null_value ='No'\n",
    "many_ids_0 = []\n",
    "one_id_1 = []\n",
    "amount_array_2 =[]\n",
    "\n",
    "loop_count = 0\n",
    "for key in exceptions_1_umb['index'].unique():\n",
    "#for key in ['553_1251128974_Advent Geneva','409_1251128952_Advent Geneva']:\n",
    "    #print(key)\n",
    "    loop_count = loop_count + 1\n",
    "    print(loop_count)\n",
    "    if key in exceptions_1_umb_ids:\n",
    "        sort_data = X_test[(X_test['SideA.ViewData.Side1_UniqueIds']==key) & (X_test['Predicted_action_2']!='UMR_One_to_One')].sort_values(by = ['probability_UMB_2'], ascending =[False])\n",
    "        sort_data = sort_data.reset_index().drop('index',1)\n",
    "        \n",
    "#        Change made on 08-12-2020. As per Pratik, we will take the first 15 values, as oaktree is smaller data. For weiss, we take 8 as weiss is too big and it takes too much time with value of 15\n",
    "#        sort_data = sort_data.loc[0:10,:]\n",
    "        sort_data = sort_data.loc[0:11,:]\n",
    "        sort_data = sort_data.drop_duplicates(subset=['SideB.ViewData.Accounting Net Amount'])\n",
    "        sort_data = sort_data.reset_index().drop('index',1)\n",
    "        #print(sort_data)\n",
    "\n",
    "        values2 =  sort_data['SideB.ViewData.Accounting Net Amount'].values\n",
    "        net_sum2 = sort_data['SideA.ViewData.B-P Net Amount'].max()\n",
    "\n",
    "        #memo = dict()\n",
    "        #print(values)\n",
    "        #print(net_sum)\n",
    "\n",
    "        if subSum(values2,net_sum2) == []: \n",
    "            #print(\"There are no valid subsets.\")\n",
    "            amount_array2 = ['NULL']\n",
    "        else:\n",
    "            amount_array2 = subSum(values2,net_sum2)\n",
    "\n",
    "            id0_aggregation = sort_data[(sort_data['SideB.ViewData.Accounting Net Amount'].isin(amount_array2)) & (sort_data['SideA.ViewData.Side1_UniqueIds']==key)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "            id1_unique = key       \n",
    "\n",
    "            if len(id0_aggregation)>1: \n",
    "                many_ids_0.append(id0_aggregation)\n",
    "                one_id_1.append(id1_unique)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        sort_data2 = X_test[(X_test['SideA.ViewData.Side1_UniqueIds']==key) & (X_test['Predicted_action_2']!='UMR_One_to_One')].sort_values(by = ['probability_UMB_2'], ascending =[False])\n",
    "        sort_data2 = sort_data2.reset_index().drop('index',1)\n",
    "        \n",
    "#        Change made on 08-12-2020. As per Pratik, we will take the first 8 values, not 10 in order to not overpredict otm and mto umrs\n",
    "#        sort_data2 = sort_data2.loc[0:10,:]\n",
    "        sort_data2 = sort_data2.loc[0:11,:]\n",
    "        sort_data2 = sort_data2.drop_duplicates(subset=['SideB.ViewData.Accounting Net Amount'])\n",
    "        sort_data2 = sort_data2.reset_index().drop('index',1)\n",
    "        \n",
    "\n",
    "        values2 =  sort_data2['SideB.ViewData.Accounting Net Amount'].values\n",
    "        net_sum2 = sort_data2['SideA.ViewData.B-P Net Amount'].max()\n",
    "        #values =  X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key) & (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideA.ViewData.B-P Net Amount'].values\n",
    "        #net_sum = X_test[(X_test['SideB.ViewData.Side0_UniqueIds']==key)& (X_test['Predicted_action_2']=='UMB_One_to_One')]['SideB.ViewData.Accounting Net Amount'].max()\n",
    "\n",
    "        #memo = dict()\n",
    "        #print(values)\n",
    "        #print(net_sum)\n",
    "\n",
    "\n",
    "        if subSum(values2,net_sum2) == []: \n",
    "            #print(\"There are no valid subsets.\")\n",
    "            amount_array2 = ['NULL']\n",
    "        else:\n",
    "            amount_array2 = subSum(values2,net_sum2)\n",
    "\n",
    "            id0_aggregation = sort_data2[(sort_data2['SideB.ViewData.Accounting Net Amount'].isin(amount_array2)) & (sort_data2['SideA.ViewData.Side1_UniqueIds']==key)]['SideB.ViewData.Side0_UniqueIds'].values\n",
    "            id1_unique = key       \n",
    "\n",
    "            if len(id0_aggregation)>1: \n",
    "                many_ids_0.append(id0_aggregation)\n",
    "                one_id_1.append(id1_unique)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "umr_mto_table = pd.DataFrame(one_id_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End change\n",
    "\n",
    "if umr_mto_table.empty == False:\n",
    "    umr_mto_table.columns = ['SideA.ViewData.Side1_UniqueIds']\n",
    "    umr_mto_table['SideB.ViewData.Side0_UniqueIds'] =many_ids_0\n",
    "else:\n",
    "    print('No Many to One found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110_3791139278_State Street</td>\n",
       "      <td>[85_3791139278_Advent Geneva, 84_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109_3791139278_State Street</td>\n",
       "      <td>[83_3791139278_Advent Geneva, 84_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_3791139058_Credit Suisse</td>\n",
       "      <td>[8_3791094530_Advent Geneva, 9_3791094530_Adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95_3791137344_State Street</td>\n",
       "      <td>[39_3791139278_Advent Geneva, 48_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90_3791137344_State Street</td>\n",
       "      <td>[44_3791139278_Advent Geneva, 35_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89_3791137344_State Street</td>\n",
       "      <td>[34_3791139278_Advent Geneva, 43_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91_3791137344_State Street</td>\n",
       "      <td>[36_3791139278_Advent Geneva, 45_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3_379804133_US BANK</td>\n",
       "      <td>[2_3791044155_Advent Geneva, 1_379919467_Adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3_3791139127_JP Morgan</td>\n",
       "      <td>[23_3791139127_Advent Geneva, 22_3791139127_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9_3791129289_State Street</td>\n",
       "      <td>[63_3791114597_Advent Geneva, 61_3791114597_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7_3791046333_State Street</td>\n",
       "      <td>[49_3791048390_Advent Geneva, 50_3791048390_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7_3791088743_State Street</td>\n",
       "      <td>[63_3791114597_Advent Geneva, 61_3791114597_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>86_3791137344_State Street</td>\n",
       "      <td>[33_3791139278_Advent Geneva, 24_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>85_3791137344_State Street</td>\n",
       "      <td>[32_3791139278_Advent Geneva, 23_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15_3791133038_BNP Paribas</td>\n",
       "      <td>[25_3791135288_Advent Geneva, 3_3791139052_Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8_3791133038_BNP Paribas</td>\n",
       "      <td>[15_3791135288_Advent Geneva, 12_3791139052_Ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SideA.ViewData.Side1_UniqueIds  \\\n",
       "0     110_3791139278_State Street   \n",
       "1     109_3791139278_State Street   \n",
       "2      2_3791139058_Credit Suisse   \n",
       "3      95_3791137344_State Street   \n",
       "4      90_3791137344_State Street   \n",
       "5      89_3791137344_State Street   \n",
       "6      91_3791137344_State Street   \n",
       "7             3_379804133_US BANK   \n",
       "8          3_3791139127_JP Morgan   \n",
       "9       9_3791129289_State Street   \n",
       "10      7_3791046333_State Street   \n",
       "11      7_3791088743_State Street   \n",
       "12     86_3791137344_State Street   \n",
       "13     85_3791137344_State Street   \n",
       "14      15_3791133038_BNP Paribas   \n",
       "15       8_3791133038_BNP Paribas   \n",
       "\n",
       "                       SideB.ViewData.Side0_UniqueIds  \n",
       "0   [85_3791139278_Advent Geneva, 84_3791139278_Ad...  \n",
       "1   [83_3791139278_Advent Geneva, 84_3791139278_Ad...  \n",
       "2   [8_3791094530_Advent Geneva, 9_3791094530_Adve...  \n",
       "3   [39_3791139278_Advent Geneva, 48_3791139278_Ad...  \n",
       "4   [44_3791139278_Advent Geneva, 35_3791139278_Ad...  \n",
       "5   [34_3791139278_Advent Geneva, 43_3791139278_Ad...  \n",
       "6   [36_3791139278_Advent Geneva, 45_3791139278_Ad...  \n",
       "7   [2_3791044155_Advent Geneva, 1_379919467_Adven...  \n",
       "8   [23_3791139127_Advent Geneva, 22_3791139127_Ad...  \n",
       "9   [63_3791114597_Advent Geneva, 61_3791114597_Ad...  \n",
       "10  [49_3791048390_Advent Geneva, 50_3791048390_Ad...  \n",
       "11  [63_3791114597_Advent Geneva, 61_3791114597_Ad...  \n",
       "12  [33_3791139278_Advent Geneva, 24_3791139278_Ad...  \n",
       "13  [32_3791139278_Advent Geneva, 23_3791139278_Ad...  \n",
       "14  [25_3791135288_Advent Geneva, 3_3791139052_Adv...  \n",
       "15  [15_3791135288_Advent Geneva, 12_3791139052_Ad...  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_mto_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.B-P Net Amount</th>\n",
       "      <th>SideB.ViewData.Accounting Net Amount</th>\n",
       "      <th>Trade_Date_match</th>\n",
       "      <th>Settle_Date_match</th>\n",
       "      <th>Amount_diff_2</th>\n",
       "      <th>Trade_date_diff</th>\n",
       "      <th>Settle_date_diff</th>\n",
       "      <th>SideA.ISIN_NA</th>\n",
       "      <th>SideB.ISIN_NA</th>\n",
       "      <th>ViewData.Combined Transaction Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SideA.ViewData.Status</th>\n",
       "      <th>SideA.ViewData.BreakID_A_side</th>\n",
       "      <th>Predicted_action</th>\n",
       "      <th>probability_No_pair</th>\n",
       "      <th>probability_UMB</th>\n",
       "      <th>probability_UMR</th>\n",
       "      <th>Predicted_action_2</th>\n",
       "      <th>probability_No_pair_2</th>\n",
       "      <th>probability_UMB_2</th>\n",
       "      <th>Tolerance_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SideA.ViewData.B-P Net Amount, SideB.ViewData.Accounting Net Amount, Trade_Date_match, Settle_Date_match, Amount_diff_2, Trade_date_diff, Settle_date_diff, SideA.ISIN_NA, SideB.ISIN_NA, ViewData.Combined Transaction Type, Combined_Desc, Combined_TType, abs_amount_flag, tt_map_flag, All_key_nan, new_key_match, new_pb1, SideB.Date, SideA.ViewData.Settle Date, SideB.ViewData.Settle Date, SideA.ViewData._ID, SideB.ViewData._ID, SideB.ViewData.Side0_UniqueIds, SideA.ViewData.Side1_UniqueIds, SideB.ViewData.Status, SideB.ViewData.BreakID_B_side, SideA.ViewData.Status, SideA.ViewData.BreakID_A_side, Predicted_action, probability_No_pair, probability_UMB, probability_UMR, Predicted_action_2, probability_No_pair_2, probability_UMB_2, Tolerance_level]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['SideB.ViewData.Side0_UniqueIds']=='80_3791139278_Advent Geneva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'77_3791122313_Advent Geneva,39_3791123345_Advent Geneva'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meo[meo['ViewData.Side1_UniqueIds']=='46_3791135409_State Street']['ViewData.Side0_UniqueIds'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ViewData.BreakID</th>\n",
       "      <th>ViewData.Status</th>\n",
       "      <th>ViewData.SPM ID</th>\n",
       "      <th>ViewData.Cancel Amount</th>\n",
       "      <th>ViewData.Currency</th>\n",
       "      <th>ViewData.Custodian Account</th>\n",
       "      <th>ViewData.Trade Date</th>\n",
       "      <th>ViewData.Transaction ID</th>\n",
       "      <th>ViewData.Investment ID</th>\n",
       "      <th>...</th>\n",
       "      <th>ViewData.Interest Amount Difference</th>\n",
       "      <th>ViewData.Accounting Trade Expenses</th>\n",
       "      <th>ViewData.Cust Trade Expenses</th>\n",
       "      <th>ViewData.Trade Expenses Difference</th>\n",
       "      <th>ViewData.Accounting OTE Custodian Account</th>\n",
       "      <th>ViewData.Cust OTE Custodian Account</th>\n",
       "      <th>ViewData.OTE Custodian Account Difference</th>\n",
       "      <th>ViewData.Accounting LoanX ID</th>\n",
       "      <th>ViewData.Cust LoanX ID</th>\n",
       "      <th>ViewData.LoanX ID Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>1654004372</td>\n",
       "      <td>OB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-787.13</td>\n",
       "      <td>EUR</td>\n",
       "      <td>OKMF86800402</td>\n",
       "      <td>11-25-2020</td>\n",
       "      <td>6676053</td>\n",
       "      <td>Cognita (Lernen Bidco Ltd) TL-B E+4.25% (FL: 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  ViewData.BreakID ViewData.Status  ViewData.SPM ID  \\\n",
       "167         167        1654004372              OB              NaN   \n",
       "\n",
       "     ViewData.Cancel Amount ViewData.Currency ViewData.Custodian Account  \\\n",
       "167                 -787.13               EUR               OKMF86800402   \n",
       "\n",
       "    ViewData.Trade Date ViewData.Transaction ID  \\\n",
       "167          11-25-2020                 6676053   \n",
       "\n",
       "                                ViewData.Investment ID  ...  \\\n",
       "167  Cognita (Lernen Bidco Ltd) TL-B E+4.25% (FL: 0...  ...   \n",
       "\n",
       "    ViewData.Interest Amount Difference ViewData.Accounting Trade Expenses  \\\n",
       "167                                 NaN                                NaN   \n",
       "\n",
       "    ViewData.Cust Trade Expenses ViewData.Trade Expenses Difference  \\\n",
       "167                          NaN                                NaN   \n",
       "\n",
       "    ViewData.Accounting OTE Custodian Account  \\\n",
       "167                                       NaN   \n",
       "\n",
       "     ViewData.Cust OTE Custodian Account  \\\n",
       "167                                  NaN   \n",
       "\n",
       "     ViewData.OTE Custodian Account Difference  ViewData.Accounting LoanX ID  \\\n",
       "167                                        NaN                           NaN   \n",
       "\n",
       "     ViewData.Cust LoanX ID ViewData.LoanX ID Difference  \n",
       "167                     NaN                          NaN  \n",
       "\n",
       "[1 rows x 372 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meo[meo['ViewData.Side0_UniqueIds']=='80_3791139278_Advent Geneva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.B-P Net Amount</th>\n",
       "      <th>SideB.ViewData.Accounting Net Amount</th>\n",
       "      <th>Trade_Date_match</th>\n",
       "      <th>Settle_Date_match</th>\n",
       "      <th>Amount_diff_2</th>\n",
       "      <th>Trade_date_diff</th>\n",
       "      <th>Settle_date_diff</th>\n",
       "      <th>SideA.ISIN_NA</th>\n",
       "      <th>SideB.ISIN_NA</th>\n",
       "      <th>ViewData.Combined Transaction Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SideA.ViewData.Status</th>\n",
       "      <th>SideA.ViewData.BreakID_A_side</th>\n",
       "      <th>Predicted_action</th>\n",
       "      <th>probability_No_pair</th>\n",
       "      <th>probability_UMB</th>\n",
       "      <th>probability_UMR</th>\n",
       "      <th>Predicted_action_2</th>\n",
       "      <th>probability_No_pair_2</th>\n",
       "      <th>probability_UMB_2</th>\n",
       "      <th>Tolerance_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>105.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-976.66</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.800895</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1077.82</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.203725</td>\n",
       "      <td>0.794967</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>857.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-224.57</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.289461</td>\n",
       "      <td>0.705487</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.426803</td>\n",
       "      <td>0.573197</td>\n",
       "      <td>0.146395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>384.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-697.36</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.760177</td>\n",
       "      <td>0.237948</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>-47389.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-48471.81</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internaldrawdown</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.996588</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.968176</td>\n",
       "      <td>0.031824</td>\n",
       "      <td>0.936352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>710.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-371.00</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalrevenue</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.929960</td>\n",
       "      <td>0.069625</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.968176</td>\n",
       "      <td>0.031824</td>\n",
       "      <td>0.936352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>91.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-990.03</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.766488</td>\n",
       "      <td>0.231755</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>73.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1008.59</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.800895</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>44.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1037.12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.208573</td>\n",
       "      <td>0.790193</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>710.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-371.00</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalrevenue</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.765608</td>\n",
       "      <td>0.233194</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.933993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>122318.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121236.65</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalsell</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.997863</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.998851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>45.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1036.23</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.938140</td>\n",
       "      <td>0.060983</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.726075</td>\n",
       "      <td>0.273925</td>\n",
       "      <td>0.452150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>567.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-513.95</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.253271</td>\n",
       "      <td>0.744540</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>198.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-883.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.191307</td>\n",
       "      <td>0.807633</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>UMB_One_to_One</td>\n",
       "      <td>0.219877</td>\n",
       "      <td>0.780123</td>\n",
       "      <td>0.560246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>56.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1025.79</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>0.220228</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>1233.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.37</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalrelease</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.906076</td>\n",
       "      <td>0.091822</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.548292</td>\n",
       "      <td>0.451708</td>\n",
       "      <td>0.096584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>20.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1061.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.786721</td>\n",
       "      <td>0.211568</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>102.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-979.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.766488</td>\n",
       "      <td>0.231755</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>248.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-833.07</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.796171</td>\n",
       "      <td>0.202175</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>-89868.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-90950.00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalbuy</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.998461</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.840957</td>\n",
       "      <td>0.159043</td>\n",
       "      <td>0.681914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>1081.85</td>\n",
       "      <td>6.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1075.82</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>internalinterest</td>\n",
       "      <td>...</td>\n",
       "      <td>SDB</td>\n",
       "      <td>1543331765</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.787006</td>\n",
       "      <td>0.211278</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>No-Pair</td>\n",
       "      <td>0.618286</td>\n",
       "      <td>0.381714</td>\n",
       "      <td>0.236572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SideA.ViewData.B-P Net Amount  SideB.ViewData.Accounting Net Amount  \\\n",
       "4168                        1081.85                                105.19   \n",
       "4169                        1081.85                                  4.03   \n",
       "4170                        1081.85                                857.28   \n",
       "4171                        1081.85                                384.49   \n",
       "4172                        1081.85                             -47389.96   \n",
       "4173                        1081.85                                710.85   \n",
       "4174                        1081.85                                 91.82   \n",
       "4175                        1081.85                                 73.26   \n",
       "4176                        1081.85                                 44.73   \n",
       "4177                        1081.85                                710.85   \n",
       "4178                        1081.85                             122318.50   \n",
       "4179                        1081.85                                 45.62   \n",
       "4180                        1081.85                                567.90   \n",
       "4181                        1081.85                                198.50   \n",
       "4182                        1081.85                                 56.06   \n",
       "4183                        1081.85                               1233.22   \n",
       "4184                        1081.85                                 20.73   \n",
       "4185                        1081.85                                102.60   \n",
       "4186                        1081.85                                248.78   \n",
       "4187                        1081.85                             -89868.15   \n",
       "4188                        1081.85                                  6.03   \n",
       "\n",
       "      Trade_Date_match  Settle_Date_match  Amount_diff_2  Trade_date_diff  \\\n",
       "4168                 0                  0        -976.66              8.0   \n",
       "4169                 0                  0       -1077.82              8.0   \n",
       "4170                 0                  0        -224.57              8.0   \n",
       "4171                 0                  0        -697.36            100.0   \n",
       "4172                 0                  0      -48471.81            -50.0   \n",
       "4173                 0                  0        -371.00            -50.0   \n",
       "4174                 0                  0        -990.03            100.0   \n",
       "4175                 0                  0       -1008.59              8.0   \n",
       "4176                 0                  0       -1037.12              8.0   \n",
       "4177                 0                  0        -371.00            -67.0   \n",
       "4178                 0                  0      121236.65            -68.0   \n",
       "4179                 0                  0       -1036.23            100.0   \n",
       "4180                 0                  0        -513.95              8.0   \n",
       "4181                 0                  0        -883.35              8.0   \n",
       "4182                 0                  0       -1025.79            100.0   \n",
       "4183                 0                  0         151.37             55.0   \n",
       "4184                 0                  0       -1061.12            100.0   \n",
       "4185                 0                  0        -979.25            100.0   \n",
       "4186                 0                  0        -833.07            100.0   \n",
       "4187                 0                  0      -90950.00             65.0   \n",
       "4188                 0                  0       -1075.82            100.0   \n",
       "\n",
       "      Settle_date_diff  SideA.ISIN_NA  SideB.ISIN_NA  \\\n",
       "4168                 8              1              1   \n",
       "4169                 8              1              1   \n",
       "4170                 8              1              1   \n",
       "4171               100              1              1   \n",
       "4172               -50              1              1   \n",
       "4173               -50              1              1   \n",
       "4174               100              1              1   \n",
       "4175                 8              1              1   \n",
       "4176                 8              1              1   \n",
       "4177               -67              1              1   \n",
       "4178               -69              1              1   \n",
       "4179               100              1              1   \n",
       "4180                 8              1              1   \n",
       "4181                 8              1              1   \n",
       "4182               100              1              1   \n",
       "4183                55              1              1   \n",
       "4184               100              1              1   \n",
       "4185               100              1              1   \n",
       "4186               100              1              1   \n",
       "4187                55              1              1   \n",
       "4188               100              1              1   \n",
       "\n",
       "     ViewData.Combined Transaction Type  ... SideA.ViewData.Status  \\\n",
       "4168                   internalinterest  ...                   SDB   \n",
       "4169                   internalinterest  ...                   SDB   \n",
       "4170                   internalinterest  ...                   SDB   \n",
       "4171                   internalinterest  ...                   SDB   \n",
       "4172                   internaldrawdown  ...                   SDB   \n",
       "4173                    internalrevenue  ...                   SDB   \n",
       "4174                   internalinterest  ...                   SDB   \n",
       "4175                   internalinterest  ...                   SDB   \n",
       "4176                   internalinterest  ...                   SDB   \n",
       "4177                    internalrevenue  ...                   SDB   \n",
       "4178                       internalsell  ...                   SDB   \n",
       "4179                   internalinterest  ...                   SDB   \n",
       "4180                   internalinterest  ...                   SDB   \n",
       "4181                   internalinterest  ...                   SDB   \n",
       "4182                   internalinterest  ...                   SDB   \n",
       "4183                    internalrelease  ...                   SDB   \n",
       "4184                   internalinterest  ...                   SDB   \n",
       "4185                   internalinterest  ...                   SDB   \n",
       "4186                   internalinterest  ...                   SDB   \n",
       "4187                        internalbuy  ...                   SDB   \n",
       "4188                   internalinterest  ...                   SDB   \n",
       "\n",
       "     SideA.ViewData.BreakID_A_side  Predicted_action  probability_No_pair  \\\n",
       "4168                    1543331765    UMB_One_to_One             0.197900   \n",
       "4169                    1543331765    UMB_One_to_One             0.203725   \n",
       "4170                    1543331765    UMB_One_to_One             0.289461   \n",
       "4171                    1543331765           No-Pair             0.760177   \n",
       "4172                    1543331765           No-Pair             0.996588   \n",
       "4173                    1543331765           No-Pair             0.929960   \n",
       "4174                    1543331765           No-Pair             0.766488   \n",
       "4175                    1543331765    UMB_One_to_One             0.197900   \n",
       "4176                    1543331765    UMB_One_to_One             0.208573   \n",
       "4177                    1543331765           No-Pair             0.765608   \n",
       "4178                    1543331765           No-Pair             0.997863   \n",
       "4179                    1543331765           No-Pair             0.938140   \n",
       "4180                    1543331765    UMB_One_to_One             0.253271   \n",
       "4181                    1543331765    UMB_One_to_One             0.191307   \n",
       "4182                    1543331765           No-Pair             0.778039   \n",
       "4183                    1543331765           No-Pair             0.906076   \n",
       "4184                    1543331765           No-Pair             0.786721   \n",
       "4185                    1543331765           No-Pair             0.766488   \n",
       "4186                    1543331765           No-Pair             0.796171   \n",
       "4187                    1543331765           No-Pair             0.998461   \n",
       "4188                    1543331765           No-Pair             0.787006   \n",
       "\n",
       "      probability_UMB  probability_UMR Predicted_action_2  \\\n",
       "4168         0.800895         0.001204     UMB_One_to_One   \n",
       "4169         0.794967         0.001309     UMB_One_to_One   \n",
       "4170         0.705487         0.005052     UMB_One_to_One   \n",
       "4171         0.237948         0.001875            No-Pair   \n",
       "4172         0.003400         0.000012            No-Pair   \n",
       "4173         0.069625         0.000415            No-Pair   \n",
       "4174         0.231755         0.001757            No-Pair   \n",
       "4175         0.800895         0.001204     UMB_One_to_One   \n",
       "4176         0.790193         0.001234     UMB_One_to_One   \n",
       "4177         0.233194         0.001198            No-Pair   \n",
       "4178         0.002074         0.000063            No-Pair   \n",
       "4179         0.060983         0.000877            No-Pair   \n",
       "4180         0.744540         0.002189     UMB_One_to_One   \n",
       "4181         0.807633         0.001060     UMB_One_to_One   \n",
       "4182         0.220228         0.001733            No-Pair   \n",
       "4183         0.091822         0.002102            No-Pair   \n",
       "4184         0.211568         0.001711            No-Pair   \n",
       "4185         0.231755         0.001757            No-Pair   \n",
       "4186         0.202175         0.001654            No-Pair   \n",
       "4187         0.001459         0.000081            No-Pair   \n",
       "4188         0.211278         0.001716            No-Pair   \n",
       "\n",
       "      probability_No_pair_2  probability_UMB_2  Tolerance_level  \n",
       "4168               0.219877           0.780123         0.560246  \n",
       "4169               0.219877           0.780123         0.560246  \n",
       "4170               0.426803           0.573197         0.146395  \n",
       "4171               0.618286           0.381714         0.236572  \n",
       "4172               0.968176           0.031824         0.936352  \n",
       "4173               0.968176           0.031824         0.936352  \n",
       "4174               0.618286           0.381714         0.236572  \n",
       "4175               0.219877           0.780123         0.560246  \n",
       "4176               0.219877           0.780123         0.560246  \n",
       "4177               0.966997           0.033003         0.933993  \n",
       "4178               0.999426           0.000574         0.998851  \n",
       "4179               0.726075           0.273925         0.452150  \n",
       "4180               0.219877           0.780123         0.560246  \n",
       "4181               0.219877           0.780123         0.560246  \n",
       "4182               0.618286           0.381714         0.236572  \n",
       "4183               0.548292           0.451708         0.096584  \n",
       "4184               0.618286           0.381714         0.236572  \n",
       "4185               0.618286           0.381714         0.236572  \n",
       "4186               0.618286           0.381714         0.236572  \n",
       "4187               0.840957           0.159043         0.681914  \n",
       "4188               0.618286           0.381714         0.236572  \n",
       "\n",
       "[21 rows x 36 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['SideA.ViewData.Side1_UniqueIds']=='154_3791056034_State Street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['609_3791044365_Advent Geneva', '610_3791044365_Advent Geneva',\n",
       "       '614_3791044365_Advent Geneva', '615_3791044365_Advent Geneva',\n",
       "       '352_3791044365_Advent Geneva', '616_3791044365_Advent Geneva',\n",
       "       '150_3791151084_Advent Geneva'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_mto_table.loc[0,'SideB.ViewData.Side0_UniqueIds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['614_3791044365_Advent Geneva', '615_3791044365_Advent Geneva',\n",
       "       '352_3791044365_Advent Geneva', '150_3791151084_Advent Geneva',\n",
       "       '644_379919610_Advent Geneva'], dtype=object)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_mto_table.loc[1,'SideB.ViewData.Side0_UniqueIds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['641_379919610_Advent Geneva', '649_379919610_Advent Geneva',\n",
       "       '748_379919610_Advent Geneva', '644_379919610_Advent Geneva',\n",
       "       '640_379919610_Advent Geneva', '647_379919610_Advent Geneva',\n",
       "       '648_379919610_Advent Geneva', '148_3791151084_Advent Geneva'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_mto_table.loc[2,'SideB.ViewData.Side0_UniqueIds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## Removing duplicate IDs from side 0\n",
    "\n",
    "if len(many_ids_0)!=0:\n",
    "    unique_many_ids_0 = np.unique(np.concatenate(many_ids_0))\n",
    "else:\n",
    "    unique_many_ids_0 = np.array(['None'])\n",
    "\n",
    "dup_ids_1 = []\n",
    "for i in unique_many_ids_0:\n",
    "    count =0\n",
    "    for j in many_ids_0:\n",
    "        if i in j:\n",
    "            count = count+1\n",
    "            if count==2:\n",
    "                dup_ids_1.append(i)\n",
    "                break             \n",
    "            \n",
    "dup_array_1 = []\n",
    "for i in many_ids_0:\n",
    "    #print(i)\n",
    "    if any(x in dup_ids_1 for x in i):\n",
    "        dup_array_1.append(i)\n",
    " \n",
    "### Converting array to list\n",
    "dup_array_1_list = []\n",
    "for i in dup_array_1:\n",
    "    dup_array_1_list.append(list(i))\n",
    "    \n",
    "many_ids_0_list =[] \n",
    "for j in many_ids_0:\n",
    "    many_ids_0_list.append(list(j))\n",
    "    \n",
    "    \n",
    "filtered_mto = [i for i in many_ids_0_list if not i in dup_array_1_list]\n",
    "\n",
    "one_id_1_final = []\n",
    "for i, j in zip(many_ids_0_list, one_id_1):\n",
    "    if i in filtered_mto:\n",
    "        one_id_1_final.append(j) \n",
    "\n",
    "if len(one_id_1_final)!=0:\n",
    "    #unique_many_ids_1 = np.unique(np.concatenate(many_ids_1))\n",
    "    one_id_1_final = one_id_1_final\n",
    "else:\n",
    "    one_id_1_final = np.array(['None'])\n",
    "\n",
    "#umr_otm_table = umr_otm_table[umr_otm_table['SideB.ViewData.Side0_UniqueIds'].isin(one_id_0_final)]\n",
    "#umr_mto_table = umr_mto_table[umr_mto_table['SideA.ViewData.Side1_UniqueIds'].isin(one_id_1_final)]\n",
    "#umr_mto_table = umr_mto_table.reset_index().drop('index',1)\n",
    "\n",
    "\n",
    "if(umr_mto_table.empty == False):\n",
    "    umr_mto_table = umr_mto_table[umr_mto_table['SideA.ViewData.Side1_UniqueIds'].isin(one_id_1_final)]\n",
    "    umr_mto_table = umr_mto_table.reset_index().drop('index',1)\n",
    "#TODO : Revisit this code later - start here\n",
    "#    umr_mto_table['BreakID_Side0'] = umr_mto_table.apply(lambda x: list(meo_df[meo_df['ViewData.Side0_UniqueIds'].isin(umr_mto_table['SideB.ViewData.Side0_UniqueIds'])]['ViewData.BreakID']), axis=1)\n",
    "#    for i in range(0,umr_mto_table.shape[0]):\n",
    "#        umr_mto_table['BreakID_Side0'].iloc[i] = list(meo_df[meo_df['ViewData.Side0_UniqueIds'].isin(umr_mto_table['SideB.ViewData.Side0_UniqueIds'].values[i])]['ViewData.BreakID'])#        fun_otm_mto_df['BreakID_Side1'].iloc[i] = list(fun_meo_df[fun_meo_df['ViewData.Side1_UniqueIds'].isin(fun_otm_mto_df['SideA.ViewData.Side1_UniqueIds'].iloc[i])]['ViewData.BreakID'])\n",
    "#TODO : Revisit this code later - end here\n",
    "else:\n",
    "    temp_umr_mto_table_message = 'No Many to One found'\n",
    "    print(temp_umr_mto_table_message)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_3791139058_Credit Suisse</td>\n",
       "      <td>[8_3791094530_Advent Geneva, 9_3791094530_Adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95_3791137344_State Street</td>\n",
       "      <td>[39_3791139278_Advent Geneva, 48_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90_3791137344_State Street</td>\n",
       "      <td>[44_3791139278_Advent Geneva, 35_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89_3791137344_State Street</td>\n",
       "      <td>[34_3791139278_Advent Geneva, 43_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91_3791137344_State Street</td>\n",
       "      <td>[36_3791139278_Advent Geneva, 45_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3_379804133_US BANK</td>\n",
       "      <td>[2_3791044155_Advent Geneva, 1_379919467_Adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3_3791139127_JP Morgan</td>\n",
       "      <td>[23_3791139127_Advent Geneva, 22_3791139127_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86_3791137344_State Street</td>\n",
       "      <td>[33_3791139278_Advent Geneva, 24_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85_3791137344_State Street</td>\n",
       "      <td>[32_3791139278_Advent Geneva, 23_3791139278_Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15_3791133038_BNP Paribas</td>\n",
       "      <td>[25_3791135288_Advent Geneva, 3_3791139052_Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8_3791133038_BNP Paribas</td>\n",
       "      <td>[15_3791135288_Advent Geneva, 12_3791139052_Ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SideA.ViewData.Side1_UniqueIds  \\\n",
       "0      2_3791139058_Credit Suisse   \n",
       "1      95_3791137344_State Street   \n",
       "2      90_3791137344_State Street   \n",
       "3      89_3791137344_State Street   \n",
       "4      91_3791137344_State Street   \n",
       "5             3_379804133_US BANK   \n",
       "6          3_3791139127_JP Morgan   \n",
       "7      86_3791137344_State Street   \n",
       "8      85_3791137344_State Street   \n",
       "9       15_3791133038_BNP Paribas   \n",
       "10       8_3791133038_BNP Paribas   \n",
       "\n",
       "                       SideB.ViewData.Side0_UniqueIds  \n",
       "0   [8_3791094530_Advent Geneva, 9_3791094530_Adve...  \n",
       "1   [39_3791139278_Advent Geneva, 48_3791139278_Ad...  \n",
       "2   [44_3791139278_Advent Geneva, 35_3791139278_Ad...  \n",
       "3   [34_3791139278_Advent Geneva, 43_3791139278_Ad...  \n",
       "4   [36_3791139278_Advent Geneva, 45_3791139278_Ad...  \n",
       "5   [2_3791044155_Advent Geneva, 1_379919467_Adven...  \n",
       "6   [23_3791139127_Advent Geneva, 22_3791139127_Ad...  \n",
       "7   [33_3791139278_Advent Geneva, 24_3791139278_Ad...  \n",
       "8   [32_3791139278_Advent Geneva, 23_3791139278_Ad...  \n",
       "9   [25_3791135288_Advent Geneva, 3_3791139052_Adv...  \n",
       "10  [15_3791135288_Advent Geneva, 12_3791139052_Ad...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umr_mto_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.B-P Net Amount</th>\n",
       "      <th>SideB.ViewData.Accounting Net Amount</th>\n",
       "      <th>Trade_Date_match</th>\n",
       "      <th>Settle_Date_match</th>\n",
       "      <th>Amount_diff_2</th>\n",
       "      <th>Trade_date_diff</th>\n",
       "      <th>Settle_date_diff</th>\n",
       "      <th>SideA.ISIN_NA</th>\n",
       "      <th>SideB.ISIN_NA</th>\n",
       "      <th>ViewData.Combined Transaction Type</th>\n",
       "      <th>...</th>\n",
       "      <th>SideA.ViewData.Status</th>\n",
       "      <th>SideA.ViewData.BreakID_A_side</th>\n",
       "      <th>Predicted_action</th>\n",
       "      <th>probability_No_pair</th>\n",
       "      <th>probability_UMB</th>\n",
       "      <th>probability_UMR</th>\n",
       "      <th>Predicted_action_2</th>\n",
       "      <th>probability_No_pair_2</th>\n",
       "      <th>probability_UMB_2</th>\n",
       "      <th>Tolerance_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SideA.ViewData.B-P Net Amount, SideB.ViewData.Accounting Net Amount, Trade_Date_match, Settle_Date_match, Amount_diff_2, Trade_date_diff, Settle_date_diff, SideA.ISIN_NA, SideB.ISIN_NA, ViewData.Combined Transaction Type, Combined_Desc, Combined_TType, abs_amount_flag, tt_map_flag, All_key_nan, new_key_match, new_pb1, SideB.Date, SideA.ViewData.Settle Date, SideB.ViewData.Settle Date, SideA.ViewData._ID, SideB.ViewData._ID, SideB.ViewData.Side0_UniqueIds, SideA.ViewData.Side1_UniqueIds, SideB.ViewData.Status, SideB.ViewData.BreakID_B_side, SideA.ViewData.Status, SideA.ViewData.BreakID_A_side, Predicted_action, probability_No_pair, probability_UMB, probability_UMR, Predicted_action_2, probability_No_pair_2, probability_UMB_2, Tolerance_level]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[X_test['SideB.ViewData.Side0_UniqueIds']=='44_3791150882_Advent Geneva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_mto_flat = [item for sublist in filtered_mto for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ## Removing all the OTM and MTO Ids\n",
    "\n",
    "X_test_left2 = X_test_left[~(X_test_left['SideB.ViewData.Side0_UniqueIds'].isin(filtered_mto_flat))]\n",
    "\n",
    "X_test_left2 = X_test_left2[~(X_test_left2['SideA.ViewData.Side1_UniqueIds'].isin(list(one_id_1)))]\n",
    "\n",
    "X_test_left2 = X_test_left[~(X_test_left['SideB.ViewData.Side0_UniqueIds'].isin(filtered_otm_flat))]\n",
    "X_test_left2 = X_test_left2[~(X_test_left2['SideB.ViewData.Side0_UniqueIds'].isin(list(one_id_0)))]\n",
    "\n",
    "X_test_left2 = X_test_left2.reset_index().drop('index',1)\n",
    "\n",
    "# ## UMB one to one (final)\n",
    "\n",
    "X_test_umb = X_test_left2[X_test_left2['Predicted_action_2']=='UMB_One_to_One']\n",
    "X_test_umb = X_test_umb.reset_index().drop('index',1)\n",
    "\n",
    "one_side_unique_umb_ids = one_to_one_umb(X_test_umb)\n",
    "\n",
    "final_oto_umb_table = X_test_umb[X_test_umb['SideA.ViewData.Side1_UniqueIds'].isin(one_side_unique_umb_ids)]\n",
    "\n",
    "final_oto_umb_table = final_oto_umb_table[['SideB.ViewData.Side0_UniqueIds','SideA.ViewData.Side1_UniqueIds','SideB.ViewData.BreakID_B_side','SideA.ViewData.BreakID_A_side','Predicted_action_2','probability_No_pair_2','probability_UMB_2','probability_UMR']]\n",
    "\n",
    "final_oto_umb_table['probability_UMR'] = 0.00010\n",
    "final_oto_umb_table = final_oto_umb_table.rename(columns = {'Predicted_action_2':'Predicted_action','probability_No_pair_2':'probability_No_pair','probability_UMB_2':'probability_UMB'})\n",
    "\n",
    "# ## Removing IDs from OTO UMB\n",
    "\n",
    "X_test_left3 = X_test_left2[~(X_test_left2['SideB.ViewData.Side0_UniqueIds'].isin(final_oto_umb_table['SideB.ViewData.Side0_UniqueIds']))]\n",
    "X_test_left3 = X_test_left3[~(X_test_left3['SideA.ViewData.Side1_UniqueIds'].isin(final_oto_umb_table['SideA.ViewData.Side1_UniqueIds']))]\n",
    "\n",
    "\n",
    "X_test_left3 = X_test_left3.reset_index().drop('index',1)\n",
    "\n",
    "# ## UMB One to Many and Many to One\n",
    "\n",
    "## Total IDs \n",
    "\n",
    "X_test['SideB.ViewData.Side0_UniqueIds'].nunique() + X_test['SideA.ViewData.Side1_UniqueIds'].nunique()\n",
    "X_test_left3['SideB.ViewData.Side0_UniqueIds'].nunique() + X_test_left3['SideA.ViewData.Side1_UniqueIds'].nunique()\n",
    "\n",
    "open_ids_0_last , open_ids_1_last = no_pair_seg2(X_test_left3)\n",
    "\n",
    "X_test_left3[~X_test_left3['SideB.ViewData.Side0_UniqueIds'].isin(open_ids_0_last)]\n",
    "\n",
    "X_test_left4 = X_test_left3[~((X_test_left3['SideB.ViewData.Side0_UniqueIds'].isin(open_ids_0_last)) | (X_test_left3['SideA.ViewData.Side1_UniqueIds'].isin(open_ids_1_last)))]\n",
    "\n",
    "X_test_left4 = X_test_left4.reset_index().drop('index',1)\n",
    "X_test_left4['SideB.ViewData.Side0_UniqueIds'].nunique() + X_test_left4['SideA.ViewData.Side1_UniqueIds'].nunique()\n",
    "\n",
    "# ## Many to Many new\n",
    "\n",
    "#MANY TO MANY NEW\n",
    "rr2 = X_test[X_test['Predicted_action_2']=='UMB_One_to_One'].groupby(['SideB.ViewData.Side0_UniqueIds'])['SideA.ViewData.Side1_UniqueIds'].unique().reset_index()\n",
    "rr2['SideA.ViewData.Side1_UniqueIds'] = rr2['SideA.ViewData.Side1_UniqueIds'].apply(tuple)\n",
    "\n",
    "rr2.groupby(['SideA.ViewData.Side1_UniqueIds'])['SideB.ViewData.Side0_UniqueIds'].unique().reset_index()\n",
    "\n",
    "rr2 = X_test_left4[X_test_left4['Predicted_action_2']=='UMB_One_to_One'].groupby(['SideB.ViewData.Side0_UniqueIds'])['SideA.ViewData.Side1_UniqueIds'].unique().reset_index()\n",
    "\n",
    "acc_amount = X_test[X_test['Predicted_action_2']=='UMB_One_to_One'].groupby(['SideB.ViewData.Side0_UniqueIds'])['SideB.ViewData.Accounting Net Amount'].max().reset_index()\n",
    "pb_amount_sum =  X_test[X_test['Predicted_action_2']=='UMB_One_to_One'].groupby(['SideB.ViewData.Side0_UniqueIds'])['SideA.ViewData.B-P Net Amount'].sum().reset_index()\n",
    "\n",
    "rr3 = pd.merge(rr2, acc_amount, on='SideB.ViewData.Side0_UniqueIds', how='left')\n",
    "rr4 = pd.merge(rr3, pb_amount_sum, on='SideB.ViewData.Side0_UniqueIds', how='left')\n",
    "\n",
    "rr4['SideA.ViewData.Side1_UniqueIds'] = rr4['SideA.ViewData.Side1_UniqueIds'].apply(tuple)\n",
    "\n",
    "rr5 = rr4.groupby(['SideA.ViewData.Side1_UniqueIds'])['SideB.ViewData.Side0_UniqueIds'].unique().reset_index()\n",
    "\n",
    "rr6 = pd.merge(rr5, rr4.groupby(['SideA.ViewData.Side1_UniqueIds'])['SideB.ViewData.Accounting Net Amount'].sum().reset_index(), on='SideA.ViewData.Side1_UniqueIds', how='left')\n",
    "\n",
    "rr7 = pd.merge(rr6,rr4[['SideA.ViewData.Side1_UniqueIds','SideA.ViewData.B-P Net Amount']].drop_duplicates(), on='SideA.ViewData.Side1_UniqueIds',how='left')\n",
    "\n",
    "rr7['diff'] = rr7['SideB.ViewData.Accounting Net Amount'] - rr7['SideA.ViewData.B-P Net Amount']\n",
    "\n",
    "rr7['pb_len'] = rr7['SideA.ViewData.Side1_UniqueIds'].apply(lambda x: len(x))\n",
    "rr7['acc_len'] = rr7['SideB.ViewData.Side0_UniqueIds'].apply(lambda x: len(x))\n",
    "\n",
    "rr8 = rr7[~((rr7['pb_len']==1)|(rr7['acc_len']==1))]\n",
    "rr8 = rr8.reset_index().drop('index',1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SideA.ViewData.Side1_UniqueIds</th>\n",
       "      <th>SideB.ViewData.Side0_UniqueIds</th>\n",
       "      <th>SideB.ViewData.Accounting Net Amount</th>\n",
       "      <th>SideA.ViewData.B-P Net Amount</th>\n",
       "      <th>diff</th>\n",
       "      <th>pb_len</th>\n",
       "      <th>acc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(100_3791127028_The Bank of New York Mellon, 9...</td>\n",
       "      <td>[108_3791127028_Advent Geneva, 109_3791127028_...</td>\n",
       "      <td>24789.54</td>\n",
       "      <td>27061.81</td>\n",
       "      <td>-2272.27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(11_3791057814_Credit Suisse, 10_3791057814_Cr...</td>\n",
       "      <td>[10_3791052102_Advent Geneva, 11_3791052102_Ad...</td>\n",
       "      <td>132220.03</td>\n",
       "      <td>-3131118.77</td>\n",
       "      <td>3263338.80</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(15_3791133038_BNP Paribas, 14_3791133038_BNP ...</td>\n",
       "      <td>[25_3791135288_Advent Geneva, 3_3791139052_Adv...</td>\n",
       "      <td>123085.00</td>\n",
       "      <td>125031.85</td>\n",
       "      <td>-1946.85</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(15_3791139405_Northern Trust, 12_3791139405_N...</td>\n",
       "      <td>[24_3791125244_Advent Geneva, 32_3791133117_Ad...</td>\n",
       "      <td>382491.32</td>\n",
       "      <td>3836.84</td>\n",
       "      <td>378654.48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1_3791017949_State Street, 1_3791044365_State...</td>\n",
       "      <td>[49_3791048390_Advent Geneva, 50_3791048390_Ad...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>35882.36</td>\n",
       "      <td>-35882.37</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1_3791017949_State Street, 1_3791044365_State...</td>\n",
       "      <td>[49_3791048390_Advent Geneva, 50_3791048390_Ad...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>37132.36</td>\n",
       "      <td>-37132.37</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(239_3791001204_State Street, 33_3791017949_St...</td>\n",
       "      <td>[44_3791011889_Advent Geneva, 62_3791114597_Ad...</td>\n",
       "      <td>-41180.46</td>\n",
       "      <td>-28735360.04</td>\n",
       "      <td>28694179.58</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(239_3791001204_State Street, 33_3791017949_St...</td>\n",
       "      <td>[44_3791011889_Advent Geneva, 62_3791114597_Ad...</td>\n",
       "      <td>-41180.46</td>\n",
       "      <td>-68054056.90</td>\n",
       "      <td>68012876.44</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(28_379939728_Credit Suisse, 29_379939728_Cred...</td>\n",
       "      <td>[10_3791094530_Advent Geneva, 11_3791094530_Ad...</td>\n",
       "      <td>-9511446.27</td>\n",
       "      <td>-65089706.17</td>\n",
       "      <td>55578259.90</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(28_379939728_Credit Suisse, 29_379939728_Cred...</td>\n",
       "      <td>[5_3791094530_Advent Geneva, 6_3791094530_Adve...</td>\n",
       "      <td>9738015.47</td>\n",
       "      <td>-65016753.61</td>\n",
       "      <td>74754769.08</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2_3791106374_Credit Suisse, 1_3791106374_Cred...</td>\n",
       "      <td>[24_3791118170_Advent Geneva, 6_3791118170_Adv...</td>\n",
       "      <td>-2492357.29</td>\n",
       "      <td>-3083636.90</td>\n",
       "      <td>591279.61</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(3_3791139127_JP Morgan, 5_3791139127_JP Morga...</td>\n",
       "      <td>[19_3791139127_Advent Geneva, 20_3791139127_Ad...</td>\n",
       "      <td>85214.73</td>\n",
       "      <td>-1536760.84</td>\n",
       "      <td>1621975.57</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(789_3791127144_State Street, 112_3791139278_S...</td>\n",
       "      <td>[83_3791139278_Advent Geneva, 84_3791139278_Ad...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-61660.02</td>\n",
       "      <td>61660.02</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(85_3791137344_State Street, 86_3791137344_Sta...</td>\n",
       "      <td>[23_3791139278_Advent Geneva, 24_3791139278_Ad...</td>\n",
       "      <td>-154167.79</td>\n",
       "      <td>6978922.39</td>\n",
       "      <td>-7133090.18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(8_3791133038_BNP Paribas, 7_3791133038_BNP Pa...</td>\n",
       "      <td>[12_3791139052_Advent Geneva, 15_3791135288_Ad...</td>\n",
       "      <td>53045.00</td>\n",
       "      <td>53884.02</td>\n",
       "      <td>-839.02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(8_3791139052_BNP Paribas, 9_3791139052_BNP Pa...</td>\n",
       "      <td>[14_3791139052_Advent Geneva, 15_3791139052_Ad...</td>\n",
       "      <td>395067.04</td>\n",
       "      <td>395067.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(93_3791137344_State Street, 87_3791137344_Sta...</td>\n",
       "      <td>[34_3791139278_Advent Geneva, 35_3791139278_Ad...</td>\n",
       "      <td>-40697.68</td>\n",
       "      <td>6952.49</td>\n",
       "      <td>-47650.17</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       SideA.ViewData.Side1_UniqueIds  \\\n",
       "0   (100_3791127028_The Bank of New York Mellon, 9...   \n",
       "1   (11_3791057814_Credit Suisse, 10_3791057814_Cr...   \n",
       "2   (15_3791133038_BNP Paribas, 14_3791133038_BNP ...   \n",
       "3   (15_3791139405_Northern Trust, 12_3791139405_N...   \n",
       "4   (1_3791017949_State Street, 1_3791044365_State...   \n",
       "5   (1_3791017949_State Street, 1_3791044365_State...   \n",
       "6   (239_3791001204_State Street, 33_3791017949_St...   \n",
       "7   (239_3791001204_State Street, 33_3791017949_St...   \n",
       "8   (28_379939728_Credit Suisse, 29_379939728_Cred...   \n",
       "9   (28_379939728_Credit Suisse, 29_379939728_Cred...   \n",
       "10  (2_3791106374_Credit Suisse, 1_3791106374_Cred...   \n",
       "11  (3_3791139127_JP Morgan, 5_3791139127_JP Morga...   \n",
       "12  (789_3791127144_State Street, 112_3791139278_S...   \n",
       "13  (85_3791137344_State Street, 86_3791137344_Sta...   \n",
       "14  (8_3791133038_BNP Paribas, 7_3791133038_BNP Pa...   \n",
       "15  (8_3791139052_BNP Paribas, 9_3791139052_BNP Pa...   \n",
       "16  (93_3791137344_State Street, 87_3791137344_Sta...   \n",
       "\n",
       "                       SideB.ViewData.Side0_UniqueIds  \\\n",
       "0   [108_3791127028_Advent Geneva, 109_3791127028_...   \n",
       "1   [10_3791052102_Advent Geneva, 11_3791052102_Ad...   \n",
       "2   [25_3791135288_Advent Geneva, 3_3791139052_Adv...   \n",
       "3   [24_3791125244_Advent Geneva, 32_3791133117_Ad...   \n",
       "4   [49_3791048390_Advent Geneva, 50_3791048390_Ad...   \n",
       "5   [49_3791048390_Advent Geneva, 50_3791048390_Ad...   \n",
       "6   [44_3791011889_Advent Geneva, 62_3791114597_Ad...   \n",
       "7   [44_3791011889_Advent Geneva, 62_3791114597_Ad...   \n",
       "8   [10_3791094530_Advent Geneva, 11_3791094530_Ad...   \n",
       "9   [5_3791094530_Advent Geneva, 6_3791094530_Adve...   \n",
       "10  [24_3791118170_Advent Geneva, 6_3791118170_Adv...   \n",
       "11  [19_3791139127_Advent Geneva, 20_3791139127_Ad...   \n",
       "12  [83_3791139278_Advent Geneva, 84_3791139278_Ad...   \n",
       "13  [23_3791139278_Advent Geneva, 24_3791139278_Ad...   \n",
       "14  [12_3791139052_Advent Geneva, 15_3791135288_Ad...   \n",
       "15  [14_3791139052_Advent Geneva, 15_3791139052_Ad...   \n",
       "16  [34_3791139278_Advent Geneva, 35_3791139278_Ad...   \n",
       "\n",
       "    SideB.ViewData.Accounting Net Amount  SideA.ViewData.B-P Net Amount  \\\n",
       "0                               24789.54                       27061.81   \n",
       "1                              132220.03                    -3131118.77   \n",
       "2                              123085.00                      125031.85   \n",
       "3                              382491.32                        3836.84   \n",
       "4                                  -0.01                       35882.36   \n",
       "5                                  -0.01                       37132.36   \n",
       "6                              -41180.46                   -28735360.04   \n",
       "7                              -41180.46                   -68054056.90   \n",
       "8                            -9511446.27                   -65089706.17   \n",
       "9                             9738015.47                   -65016753.61   \n",
       "10                           -2492357.29                    -3083636.90   \n",
       "11                              85214.73                    -1536760.84   \n",
       "12                                  0.00                      -61660.02   \n",
       "13                            -154167.79                     6978922.39   \n",
       "14                              53045.00                       53884.02   \n",
       "15                             395067.04                      395067.04   \n",
       "16                             -40697.68                        6952.49   \n",
       "\n",
       "           diff  pb_len  acc_len  \n",
       "0      -2272.27       3        5  \n",
       "1    3263338.80      10        7  \n",
       "2      -1946.85       2        2  \n",
       "3     378654.48       2        2  \n",
       "4     -35882.37       4        2  \n",
       "5     -37132.37       4        2  \n",
       "6   28694179.58       8        2  \n",
       "7   68012876.44       8        2  \n",
       "8   55578259.90      10        8  \n",
       "9   74754769.08      12        2  \n",
       "10    591279.61       3        2  \n",
       "11   1621975.57       5        6  \n",
       "12     61660.02       3        2  \n",
       "13  -7133090.18       4        4  \n",
       "14      -839.02       2        2  \n",
       "15         0.00       2        2  \n",
       "16    -47650.17      13       12  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settle date MTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.concat([aa, bb], axis=0)\n",
    "\n",
    "cc = cc.reset_index().drop('index',1)\n",
    "\n",
    "cc['ViewData.Transaction Type'] = cc['ViewData.Transaction Type'].astype(str)\n",
    "cc['ViewData.Settle Date'] = pd.to_datetime(cc['ViewData.Settle Date'])\n",
    "cc['filter_key_with_sd'] = cc['filter_key'].astype(str) + cc['ViewData.Settle Date'].astype(str)\n",
    "\n",
    "\n",
    "##########################\n",
    "cc7 = cc.copy()\n",
    "\n",
    "cc_new = cc7[cc7['ViewData.Status']!='SPM']\n",
    "cc_new = cc_new.reset_index().drop('index',1)\n",
    "\n",
    "#cc_new = cc_new[~((cc_new['ViewData.Side0_UniqueIds'].isin(final_umr_table['SideB.ViewData.Side0_UniqueIds'])) | (cc_new['ViewData.Side1_UniqueIds'].isin(final_umr_table['SideA.ViewData.Side1_UniqueIds'])))]\n",
    "\n",
    "#cc_new = cc_new[~((cc_new['ViewData.Side0_UniqueIds'].isin(final_umt_table['SideB.ViewData.Side0_UniqueIds'])) | (cc_new['ViewData.Side1_UniqueIds'].isin(final_umt_table['SideA.ViewData.Side1_UniqueIds'])))]\n",
    "\n",
    "cc_new = cc_new.reset_index().drop('index',1)\n",
    "\n",
    "filter_key_umt_umb_sd = []\n",
    "diff_in_amount_sd = []\n",
    "diff_in_amount_key_sd = []\n",
    "for key in cc_new['filter_key_with_sd'].unique():    \n",
    "    cc_dummy = cc_new[cc_new['filter_key_with_sd']==key]\n",
    "    if (-0.25<= cc_dummy['ViewData.Net Amount Difference'].sum() <=0.25) & (cc_dummy.shape[0]>2) & (cc_dummy['Trans_side'].nunique()>1):\n",
    "        #print(cc2_dummy.shape[0])\n",
    "        #print(key)\n",
    "        filter_key_umt_umb_sd.append(key)\n",
    "    else:\n",
    "        if (cc_dummy.shape[0]>2) & (cc_dummy['Trans_side'].nunique()>1):\n",
    "            diff = cc_dummy['ViewData.Net Amount Difference'].sum()\n",
    "            diff_in_amount_sd.append(diff)\n",
    "            diff_in_amount_key_sd.append(key)\n",
    "\n",
    "## Equity Swap Many to many\n",
    "\n",
    "sd_mtm_1_ids = []\n",
    "sd_mtm_0_ids = []\n",
    "\n",
    "for key in filter_key_umt_umb_sd:\n",
    "    one_side = cc_new[cc_new['filter_key_with_sd']== key]['ViewData.Side1_UniqueIds'].unique()\n",
    "    zero_side = cc_new[cc_new['filter_key_with_sd']== key]['ViewData.Side0_UniqueIds'].unique()\n",
    "    one_side = [i for i in one_side if i not in ['nan','None','']]\n",
    "    zero_side = [i for i in zero_side if i not in ['nan','None','']]\n",
    "    sd_mtm_1_ids.append(one_side)\n",
    "    sd_mtm_0_ids.append(zero_side)\n",
    "\n",
    "if sd_mtm_1_ids !=[]:\n",
    "    sd_mtm_list_1 = list(np.concatenate(sd_mtm_1_ids))\n",
    "else:\n",
    "    sd_mtm_list_1 = []\n",
    "\n",
    "if sd_mtm_0_ids !=[]:\n",
    "    sd_mtm_list_0 = list(np.concatenate(sd_mtm_0_ids))\n",
    "else:\n",
    "    sd_mtm_list_0 = []\n",
    "\n",
    "## Data Frame for MTM from equity Swap\n",
    "\n",
    "mtm_df_sd = pd.DataFrame(np.arange(len(sd_mtm_0_ids)))\n",
    "mtm_df_sd.columns = ['index']\n",
    "\n",
    "mtm_df_sd['ViewData.Side0_UniqueIds'] = sd_mtm_0_ids\n",
    "mtm_df_sd['ViewData.Side1_UniqueIds'] = sd_mtm_1_ids\n",
    "mtm_df_sd = mtm_df_sd.drop('index',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViewData.Side0_UniqueIds</th>\n",
       "      <th>ViewData.Side1_UniqueIds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[45_3791139278_Advent Geneva, 44_3791139278_Ad...</td>\n",
       "      <td>[93_3791137344_State Street, 87_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[23_3791139278_Advent Geneva, 24_3791139278_Ad...</td>\n",
       "      <td>[85_3791137344_State Street, 86_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[47_3791137344_Advent Geneva, 16_3791139278_Ad...</td>\n",
       "      <td>[6_3791135409_State Street, 5_3791135409_State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52_3791139278_Advent Geneva, 53_3791139278_Ad...</td>\n",
       "      <td>[67_3791137344_State Street, 68_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[58_3791139278_Advent Geneva, 59_3791139278_Ad...</td>\n",
       "      <td>[70_3791137344_State Street, 71_3791137344_Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[14_3791139052_Advent Geneva, 15_3791139052_Ad...</td>\n",
       "      <td>[8_3791139052_BNP Paribas, 9_3791139052_BNP Pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ViewData.Side0_UniqueIds  \\\n",
       "0  [45_3791139278_Advent Geneva, 44_3791139278_Ad...   \n",
       "1  [23_3791139278_Advent Geneva, 24_3791139278_Ad...   \n",
       "2  [47_3791137344_Advent Geneva, 16_3791139278_Ad...   \n",
       "3  [52_3791139278_Advent Geneva, 53_3791139278_Ad...   \n",
       "4  [58_3791139278_Advent Geneva, 59_3791139278_Ad...   \n",
       "5  [14_3791139052_Advent Geneva, 15_3791139052_Ad...   \n",
       "\n",
       "                            ViewData.Side1_UniqueIds  \n",
       "0  [93_3791137344_State Street, 87_3791137344_Sta...  \n",
       "1  [85_3791137344_State Street, 86_3791137344_Sta...  \n",
       "2  [6_3791135409_State Street, 5_3791135409_State...  \n",
       "3  [67_3791137344_State Street, 68_3791137344_Sta...  \n",
       "4  [70_3791137344_State Street, 71_3791137344_Sta...  \n",
       "5  [8_3791139052_BNP Paribas, 9_3791139052_BNP Pa...  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtm_df_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
