{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (3,5,8,9,11,17,24,30,33,36,37,38,39,40,42,44,46,54,55,56,60,70,77,79,80,81,82,83,84,85,86,89) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "uni2 = pd.read_csv('UMF 85.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def futureacc(x):\n",
    "    if type(x)==str:\n",
    "        x1 = x.split('_')\n",
    "        if len(x1)>=2:\n",
    "            k = x1[1]\n",
    "            k1 = x1[0]\n",
    "            \n",
    "            if k =='WHITNEY':\n",
    "                return 1\n",
    "            elif k1.endswith('FU'):\n",
    "                return 2\n",
    "            elif k1.endswith('COLL'):\n",
    "                return 3\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni2['map_marker'] = uni2['ViewData.Mapped Custodian Account'].apply(lambda x : futureacc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni3 = uni2[uni2['map_marker']==2.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni3 = uni3.rename(columns = {'ViewData.Net Amount Difference':'Net Amount Difference1',\n",
    "                            'ViewData.Mapped Custodian Account':'Custodian Account',\n",
    "                             'ViewData.Currency':'Currency',\n",
    "                             'ViewData.Ticker':'Ticker1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subSum(numbers,total):\n",
    "    length = len(numbers)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if length <20:\n",
    "      \n",
    "            \n",
    "      \n",
    "        \n",
    "        for index,number in enumerate(numbers):\n",
    "            if np.isclose(number, total, atol=5).any():\n",
    "                return [number]\n",
    "                print(34567)\n",
    "            subset = subSum(numbers[index+1:],total-number)\n",
    "            if subset:\n",
    "                #print(12345)\n",
    "                return [number] + subset\n",
    "        return []\n",
    "    else:\n",
    "        return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mark(x,z,k):\n",
    "    \n",
    "   \n",
    "    if ((x>1) & (x<20)):\n",
    "        if ((k<6.0) & (z==0)):\n",
    "            return 1\n",
    "        elif ((k==0.0) & (z!=0)):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "if uni3.shape[0]!=0:\n",
    "    dummy = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'])['Net Amount Difference1'].apply(list).reset_index()\n",
    "    dummy1 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'])['ViewData.Side0_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy1 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    dummy2 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'])['ViewData.Side1_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy2 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    dummy['sel_mark'] = dummy.apply(lambda x : 0 if ((x['ViewData.Side0_UniqueIds']==0) | (x['ViewData.Side1_UniqueIds']==0)) else 1, axis =1 )\n",
    "    dummy = dummy[dummy['sel_mark']==1]\n",
    "    dummy['len_amount'] = dummy['Net Amount Difference1'].apply(lambda x : len(x))\n",
    "    dummy['zero_list'] = dummy['Net Amount Difference1'].apply(lambda x : subSum(x,0))\n",
    "    dummy['zero_list_len'] = dummy['zero_list'].apply(lambda x : len(x))\n",
    "    dummy['diff_len'] = dummy['len_amount'] - dummy['zero_list_len']\n",
    "    dummy['zero_list_sum'] = dummy['zero_list'].apply(lambda x : round(abs(sum(x)),2))\n",
    "    #dummy = pd.merge(dummy, pos , on = ['Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    dummy['remove_mark'] = dummy.apply(lambda x :remove_mark(x['zero_list_len'] ,x['diff_len'], x['zero_list_sum']),axis = 1)\n",
    "    dummy = dummy[['ViewData.Task Business Date','Custodian Account', 'Currency', 'Ticker1', 'zero_list',  'diff_len', 'remove_mark','sel_mark']]\n",
    "    df3 = pd.merge(uni3, dummy, on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    df4 = df3[(df3['sel_mark']==1) & (df3['sel_mark']==1)]\n",
    "    \n",
    "    if df4.shape[0]!=0:\n",
    "        df4['Predicted Category'] = 'Match'\n",
    "        df4['Predicted Comment'] = 'Match'\n",
    "        df4 = df4[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df4.to_csv('Schonfield 85 p1.csv')\n",
    "        df5 = df3[~((df3['sel_mark']==1) & (df3['sel_mark']==1))]\n",
    "        \n",
    "        df5['Predicted Category'] = 'OTE'\n",
    "        df5['Predicted Comment'] = 'Yet to be commented'\n",
    "        df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df5.to_csv('Schonfield 85 p2.csv')\n",
    "    else:\n",
    "        df5 = df3.copy()\n",
    "        \n",
    "        df5['Predicted Category'] = 'OTE'\n",
    "        df5['Predicted Comment'] = 'Yet to be commented'\n",
    "        df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df5.to_csv('Schonfield 85 p3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni3 = uni2[uni2['map_marker']==0.0]\n",
    "\n",
    "uni3 = uni3.rename(columns = {'ViewData.Net Amount Difference':'Net Amount Difference1',\n",
    "                            'ViewData.Mapped Custodian Account':'Custodian Account',\n",
    "                             'ViewData.Currency':'Currency',\n",
    "                             'ViewData.Ticker':'Ticker1'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "if uni3.shape[0]!=0:\n",
    "    dummy = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'])['Net Amount Difference1'].apply(list).reset_index()\n",
    "    dummy1 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'])['ViewData.Side0_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy1 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'], how = 'left')\n",
    "    dummy2 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'])['ViewData.Side1_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy2 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'], how = 'left')\n",
    "    dummy['sel_mark'] = dummy.apply(lambda x : 0 if ((x['ViewData.Side0_UniqueIds']==0) | (x['ViewData.Side1_UniqueIds']==0)) else 1, axis =1 )\n",
    "    dummy = dummy[dummy['sel_mark']==1]\n",
    "    dummy['len_amount'] = dummy['Net Amount Difference1'].apply(lambda x : len(x))\n",
    "    dummy['zero_list'] = dummy['Net Amount Difference1'].apply(lambda x : subSum(x,0))\n",
    "    dummy['zero_list_len'] = dummy['zero_list'].apply(lambda x : len(x))\n",
    "    dummy['diff_len'] = dummy['len_amount'] - dummy['zero_list_len']\n",
    "    dummy['zero_list_sum'] = dummy['zero_list'].apply(lambda x : round(abs(sum(x)),2))\n",
    "    #dummy = pd.merge(dummy, pos , on = ['Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    dummy['remove_mark'] = dummy.apply(lambda x :remove_mark(x['zero_list_len'] ,x['diff_len'], x['zero_list_sum']),axis = 1)\n",
    "    dummy = dummy[['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date', 'zero_list',  'diff_len', 'remove_mark','sel_mark']]\n",
    "    df3 = pd.merge(uni3, dummy, on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Transaction Type','ViewData.Settle Date'], how = 'left')\n",
    "    df4 = df3[(df3['sel_mark']==1) & (df3['sel_mark']==1)]\n",
    "    \n",
    "    if df4.shape[0]!=0:\n",
    "        df4['Predicted Category'] = 'Match'\n",
    "        df4['Predicted Comment'] = 'Match'\n",
    "        df4 = df4[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df4.to_csv('Schonfield 85 p4.csv')\n",
    "        df5 = df3[~((df3['sel_mark']==1) & (df3['sel_mark']==1))]\n",
    "        uni3 = df5.copy()\n",
    "        dummy = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['Net Amount Difference1'].apply(list).reset_index()\n",
    "        dummy1 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['ViewData.Side0_UniqueIds'].count().reset_index()\n",
    "        dummy = pd.merge(dummy, dummy1 , on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        dummy2 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['ViewData.Side1_UniqueIds'].count().reset_index()\n",
    "        dummy = pd.merge(dummy, dummy2 , on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        dummy['sel_mark'] = dummy.apply(lambda x : 0 if ((x['ViewData.Side0_UniqueIds']==0) | (x['ViewData.Side1_UniqueIds']==0)) else 1, axis =1 )\n",
    "        dummy = dummy[dummy['sel_mark']==1]\n",
    "        \n",
    "        dummy['len_amount'] = dummy['Net Amount Difference1'].apply(lambda x : len(x))\n",
    "        dummy['zero_list'] = dummy['Net Amount Difference1'].apply(lambda x : subSum(x,0))\n",
    "        dummy['zero_list_len'] = dummy['zero_list'].apply(lambda x : len(x))\n",
    "        dummy['diff_len'] = dummy['len_amount'] - dummy['zero_list_len']\n",
    "        dummy['zero_list_sum'] = dummy['zero_list'].apply(lambda x : round(abs(sum(x)),2))\n",
    "        \n",
    "        df3 = pd.DataFrame()\n",
    "        df4 = pd.DataFrame()\n",
    "        df5 = pd.DataFrame()\n",
    "        \n",
    "        uni3.drop(['zero_list', 'diff_len', 'remove_mark', 'sel_mark'], axis = 1, inplace = True)\n",
    "        \n",
    "        dummy['remove_mark'] = dummy.apply(lambda x :remove_mark(x['zero_list_len'] ,x['diff_len'], x['zero_list_sum']),axis = 1)\n",
    "        dummy = dummy[['ViewData.Task Business Date','Custodian Account','Currency','zero_list',  'diff_len', 'remove_mark','sel_mark']]\n",
    "        df3 = pd.merge(uni3, dummy, on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        df4 = df3[(df3['sel_mark']==1) & (df3['sel_mark']==1)]\n",
    "        \n",
    "        \n",
    "        if df4.shape[0]!=0:\n",
    "            \n",
    "            df4['Predicted Category'] = 'Match'\n",
    "            df4['Predicted Comment'] = 'Match'\n",
    "            df4 = df4[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df4.to_csv('Schonfield 85 p5.csv')\n",
    "        \n",
    "        \n",
    "            df5 = df3[~((df3['sel_mark']==1) & (df3['sel_mark']==1))]\n",
    "            df5['Predicted Category'] = 'OTE'\n",
    "            df5['Predicted Comment'] = 'Yet to be commented'\n",
    "            df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df5.to_csv('Schonfield 85 p6.csv')\n",
    "        else:\n",
    "            df5 = df3.copy()\n",
    "        \n",
    "            df5['Predicted Category'] = 'OTE'\n",
    "            df5['Predicted Comment'] = 'Yet to be commented'\n",
    "            df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df5.to_csv('Schonfield 85 p7.csv')\n",
    "    else:\n",
    "        df5 = df3.copy()\n",
    "        \n",
    "        df5['Predicted Category'] = 'OTE'\n",
    "        df5['Predicted Comment'] = 'Yet to be commented'\n",
    "        df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df5.to_csv('Schonfield 85 p8.csv')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni3 = uni2[uni2['map_marker']==1.0]\n",
    "\n",
    "uni3 = uni3.rename(columns = {'ViewData.Net Amount Difference':'Net Amount Difference1',\n",
    "                            'ViewData.Mapped Custodian Account':'Custodian Account',\n",
    "                             'ViewData.Currency':'Currency',\n",
    "                             'ViewData.Ticker':'Ticker1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\consultant137\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "if uni3.shape[0]!=0:\n",
    "    dummy = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'])['Net Amount Difference1'].apply(list).reset_index()\n",
    "    dummy1 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'])['ViewData.Side0_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy1 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'], how = 'left')\n",
    "    dummy2 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'])['ViewData.Side1_UniqueIds'].count().reset_index()\n",
    "    dummy = pd.merge(dummy, dummy2 , on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'], how = 'left')\n",
    "    dummy['sel_mark'] = dummy.apply(lambda x : 0 if ((x['ViewData.Side0_UniqueIds']==0) | (x['ViewData.Side1_UniqueIds']==0)) else 1, axis =1 )\n",
    "    dummy = dummy[dummy['sel_mark']==1]\n",
    "    dummy['len_amount'] = dummy['Net Amount Difference1'].apply(lambda x : len(x))\n",
    "    dummy['zero_list'] = dummy['Net Amount Difference1'].apply(lambda x : subSum(x,0))\n",
    "    dummy['zero_list_len'] = dummy['zero_list'].apply(lambda x : len(x))\n",
    "    dummy['diff_len'] = dummy['len_amount'] - dummy['zero_list_len']\n",
    "    dummy['zero_list_sum'] = dummy['zero_list'].apply(lambda x : round(abs(sum(x)),2))\n",
    "    #dummy = pd.merge(dummy, pos , on = ['Custodian Account','Currency','Ticker1'], how = 'left')\n",
    "    dummy['remove_mark'] = dummy.apply(lambda x :remove_mark(x['zero_list_len'] ,x['diff_len'], x['zero_list_sum']),axis = 1)\n",
    "    dummy = dummy[['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date', 'zero_list',  'diff_len', 'remove_mark','sel_mark']]\n",
    "    df3 = pd.merge(uni3, dummy, on = ['ViewData.Task Business Date','Custodian Account','Currency','Ticker1','ViewData.Settle Date'], how = 'left')\n",
    "    df4 = df3[(df3['sel_mark']==1) & (df3['sel_mark']==1)]\n",
    "    \n",
    "    if df4.shape[0]!=0:\n",
    "        df4['Predicted Category'] = 'Match'\n",
    "        df4['Predicted Comment'] = 'Match'\n",
    "        df4 = df4[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df4.to_csv('Schonfield 85 p9.csv')\n",
    "        df5 = df3[~((df3['sel_mark']==1) & (df3['sel_mark']==1))]\n",
    "        uni3 = df5.copy()\n",
    "        dummy = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['Net Amount Difference1'].apply(list).reset_index()\n",
    "        dummy1 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['ViewData.Side0_UniqueIds'].count().reset_index()\n",
    "        dummy = pd.merge(dummy, dummy1 , on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        dummy2 = uni3.groupby(['ViewData.Task Business Date','Custodian Account','Currency'])['ViewData.Side1_UniqueIds'].count().reset_index()\n",
    "        dummy = pd.merge(dummy, dummy2 , on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        dummy['sel_mark'] = dummy.apply(lambda x : 0 if ((x['ViewData.Side0_UniqueIds']==0) | (x['ViewData.Side1_UniqueIds']==0)) else 1, axis =1 )\n",
    "        dummy = dummy[dummy['sel_mark']==1]\n",
    "        \n",
    "        dummy['len_amount'] = dummy['Net Amount Difference1'].apply(lambda x : len(x))\n",
    "        dummy['zero_list'] = dummy['Net Amount Difference1'].apply(lambda x : subSum(x,0))\n",
    "        dummy['zero_list_len'] = dummy['zero_list'].apply(lambda x : len(x))\n",
    "        dummy['diff_len'] = dummy['len_amount'] - dummy['zero_list_len']\n",
    "        dummy['zero_list_sum'] = dummy['zero_list'].apply(lambda x : round(abs(sum(x)),2))\n",
    "        \n",
    "        df3 = pd.DataFrame()\n",
    "        df4 = pd.DataFrame()\n",
    "        df5 = pd.DataFrame()\n",
    "        \n",
    "        uni3.drop(['zero_list', 'diff_len', 'remove_mark', 'sel_mark'], axis = 1, inplace = True)\n",
    "        \n",
    "        dummy['remove_mark'] = dummy.apply(lambda x :remove_mark(x['zero_list_len'] ,x['diff_len'], x['zero_list_sum']),axis = 1)\n",
    "        dummy = dummy[['ViewData.Task Business Date','Custodian Account','Currency','zero_list',  'diff_len', 'remove_mark','sel_mark']]\n",
    "        df3 = pd.merge(uni3, dummy, on = ['ViewData.Task Business Date','Custodian Account','Currency'], how = 'left')\n",
    "        df4 = df3[(df3['sel_mark']==1) & (df3['sel_mark']==1)]\n",
    "        \n",
    "        \n",
    "        if df4.shape[0]!=0:\n",
    "            \n",
    "            df4['Predicted Category'] = 'Match'\n",
    "            df4['Predicted Comment'] = 'Match'\n",
    "            df4 = df4[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df4.to_csv('Schonfield 85 p10.csv')\n",
    "        \n",
    "        \n",
    "            df5 = df3[~((df3['sel_mark']==1) & (df3['sel_mark']==1))]\n",
    "            df5['Predicted Category'] = 'OTE'\n",
    "            df5['Predicted Comment'] = 'Yet to be commented'\n",
    "            df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df5.to_csv('Schonfield 85 p11.csv')\n",
    "        else:\n",
    "            df5 = df3.copy()\n",
    "        \n",
    "            df5['Predicted Category'] = 'OTE'\n",
    "            df5['Predicted Comment'] = 'Yet to be commented'\n",
    "            df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "            df5.to_csv('Schonfield 85 p12.csv')\n",
    "    else:\n",
    "        df5 = df3.copy()\n",
    "        \n",
    "        df5['Predicted Category'] = 'OTE'\n",
    "        df5['Predicted Comment'] = 'Yet to be commented'\n",
    "        df5 = df5[['ViewData.Side0_UniqueIds','ViewData.Side1_UniqueIds','Predicted Category','Predicted Comment']]\n",
    "        df5.to_csv('Schonfield 85 p13.csv')\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
